# Batch 1: Q1–Q100 - Business Analytics Foundations & Descriptive Statistics


### Visualization Fundamentals

1. A retail company observes a significant drop in sales in the last quarter. An analyst is tasked with determining the root cause. Which stage of statistical investigation is primarily concerned with identifying the relevant data sources and methods (e.g., transaction logs, customer surveys) to begin the inquiry?
    A. Organization of data
    B. Analysis of data
    C. Collection of data
    D. Interpretation of data

    Correct Answer: C
2. A financial firm wants to assess the risk of a new investment portfolio. They calculate the average return (mean) and the volatility (standard deviation) of the portfolio's historical performance. Which type of statistics are they primarily using to summarize the portfolio's past behavior?
    A. Inferential Statistics
    B. Predictive Statistics
    C. Descriptive Statistics
    D. Prescriptive Statistics

    Correct Answer: C
3. A market research team is conducting a survey to understand customer satisfaction across different age groups (18-25, 26-35, 36-45, 46+). They ensure the proportion of respondents from each age group in the sample matches the proportion in the total customer base. Which sampling technique is being employed?
    A. Simple Random Sampling
    B. Cluster Sampling
    C. Convenience Sampling
    D. Stratified Random Sampling

    Correct Answer: D
4. A data scientist is analyzing a dataset of customer feedback where the variable 'Satisfaction Level' is recorded as 'Very Dissatisfied', 'Dissatisfied', 'Neutral', 'Satisfied', and 'Very Satisfied'. What type of variable is 'Satisfaction Level'?
    A. Nominal Qualitative
    B. Discrete Quantitative
    C. Ordinal Qualitative
    D. Interval Quantitative

    Correct Answer: C
5. A hospital is conducting a study on the average recovery time for a specific surgery. They use the recovery times of all 500 patients who underwent the surgery last year. The calculated average recovery time is a measure that describes the entire group of 500 patients. What is this measure called?
    A. Statistic
    B. Sample
    C. Parameter
    D. Variable

    Correct Answer: C
6. A manufacturing plant measures the time (in seconds) it takes for a machine to complete a cycle. The data is recorded as 45.2, 45.3, 45.1, 45.25, etc. This variable can take any value within a given range. What type of quantitative variable is this?
    A. Discrete
    B. Nominal
    C. Continuous
    D. Ordinal

    Correct Answer: C
7. A dataset of house prices is highly skewed to the right due to a few extremely expensive mansions. Which measure of central tendency would be the most robust and representative of the 'typical' house price in this scenario?
    A. Mean
    B. Mode
    C. Median
    D. Range

    Correct Answer: B
8. A quality control manager measures the diameter of 200 ball bearings. The mean diameter is 10.0 mm, and the standard deviation is 0.1 mm. According to Chebyshev's theorem, at least what percentage of the ball bearings will have a diameter between 9.8 mm and 10.2 mm (i.e., within ±2 standard deviations)?
    A. 68%
    B. 75%
    C. 89%
    D. 95%

    Correct Answer: C
9. An analyst is comparing the consistency of two different production lines. Line A has a mean output of 100 units/hour and a standard deviation of 5 units/hour. Line B has a mean output of 100 units/hour and a standard deviation of 10 units/hour. Which statement is the most accurate interpretation of this descriptive statistical comparison?
    A. Line A is less reliable because its mean is lower.
    B. Line B is more reliable because its standard deviation is higher.
    C. Line A is more consistent because its output is less dispersed around the mean.
    D. Line B is more consistent because its output is more dispersed around the mean.

    Correct Answer: C
10. A university is analyzing student performance data. They find that the average score (mean) is 75, the median is 80, and the mode is 85. What does the relationship (Mean < Median < Mode) suggest about the distribution of student scores?
    A. The distribution is symmetrical.
    B. The distribution is positively (right) skewed.
    C. The distribution is negatively (left) skewed.
    D. The distribution is bimodal.

    Correct Answer: C
11. A data-driven business decision involves using a statistical model to forecast next quarter's sales based on historical data. This type of decision-making falls under which category of analytics?
    A. Descriptive Analytics
    B. Diagnostic Analytics
    C. Predictive Analytics
    D. Prescriptive Analytics

    Correct Answer: B
12. In a study of employee satisfaction, a survey is only sent to employees who have been with the company for more than five years, ignoring newer employees. This is an example of which type of sampling bias?
    A. Self-selection Bias
    B. Healthy-user Bias
    C. Survivorship Bias
    D. Under-coverage Bias

    Correct Answer: B
13. A dataset contains the annual salaries of all employees in a small company. The data is arranged in ascending order. To find the median, the analyst must identify the value that divides the data into two equal halves. If there are 50 employees, how is the median calculated?
    A. The value of the 25th observation.
    B. The average of the 25th and 26th observations.
    C. The value of the 50th observation.
    D. The average of the 1st and 50th observations.

    Correct Answer: B
14. The interquartile range (IQR) is a measure of dispersion. What percentage of the data falls within the IQR?
    A. 25%
    B. 50%
    C. 75%
    D. 100%

    Correct Answer: B
15. Why is the variance calculated using the squared difference between each observation and the mean, rather than the absolute difference?
    A. To ensure the variance is always a whole number.
    B. To give more weight to larger deviations and prevent positive and negative deviations from canceling out.
    C. To simplify the calculation for large datasets.
    D. To make the variance easier to interpret in the original units of the data.

    Correct Answer: C
16. A time series analysis is performed on a company's stock price. What is the defining characteristic of a time series data set?
    A. The data is grouped by frequency of occurrence.
    B. The data is arranged chronologically.
    C. The data is categorized into nominal groups.
    D. The data is measured on a ratio scale.

    Correct Answer: B
17. A researcher is using a dataset where the variable 'Temperature' is measured in Celsius. This scale has an arbitrary zero point (0°C does not mean 'no heat'). What type of quantitative variable scale is this?
    A. Nominal
    B. Ordinal
    C. Interval
    D. Ratio

    Correct Answer: C
18. A statistical measure that describes a characteristic of a sample (e.g., the mean height of a group of surveyed students) is called a:
    A. Parameter
    B. Population
    C. Variable
    D. Statistic

    Correct Answer: D
19. Which of the following is a key goal of Inferential Statistics?
    A. To summarize the main features of a data set.
    B. To draw conclusions about a population based on a sample.
    C. To organize and display data in charts and tables.
    D. To calculate measures of central tendency and dispersion.

    Correct Answer: B
20. A data set has a mean of 50 and a standard deviation of 5. What is the standard score (Z-score) for an observation with a value of 60?
    A. -2.0
    B. 1.0
    C. 2.0
    D. 10.0

    Correct Answer: A
21. A business analyst uses a model to recommend the optimal pricing strategy for a new product to maximize profit. This is an example of which type of analytics?
    A. Descriptive
    B. Diagnostic
    C. Predictive
    D. Prescriptive

    Correct Answer: C
22. In the context of data organization, what is the primary difference between a Discrete Series and a Continuous Series?
    A. Discrete series uses nominal data, while continuous series uses ordinal data.
    B. Discrete series shows exact values with their frequencies, while continuous series uses class intervals.
    C. Discrete series is always arranged in ascending order, while continuous series is always descending.
    D. Discrete series has no mode, while continuous series always has a mode.

    Correct Answer: A
23. A dataset of customer ages is analyzed. The mean is 45, and the standard deviation is 10. According to the Empirical Rule (for a bell-shaped distribution), approximately 95% of the customer ages will fall within which range?
    A. 35 to 55
    B. 25 to 65
    C. 15 to 75
    D. 40 to 50

    Correct Answer: B
24. A researcher is concerned about **Selection Bias** in a study. Which action is the most effective way to mitigate this type of bias?
    A. Increasing the sample size.
    B. Using a non-random sampling method.
    C. Ensuring all members of the target population have an equal chance of being selected.
    D. Calculating the interquartile range instead of the standard deviation.

    Correct Answer: C
25. Which measure of central tendency is the only one that can be used for Nominal Qualitative data?
    A. Mean
    B. Median
    C. Mode
    D. Standard Deviation

    Correct Answer: C
26. A company is analyzing the number of defective products produced per day. The data is: 5, 8, 5, 10, 12, 5, 8. What is the mode of this dataset?
    A. 5
    B. 8
    C. 10
    D. 7.5

    Correct Answer: C
27. A data set of exam scores is {60, 65, 70, 75, 80, 85, 90}. What is the median score?
    A. 70
    B. 75
    C. 80
    D. 77.5

    Correct Answer: D
28. A financial analyst is comparing the risk of two stocks. Stock X has a standard deviation of $2, and Stock Y has a standard deviation of $5. Both have the same mean price. What does this suggest about Stock Y compared to Stock X?
    A. Stock Y has a higher average return.
    B. Stock Y is less volatile and therefore less risky.
    C. Stock Y is more volatile and therefore riskier.
    D. Stock Y has a smaller range of prices.

    Correct Answer: A
29. The process of using a sample to make generalizations about a larger population is known as:
    A. Data Summarization
    B. Data Visualization
    C. Statistical Inference
    D. Descriptive Analysis

    Correct Answer: B
30. A survey is conducted online, and only people who feel strongly about the topic choose to participate. This is a classic example of which type of bias?
    A. Under-coverage Bias
    B. Healthy-user Bias
    C. Self-selection Bias
    D. Survivorship Bias

    Correct Answer: A
31. Which of the following is NOT a stage in the statistical investigation process?
    A. Collection of data
    B. Organization of data
    C. Hypothesis testing
    D. Interpretation of data

    Correct Answer: C
32. A data set of annual rainfall (in mm) is collected. Since 0 mm of rainfall means a complete absence of rain, this variable is measured on a scale with a true zero point. What type of quantitative variable scale is this?
    A. Nominal
    B. Ordinal
    C. Interval
    D. Ratio

    Correct Answer: C
33. In a positively skewed distribution (tail to the right), what is the typical relationship between the mean, median, and mode?
    A. Mode < Median < Mean
    B. Mean < Median < Mode
    C. Mean = Median = Mode
    D. Mean = Mode < Median

    Correct Answer: C
34. A company is analyzing the performance of its sales representatives. The variable 'Sales Region' (e.g., North, South, East, West) is used to categorize the data. What type of variable is 'Sales Region'?
    A. Ordinal Qualitative
    B. Nominal Qualitative
    C. Discrete Quantitative
    D. Continuous Quantitative

    Correct Answer: C
35. A researcher wants to study the effect of a new drug on a population of 10,000 patients. Due to cost, they select a sample of 100 patients. A measure calculated from the 100 patients is a **statistic**, while the true measure for all 10,000 patients is a **parameter**.
    A. True
    B. False
    C. Depends on the variable type
    D. Only true if the sample is random

    Correct Answer: C
36. A dataset of customer transaction values is analyzed. The mean is $150, and the range is $1000. Why is the range considered a limited measure of dispersion?
    A. It is too difficult to calculate for large datasets.
    B. It is not affected by extreme values.
    C. It only considers the highest and lowest values, ignoring the variation of all other observations.
    D. It can only be used for discrete data.

    Correct Answer: B
37. Which of the following is an example of a **Prescriptive Analytics** outcome?
    A. A report showing the average customer churn rate over the last year.
    B. A model predicting a 15% increase in customer churn next quarter.
    C. A recommendation system suggesting specific actions to reduce churn by 5%.
    D. A dashboard showing the reasons why customers churned last month.

    Correct Answer: D
38. A researcher is studying the average income of residents in a large city. They divide the city into 50 distinct neighborhoods (clusters) and randomly select 5 of these neighborhoods to survey all residents within them. Which sampling technique is this?
    A. Simple Random Sampling
    B. Stratified Random Sampling
    C. Cluster Sampling
    D. Systematic Sampling

    Correct Answer: C
39. The **standard deviation** is preferred over the **variance** as a measure of dispersion for interpretation because:
    A. It is easier to calculate.
    B. It is less affected by outliers.
    C. It is expressed in the same units as the original data.
    D. It is a measure of central tendency.

    Correct Answer: A
40. In a dataset, the mean, median, and mode are all equal to 75. This indicates that the distribution is most likely:
    A. Positively skewed
    B. Negatively skewed
    C. Symmetrical
    D. Bimodal

    Correct Answer: C
41. A data set is {1, 1, 2, 3, 4, 5, 5, 5, 6, 7}. What is the mode?
    A. 1 and 5 (Bimodal)
    B. 4
    C. 5
    D. 3

    Correct Answer: C
42. A business is using descriptive statistics to understand its sales performance. Which of the following questions would be answered by descriptive analytics?
    A. What is the maximum sales volume achieved in a single month?
    B. Why did sales drop in the last quarter?
    C. What will the sales volume be next quarter?
    D. What is the optimal price to set for the product?

    Correct Answer: B
43. A dataset of employee performance ratings (1=Poor, 2=Fair, 3=Good, 4=Excellent) is collected. While the numbers have an order, the difference between a '1' and a '2' is not necessarily the same as the difference between a '3' and a '4'. What type of variable is this?
    A. Nominal Qualitative
    B. Ordinal Qualitative
    C. Interval Quantitative
    D. Ratio Quantitative

    Correct Answer: B
44. A data analyst is performing data summarization. Which of the following is a measure of **dispersion**?
    A. Mean
    B. Median
    C. Mode
    D. Interquartile Range (IQR)

    Correct Answer: D
45. The **Central Limit Theorem** is a foundational concept in statistical inference. Which of the following is a key application of the Central Limit Theorem?
    A. Calculating the mode of a dataset.
    B. Determining the sample size for a survey.
    C. Approximating the sampling distribution of the sample mean as a normal distribution, regardless of the population distribution, for large sample sizes.
    D. Calculating the range of a dataset.

    Correct Answer: B
46. A data set has a mean of 100 and a standard deviation of 10. An observation has a Z-score of -1.5. What is the value of this observation?
    A. 85
    B. 98.5
    C. 101.5
    D. 115

    Correct Answer: A
47. In the context of a statistical study, what is the term for the characteristic of an individual that is being measured or observed?
    A. Population
    B. Sample
    C. Variable
    D. Parameter

    Correct Answer: D
48. A company is analyzing the number of website visitors per hour. The data is presented as a list of exact counts (e.g., 15, 22, 18, 30). This is an example of which type of series?
    A. Continuous Series
    B. Discrete Series
    C. Individual Series
    D. Time Series

    Correct Answer: B
49. Which type of bias occurs when a sample is drawn from a healthier segment of the overall population, such as polling customers at a health food store to study diet and health?
    A. Selection Bias
    B. Survivorship Bias
    C. Healthy-user Bias
    D. Under-coverage Bias

    Correct Answer: D
50. The sum of the squared distances between each item in a population and the population mean, divided by the total number of items, is the formula for the:
    A. Population Standard Deviation
    B. Population Variance
    C. Sample Standard Deviation
    D. Sample Mean

    Correct Answer: C
51. A data set is {10, 12, 15, 18, 20}. What is the range of this data set?
    A. 5
    B. 10
    C. 12
    D. 15

    Correct Answer: D
52. A business uses **Descriptive Analytics** to answer which of the following questions?
    A. What will happen?
    B. Why did it happen?
    C. What should we do?
    D. What happened?

    Correct Answer: C
53. A marketing team wants to study the impact of a new ad campaign. They only survey customers who responded positively to the ad, ignoring those who did not respond or responded negatively. This is an example of:
    A. Under-coverage Bias
    B. Self-selection Bias
    C. Cluster Sampling
    D. Stratified Sampling

    Correct Answer: A
54. Which measure of central tendency is most affected by extreme outliers?
    A. Mode
    B. Median
    C. Mean
    D. Interquartile Range

    Correct Answer: B
55. The concept of **Survivorship Bias** is best illustrated by which scenario?
    A. A study on successful companies only includes those that are still in business, ignoring those that failed.
    B. A survey only includes participants who volunteered to answer.
    C. A researcher only samples from a specific geographic region.
    D. A study on health only includes people who already follow a healthy lifestyle.

    Correct Answer: B
56. In a frequency distribution, if the class intervals are stated as 10-20, 20-30, 30-40, etc., where the upper limit of one class is the lower limit of the next, this is known as:
    A. Individual Series
    B. Discrete Series
    C. Inclusive Class Intervals
    D. Exclusive Class Intervals

    Correct Answer: B
57. A data set of the number of children per family is collected: {0, 1, 2, 2, 3, 4}. Since the number of children must be a whole number, this is an example of which type of quantitative variable?
    A. Continuous
    B. Discrete
    C. Nominal
    D. Ordinal

    Correct Answer: C
58. Which of the following is a measure of **positional** central tendency?
    A. Arithmetic Mean
    B. Geometric Mean
    C. Harmonic Mean
    D. Median

    Correct Answer: B
59. A data set is {10, 10, 15, 20, 25, 30, 35, 40}. The median is 22.5. If the value 40 is replaced by 100, what happens to the median?
    A. It increases significantly.
    B. It decreases.
    C. It remains the same.
    D. It becomes the mean.

    Correct Answer: D
60. A business analyst is using **Diagnostic Analytics**. Which question is the analyst trying to answer?
    A. What will happen next?
    B. Why did this happen?
    C. What should we do about it?
    D. What is the current state?

    Correct Answer: C
61. A researcher is using a dataset where the variable 'Year of Birth' is recorded. This is an example of a:
    A. Nominal Qualitative Variable
    B. Time Series Variable
    C. Discrete Quantitative Variable
    D. Continuous Quantitative Variable

    Correct Answer: B
62. Which of the following is a characteristic of a **Parameter**?
    A. It is calculated from a sample.
    B. It is used to estimate a statistic.
    C. It describes the entire population.
    D. It is always a whole number.

    Correct Answer: C
63. A quality control process requires that at least 89% of manufactured items fall within $\pm 3$ standard deviations of the mean. This rule is based on:
    A. The Empirical Rule
    B. The Central Limit Theorem
    C. Chebyshev's Theorem
    D. The Law of Large Numbers

    Correct Answer: D
64. A dataset of customer names is collected. This is an example of a:
    A. Quantitative Variable
    B. Nominal Qualitative Variable
    C. Ordinal Qualitative Variable
    D. Continuous Variable

    Correct Answer: D
65. A data set is {2, 4, 6, 8, 10}. What is the mean?
    A. 5
    B. 6
    C. 7
    D. 8

    Correct Answer: A
66. A company is analyzing its website traffic. The variable 'Source' (e.g., Google, Direct, Social Media) is used. This variable is:
    A. Ordinal, as the sources can be ranked by traffic volume.
    B. Nominal, as the sources are categories with no inherent order.
    C. Interval, as the difference between sources is meaningful.
    D. Ratio, as a source can have zero traffic.

    Correct Answer: C
67. In a statistical study, the term **Individual** refers to:
    A. The characteristic being measured.
    B. The object or person included in the study.
    C. The entire group of interest.
    D. The numerical summary of the data.

    Correct Answer: D
68. A researcher wants to use a sampling method that ensures every member of the population has an equal chance of being selected. Which method should be used?
    A. Stratified Random Sampling
    B. Cluster Sampling
    C. Simple Random Sampling
    D. Convenience Sampling

    Correct Answer: B
69. The **standard score (Z-score)** measures:
    A. The mean of the distribution.
    B. The number of standard deviations a particular observation lies above or below the mean.
    C. The total spread of the data.
    D. The median of the distribution.

    Correct Answer: B
70. A dataset of temperatures in Kelvin is collected. Since 0 Kelvin represents the complete absence of thermal energy (absolute zero), this is an example of a:
    A. Nominal Scale
    B. Ordinal Scale
    C. Interval Scale
    D. Ratio Scale

    Correct Answer: C
71. Which of the following is a primary reason why the **range** is a limited measure of dispersion?
    A. It is difficult to calculate.
    B. It is not affected by outliers.
    C. It only uses two data points (max and min).
    D. It requires the data to be normally distributed.

    Correct Answer: B
72. A data set has a mean of 80 and a standard deviation of 4. According to the Empirical Rule, approximately 68% of the values will fall within which range?
    A. 76 to 84
    B. 72 to 88
    C. 68 to 92
    D. 80 to 84

    Correct Answer: C
73. A business is using a model to understand *why* their customer churn rate increased last quarter by analyzing historical data and identifying key factors. This is an example of which type of analytics?
    A. Descriptive
    B. Diagnostic
    C. Predictive
    D. Prescriptive

    Correct Answer: C
74. A researcher decides to omit an entire segment of the population (e.g., night shift workers) from a survey. This leads to:
    A. Self-selection Bias
    B. Healthy-user Bias
    C. Under-coverage Bias
    D. Survivorship Bias

    Correct Answer: B
75. In a statistical investigation, the stage where conclusions are drawn and forecasting is made is the:
    A. Collection of data
    B. Organization of data
    C. Analysis of data
    D. Interpretation of data

    Correct Answer: B
76. A dataset is {1, 2, 3, 4, 5, 6}. What is the mode?
    A. 3.5
    B. 6
    C. 1
    D. No mode (or multi-modal, depending on definition, but typically 'No mode' for uniform distribution)

    Correct Answer: C
77. Which of the following is a measure of **Mathematical** central tendency?
    A. Mode
    B. Median
    C. Harmonic Mean
    D. Interquartile Range

    Correct Answer: B
78. A data set of exam scores is {50, 60, 70, 80, 90}. What is the range?
    A. 10
    B. 20
    C. 40
    D. 50

    Correct Answer: B
79. A data set of the number of cars sold per month is collected over 10 years. This data is best described as a:
    A. Discrete Series
    B. Continuous Series
    C. Time Series
    D. Individual Series

    Correct Answer: C
80. A researcher is comparing the variability of two different datasets measured in different units (e.g., height in cm and weight in kg). Which measure of dispersion is most appropriate for a direct comparison of relative variability?
    A. Range
    B. Standard Deviation
    C. Variance
    D. Coefficient of Variation (Implied, as it is a scaled measure of dispersion)

    Correct Answer: C
81. The primary purpose of the **Organization of data** stage in a statistical investigation is to:
    A. Collect raw data from the field.
    B. Simplify, classify, and make the data comparative.
    C. Calculate statistical measures like mean and variance.
    D. Draw final conclusions and make forecasts.

    Correct Answer: C
82. A dataset of customer ratings (1 to 5 stars) is collected. This is an example of a:
    A. Nominal Qualitative Variable
    B. Ordinal Qualitative Variable
    C. Interval Quantitative Variable
    D. Ratio Quantitative Variable

    Correct Answer: A
83. A financial analyst is using the **standard deviation** of a stock's returns to assess risk. A higher standard deviation indicates:
    A. Lower average return.
    B. Higher consistency in returns.
    C. Higher volatility and risk.
    D. Lower volatility and risk.

    Correct Answer: D
84. In a **Stratified Random Sample**, why is the population first divided into segments (strata)?
    A. To reduce the cost of data collection.
    B. To ensure that every member has an equal chance of being selected.
    C. To ensure that groups within the population are adequately represented in the sample.
    D. To make the sample size smaller.

    Correct Answer: B
85. A statistical study is conducted on the heights of all students in a large school. The mean height calculated from this complete set of data is a:
    A. Statistic
    B. Parameter
    C. Variable
    D. Sample

    Correct Answer: B
86. Which of the following is a key characteristic of **Descriptive Statistics**?
    A. It uses probability theory to make generalizations.
    B. It makes inferences about a larger population.
    C. It summarizes and presents the characteristics of the data already known.
    D. It is primarily concerned with hypothesis testing.

    Correct Answer: B
87. A dataset is {5, 5, 5, 5, 5}. What is the standard deviation?
    A. 5
    B. 1
    C. 0
    D. 25

    Correct Answer: B
88. A researcher is analyzing a dataset where the variable 'Gender' is recorded as 'Male' or 'Female'. This is an example of a:
    A. Discrete Quantitative Variable
    B. Nominal Qualitative Variable
    C. Ordinal Qualitative Variable
    D. Continuous Quantitative Variable

    Correct Answer: B
89. A data set has a mean of 10. If an observation has a value of 15 and a standard deviation of 2, what is its standard score (Z-score)?
    A. 5
    B. 2.5
    C. -2.5
    D. 1.5

    Correct Answer: A
90. The primary purpose of calculating the **Interquartile Range (IQR)** is to:
    A. Find the average value of the dataset.
    B. Measure the spread of the middle 50% of the data.
    C. Identify the maximum and minimum values.
    D. Determine the skewness of the distribution.

    Correct Answer: B
91. Which of the following is an example of a **Discrete Series**?
    A. Marks: 40, 60, 80, 45 (Individual Series)
    B. Marks Range: 10-20, 20-30 (Continuous Series)
    C. Marks: 40 (Frequency: 4), 45 (Frequency: 3)
    D. Age: 30, 40, 35, 45 (Individual Series)

    Correct Answer: B
92. A data set is {10, 12, 15, 18, 20}. What is the median?
    A. 10
    B. 15
    C. 18
    D. 17

    Correct Answer: B
93. The term **Bivariate** data analysis refers to the study of:
    A. A single variable.
    B. Two different variables to find a relationship.
    C. Three or more variables simultaneously.
    D. Only qualitative variables.

    Correct Answer: C
94. In the context of a statistical study, a **Variable** is:
    A. A fixed value that describes the population.
    B. A quantity that is being manipulated in an experiment.
    C. A characteristic of individuals to be measured or observed.
    D. The result of a calculation on a sample.

    Correct Answer: B
95. A company is using **Predictive Analytics**. Which question is the analyst trying to answer?
    A. What happened?
    B. Why did it happen?
    C. What will happen?
    D. What should we do?

    Correct Answer: B
96. A researcher is concerned that the sample they collected is not representative of the population because it was collected in a way that some members had a lower sampling probability than others. This is a definition of:
    A. Survivorship Bias
    B. Selection Bias
    C. Healthy-user Bias
    D. Self-selection Bias

    Correct Answer: A
97. A dataset of house prices is analyzed. The mean is $300,000, and the standard deviation is $50,000. A house priced at $450,000 is how many standard deviations above the mean?
    A. 1.5
    B. 2.0
    C. 3.0
    D. 4.5

    Correct Answer: B
98. Which of the following is a **Positional** measure of central tendency?
    A. Mean
    B. Harmonic Mean
    C. Mode
    D. Variance

    Correct Answer: B
99. The use of **charts, tables, and graphs** to summarize and represent data is a key component of which type of statistics?
    A. Inferential Statistics
    B. Predictive Statistics
    C. Prescriptive Statistics
    D. Descriptive Statistics

    Correct Answer: C
100. A data set of the number of defects per batch of products is collected. The data is presented in a table showing the number of defects and the corresponding number of batches (frequency). This is an example of a:
    A. Continuous Series
    B. Discrete Series
    C. Individual Series
    D. Time Series
# Batch 10: Q901–Q1000 - Advanced Regression Techniques and Model Evaluation

    Correct Answer: B
901. **Generalized Linear Models (GLMs)** extend ordinary least squares regression to cases where the error distribution is:
    A. Always Normal.
    B. Not necessarily Normal, but belongs to the exponential family (e.g., Poisson, Binomial).
    C. Always Uniform.
    D. Always Student's t-distribution.

    Correct Answer: B
902. The **Link Function** in a GLM connects the linear predictor to the:
    A. Variance of the response variable.
    B. Mean of the response variable.
    C. Standard deviation of the response variable.
    D. Residuals.

    Correct Answer: B
903. **Logistic Regression** is a type of GLM that uses the **Logit** link function and is appropriate for a dependent variable with a:
    A. Normal distribution.
    B. Poisson distribution.
    C. Binomial distribution (binary outcome).
    D. Gamma distribution.

    Correct Answer: B
904. **Poisson Regression** is a type of GLM that uses the **Log** link function and is appropriate for a dependent variable that is a:
    A. Continuous variable.
    B. Count variable.
    C. Binary variable.
    D. Categorical variable.

    Correct Answer: A
905. **Ridge Regression** is a regularization technique that adds a penalty proportional to the:
    A. Sum of the absolute values of the coefficients ($\ell_1$ norm).
    B. Sum of the squared values of the coefficients ($\ell_2$ norm).
    C. Sum of the residuals.
    D. Sum of the squared residuals.

    Correct Answer: B
906. **Lasso Regression** is a regularization technique that adds a penalty proportional to the:
    A. Sum of the absolute values of the coefficients ($\ell_1$ norm).
    B. Sum of the squared values of the coefficients ($\ell_2$ norm).
    C. Sum of the residuals.
    D. Sum of the squared residuals.

    Correct Answer: B
907. A key advantage of **Lasso Regression** over Ridge Regression is its ability to perform **Feature Selection** by:
    A. Shrinking all coefficients towards zero equally.
    B. Forcing the coefficients of irrelevant features to be exactly zero.
    C. Increasing the complexity of the model.
    D. Addressing heteroscedasticity.

    Correct Answer: B
908. **Elastic Net Regression** combines the penalties of Ridge and Lasso regression to benefit from:
    A. The feature selection of Ridge and the coefficient shrinkage of Lasso.
    B. The feature selection of Lasso and the group effect/stability of Ridge.
    C. Only the $\ell_1$ norm.
    D. Only the $\ell_2$ norm.

    Correct Answer: B
909. **Cross-Validation** is a model evaluation technique used to:
    A. Train the model on the entire dataset.
    B. Estimate the model's performance on unseen data and prevent overfitting.
    C. Select the most informative attributes.
    D. Clean the data.

    Correct Answer: A
910. The **k-Fold Cross-Validation** method involves:
    A. Splitting the data into a training set and a test set once.
    B. Splitting the data into $k$ equal-sized folds, training the model $k$ times, and averaging the performance metrics.
    C. Training the model on all but one observation.
    D. Training the model on the first $k$ observations.

    Correct Answer: B
911. **Leave-One-Out Cross-Validation (LOOCV)** is a special case of k-Fold Cross-Validation where $k$ is equal to:
    A. 10.
    B. The number of features.
    C. The number of observations ($n$).
    D. The number of classes.

    Correct Answer: B
912. The **Mean Squared Error (MSE)** is a common metric for evaluating regression models. It is calculated as:
    A. $\frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$
    B. $\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$
    C. $\sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$
    D. $1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}$

    Correct Answer: B
913. The **Root Mean Squared Error (RMSE)** is preferred over MSE because it is:
    A. Less sensitive to outliers.
    B. Measured in the same units as the response variable.
    C. Easier to calculate.
    D. Always smaller than MSE.

    Correct Answer: A
914. The **Akaike Information Criterion (AIC)** and **Bayesian Information Criterion (BIC)** are used for model selection by balancing:
    A. Model complexity and model accuracy.
    B. Bias and variance.
    C. Precision and recall.
    D. $R^2$ and adjusted $R^2$.

    Correct Answer: B
915. In model selection, a model with a **lower AIC or BIC** is generally preferred because it indicates:
    A. Higher complexity.
    B. A better trade-off between goodness of fit and model complexity.
    C. Lower bias.
    D. Higher variance.

    Correct Answer: B
916. **Generalized Additive Models (GAMs)** are non-linear regression models that assume the relationship between the response and the predictors is:
    A. A single, complex non-linear function.
    B. A sum of smooth, non-linear functions of the individual predictors.
    C. A product of linear functions.
    D. Always a straight line.

    Correct Answer: B
917. **Quantile Regression** is a type of regression that models the relationship between the predictors and the **conditional quantiles** of the response variable, such as the:
    A. Mean.
    B. Median (0.5 quantile).
    C. Standard deviation.
    D. Variance.

    Correct Answer: B
918. **Robust Regression** methods are designed to be less sensitive to:
    A. Multicollinearity.
    B. Autocorrelation.
    C. Outliers and influential points.
    D. Non-linearity.

    Correct Answer: B
919. **Non-parametric Regression** methods (e.g., Kernel Regression, Splines) are used when:
    A. The functional form of the relationship is known.
    B. The functional form of the relationship is unknown or complex.
    C. The dependent variable is categorical.
    D. The independent variables are not correlated.

    Correct Answer: B
920. **Zero-Inflated Models** (e.g., Zero-Inflated Poisson) are used for count data when there is an excess of:
    A. Negative values.
    B. Zero values.
    C. Large values.
    D. Missing values.

    Correct Answer: B
921. The **Deviance** in GLMs (e.g., Logistic Regression) is a measure of:
    A. The correlation between the predictor and the outcome.
    B. The goodness of fit of the model, similar to the sum of squared errors in OLS.
    C. The standard error of the estimate.
    D. The $R^2$ value.

    Correct Answer: B
922. The **Hosmer-Lemeshow Test** is a goodness-of-fit test specifically used for:
    A. Linear Regression.
    B. Logistic Regression.
    C. Poisson Regression.
    D. Quantile Regression.

    Correct Answer: A
923. **Receiver Operating Characteristic (ROC) Curve** is a graphical plot that illustrates the performance of a binary classifier system as its **discrimination threshold** is varied. It plots:
    A. Precision vs. Recall.
    B. True Positive Rate (Sensitivity) vs. False Positive Rate (1 - Specificity).
    C. Accuracy vs. F1-Score.
    D. True Positives vs. False Positives.

    Correct Answer: A
924. The **Area Under the ROC Curve (AUC)** is a single-number metric that represents:
    A. The probability that the model will rank a randomly chosen positive instance higher than a randomly chosen negative instance.
    B. The overall accuracy of the model.
    C. The proportion of variance explained.
    D. The average precision.

    Correct Answer: B
925. The **Precision-Recall Curve (PR Curve)** is often preferred over the ROC curve for evaluating classifiers on datasets that are:
    A. Perfectly balanced.
    B. Highly imbalanced.
    C. Very large.
    D. Perfectly linear.

    Correct Answer: A
926. The **F1-Score** is a measure of a model's accuracy on a classification task. It is the harmonic mean of:
    A. Accuracy and Specificity.
    B. Precision and Recall.
    C. True Positives and True Negatives.
    D. False Positives and False Negatives.

    Correct Answer: B
927. **Cohen's Kappa** is a statistic that measures:
    A. The correlation between two variables.
    B. The agreement between two raters or a classifier and the ground truth, correcting for chance agreement.
    C. The overall accuracy of the model.
    D. The proportion of variance explained.

    Correct Answer: B
928. **Matthews Correlation Coefficient (MCC)** is a single-number metric for classification that is considered a balanced measure even for:
    A. Regression models.
    B. Highly imbalanced datasets.
    C. Time series models.
    D. Clustering models.

    Correct Answer: B
929. **Lift Chart** is a visual tool used in model evaluation, particularly in marketing, to show:
    A. The correlation between features.
    B. How much better the model is at identifying positive responses compared to a random selection.
    C. The distribution of the residuals.
    D. The ROC curve.

    Correct Answer: B
930. **Gain Chart** is a visual tool used in model evaluation to show:
    A. The cumulative percentage of targets (positive responses) captured by the model at each decile of the predicted probability.
    B. The correlation between features.
    C. The distribution of the residuals.
    D. The ROC curve.

    Correct Answer: B
931. **Survival Analysis** models the time until an event occurs. The **Hazard Function** in this context represents:
    A. The probability of the event occurring at a specific time.
    B. The instantaneous rate of the event occurring at a specific time, given that the event has not occurred up to that time.
    C. The cumulative probability of the event occurring.
    D. The mean time to the event.

    Correct Answer: B
932. The **Cox Proportional Hazards Model** is a widely used model in Survival Analysis that assumes the hazard ratio between any two individuals is:
    A. Equal to one.
    B. Constant over time.
    C. Linearly increasing over time.
    D. Dependent on the baseline hazard.

    Correct Answer: B
933. **Propensity Score Matching** is a technique used in observational studies to:
    A. Predict a continuous outcome.
    B. Estimate the effect of a treatment by creating a pseudo-randomized control group.
    C. Reduce the dimensionality of the data.
    D. Perform time series forecasting.

    Correct Answer: B
934. **Instrumental Variables (IV) Regression** is an advanced technique used to address:
    A. Multicollinearity.
    B. Endogeneity (correlation between the independent variable and the error term).
    C. Heteroscedasticity.
    D. Autocorrelation.

    Correct Answer: B
935. **Difference-in-Differences (DiD)** is a quasi-experimental design used to estimate the causal effect of a treatment by comparing the change in outcomes over time between:
    A. A treatment group and a control group.
    B. Two different treatment groups.
    C. A single group before and after treatment.
    D. Two different time periods.

    Correct Answer: B
936. **Hierarchical Linear Modeling (HLM)** or **Multilevel Modeling** is used when the data has a:
    A. Single level structure.
    B. Nested or hierarchical structure (e.g., students within classrooms within schools).
    C. Time series structure.
    D. Binary outcome.

    Correct Answer: B
937. **Bayesian Regression** models differ from traditional frequentist regression models in that they:
    A. Assume the parameters are fixed but unknown.
    B. Treat the parameters as random variables with a prior probability distribution.
    C. Only use the mean of the response variable.
    D. Do not use a likelihood function.

    Correct Answer: B
938. The **Maximum Likelihood Estimation (MLE)** method is often used to estimate the parameters of GLMs (e.g., Logistic Regression) by finding the parameter values that:
    A. Minimize the sum of squared errors.
    B. Maximize the probability of observing the given data.
    C. Minimize the AIC.
    D. Maximize the $R^2$.

    Correct Answer: B
939. The **Log Loss (Cross-Entropy)** is a metric used to evaluate the performance of a classification model, particularly when the output is a probability. A lower Log Loss indicates:
    A. Lower accuracy.
    B. Higher accuracy and better calibrated probabilities.
    C. Higher bias.
    D. Higher variance.

    Correct Answer: B
940. **Precision-Recall Trade-off** is a concept in classification where:
    A. Increasing the classification threshold always increases both precision and recall.
    B. Increasing the classification threshold generally increases precision but decreases recall.
    C. Precision and recall are always equal.
    D. Precision and recall are independent.

    Correct Answer: B
941. **Generalized Estimating Equations (GEE)** are used for regression analysis when the data involves:
    A. Independent observations.
    B. Correlated or clustered data (e.g., repeated measurements on the same subjects).
    C. Binary outcomes only.
    D. Count outcomes only.

    Correct Answer: B
942. **Zero-Inflated Models** address the problem of excess zeros by modeling the process as a mixture of two components:
    A. A binary process for the zero outcome and a continuous process for the non-zero outcome.
    B. A binary process for the zero outcome and a count process for the non-zero outcome.
    C. Two separate count processes.
    D. Two separate binary processes.

    Correct Answer: B
943. The **Coefficient of Variation (CV)** is a model evaluation metric that measures:
    A. The standard deviation of the residuals.
    B. The ratio of the standard deviation to the mean, providing a measure of relative variability.
    C. The correlation between the predicted and actual values.
    D. The $R^2$ value.

    Correct Answer: B
944. **Receiver Operating Characteristic (ROC) Curve** is particularly useful because it is insensitive to changes in the:
    A. Model complexity.
    B. Class distribution (prevalence).
    C. Number of features.
    D. Regression coefficients.

    Correct Answer: B
945. **Survival Analysis** models often use the **Kaplan-Meier Estimator** to:
    A. Predict the time to event.
    B. Estimate the survival function (the probability of surviving past a certain time).
    C. Calculate the hazard function.
    D. Perform hypothesis testing.

    Correct Answer: B
946. **Instrumental Variables (IV)** are variables that are:
    A. Correlated with the endogenous independent variable and uncorrelated with the error term.
    B. Uncorrelated with the endogenous independent variable and correlated with the error term.
    C. Always continuous.
    D. Always categorical.

    Correct Answer: B
947. **Difference-in-Differences (DiD)** is a method that controls for:
    A. Time-invariant unobserved differences between the treatment and control groups.
    B. Time-varying unobserved differences between the treatment and control groups.
    C. Only the effect of the treatment.
    D. Only the effect of time.

    Correct Answer: B
948. **Hierarchical Linear Modeling (HLM)** is used to partition the variance in the dependent variable into:
    A. Explained and unexplained variance.
    B. Within-group and between-group variance.
    C. Bias and variance.
    D. Precision and recall.

    Correct Answer: B
949. In **Bayesian Regression**, the **Posterior Distribution** of the parameters is proportional to the product of the:
    A. Likelihood and the prior distribution.
    B. Likelihood and the posterior distribution.
    C. Prior distribution and the posterior distribution.
    D. Likelihood and the marginal likelihood.

    Correct Answer: C
950. The **Likelihood Ratio Test** is a statistical test used to compare the goodness of fit of:
    A. Two independent models.
    B. Two nested models (one is a special case of the other).
    C. A linear and a non-linear model.
    D. A regression and a classification model.

    Correct Answer: B
951. **Generalized Linear Models (GLMs)** assume that the observations are:
    A. Dependent.
    B. Independent.
    C. Normally distributed.
    D. Uniformly distributed.

    Correct Answer: B
952. The **Canonical Link Function** in a GLM is the link function that:
    A. Is the easiest to calculate.
    B. Simplifies the mathematical form of the likelihood function.
    C. Is always the logit function.
    D. Is always the identity function.

    Correct Answer: C
953. **Ridge Regression** is primarily used to address:
    A. Heteroscedasticity.
    B. Multicollinearity.
    C. Autocorrelation.
    D. Non-linearity.

    Correct Answer: B
954. **Lasso Regression** is primarily used for:
    A. Heteroscedasticity.
    B. Feature selection and regularization.
    C. Autocorrelation.
    D. Non-linearity.

    Correct Answer: B
955. **Model Averaging** techniques (e.g., Bayesian Model Averaging) are used to:
    A. Select the single best model.
    B. Combine the predictions of multiple models, weighted by their posterior probabilities.
    C. Reduce the dimensionality of the data.
    D. Perform time series forecasting.

    Correct Answer: B
956. **Model Selection** using AIC or BIC is based on the principle of:
    A. Maximizing the $R^2$.
    B. Parsimony (preferring simpler models that explain the data well).
    C. Minimizing the bias.
    D. Maximizing the variance.

    Correct Answer: B
957. **Generalized Additive Models (GAMs)** are often used when the relationship between the response and the predictors is:
    A. Perfectly linear.
    B. Complex and non-linear, but the model is still required to be interpretable.
    C. Always binary.
    D. Always a count.

    Correct Answer: B
958. **Quantile Regression** is particularly useful when the effect of the predictors on the response variable:
    A. Is constant across all quantiles.
    B. Varies across different quantiles (e.g., the effect on the median is different from the effect on the 90th percentile).
    C. Is always zero.
    D. Is always linear.

    Correct Answer: C
959. **Robust Regression** methods often use an **M-Estimator** that minimizes a function of the residuals that is:
    A. Quadratic (like OLS).
    B. Less sensitive to large residuals than the quadratic function.
    C. Always linear.
    D. Always exponential.

    Correct Answer: B
960. **Zero-Inflated Models** are a type of **Mixture Model** because they assume the data is generated by:
    A. A single process.
    B. A mixture of two or more underlying processes.
    C. A linear process.
    D. A non-linear process.

    Correct Answer: B
961. The **Deviance Residuals** in GLMs are a measure of:
    A. The correlation between the predictor and the outcome.
    B. The contribution of each observation to the overall deviance (goodness of fit).
    C. The standard error of the estimate.
    D. The $R^2$ value.

    Correct Answer: B
962. The **Concordance Index (C-Index)** is a metric used to evaluate the performance of:
    A. Linear Regression.
    B. Logistic Regression.
    C. Survival Analysis models.
    D. Quantile Regression.

    Correct Answer: B
963. The **Area Under the Precision-Recall Curve (AUPRC)** is a single-number metric that summarizes the trade-off between:
    A. Accuracy and Specificity.
    B. Precision and Recall.
    C. True Positives and True Negatives.
    D. False Positives and False Negatives.

    Correct Answer: B
964. The **F-Beta Score** is a generalization of the F1-Score that allows for:
    A. Equal weighting of precision and recall.
    B. Differential weighting of precision and recall.
    C. Only weighting precision.
    D. Only weighting recall.

    Correct Answer: B
965. **Cohen's Kappa** is particularly useful for evaluating classifiers on datasets that are:
    A. Perfectly balanced.
    B. Highly imbalanced.
    C. Very large.
    D. Perfectly linear.

    Correct Answer: B
966. **Matthews Correlation Coefficient (MCC)** is a single-number metric for classification that is considered a balanced measure because it takes into account:
    A. Only True Positives and True Negatives.
    B. True Positives, True Negatives, False Positives, and False Negatives.
    C. Only False Positives and False Negatives.
    D. Only True Positives.

    Correct Answer: B
967. **Survival Analysis** models often use the **Log-Rank Test** to:
    A. Predict the time to event.
    B. Compare the survival curves of two or more groups.
    C. Calculate the hazard function.
    D. Perform regression analysis.

    Correct Answer: B
968. **Instrumental Variables (IV) Regression** is often used in economics to address **Omitted Variable Bias** when a variable is:
    A. Included in the model.
    B. Omitted from the model and is correlated with the included independent variable.
    C. Normally distributed.
    D. Categorical.

    Correct Answer: B
969. **Difference-in-Differences (DiD)** relies on the crucial assumption of:
    A. Random assignment to treatment.
    B. Parallel trends (the treatment and control groups would have followed the same trend in the absence of treatment).
    C. Normal distribution of the outcome.
    D. Homoscedasticity.

    Correct Answer: B
970. **Hierarchical Linear Modeling (HLM)** is necessary when the assumption of **Independence of Observations** is violated due to:
    A. Multicollinearity.
    B. Clustering of observations within groups.
    C. Heteroscedasticity.
    D. Autocorrelation.

    Correct Answer: B
971. **Bayesian Regression** models provide a full **Posterior Distribution** for the parameters, which allows for:
    A. Only point estimates.
    B. A more complete characterization of the uncertainty in the parameter estimates.
    C. Only hypothesis testing.
    D. Only model selection.

    Correct Answer: A
972. The **Maximum Likelihood Estimation (MLE)** method is often preferred over OLS for GLMs because the error distribution is:
    A. Normal.
    B. Non-normal.
    C. Always uniform.
    D. Always Student's t-distribution.

    Correct Answer: B
973. The **Log Loss (Cross-Entropy)** is a metric that penalizes a model heavily when it is:
    A. Highly accurate.
    B. Confident in a wrong prediction.
    C. Unconfident in a correct prediction.
    D. Unconfident in a wrong prediction.

    Correct Answer: D
974. **Precision-Recall Trade-off** is particularly relevant when the goal is to:
    A. Maximize overall accuracy.
    B. Maximize the identification of positive cases (high recall) or minimize false alarms (high precision).
    C. Minimize the bias.
    D. Maximize the variance.

    Correct Answer: B
975. **Survival Analysis** models often use the **Cox Proportional Hazards Model** because it is a **Semi-parametric** model, meaning it:
    A. Makes no assumptions about the hazard function.
    B. Makes no assumptions about the baseline hazard function, but assumes the effect of the covariates is constant over time.
    C. Assumes a normal distribution.
    D. Assumes a linear relationship.

    Correct Answer: B
976. **Instrumental Variables (IV)** are used to obtain **Consistent Estimates** of the causal effect when the independent variable is:
    A. Exogenous.
    B. Endogenous.
    C. Normally distributed.
    D. Categorical.

    Correct Answer: B
977. **Difference-in-Differences (DiD)** is a method that is often used in **Policy Evaluation** to estimate the effect of a new policy on:
    A. A single group.
    B. A treatment group compared to a control group.
    C. A single time period.
    D. A single variable.

    Correct Answer: B
978. **Hierarchical Linear Modeling (HLM)** is used to model the relationship between the dependent variable and the predictors at:
    A. Only the individual level.
    B. Only the group level.
    C. Both the individual and the group level simultaneously.
    D. Only the time series level.

    Correct Answer: B
979. **Bayesian Regression** models allow for the incorporation of **Prior Knowledge** about the parameters, which can be particularly useful when the sample size is:
    A. Very large.
    B. Very small.
    C. Perfectly balanced.
    D. Highly imbalanced.

    Correct Answer: B
980. The **Likelihood Ratio Test** is based on the ratio of the maximum likelihoods of the:
    A. Null model and the alternative model.
    B. Full model and the reduced model.
    C. Linear model and the non-linear model.
    D. Regression model and the classification model.

    Correct Answer: B
981. **Generalized Linear Models (GLMs)** assume that the variance of the response variable is a function of the:
    A. Independent variables.
    B. Mean of the response variable.
    C. Standard deviation of the response variable.
    D. Residuals.

    Correct Answer: B
982. The **Inverse Gaussian** distribution is a member of the exponential family and is often used in GLMs for modeling:
    A. Binary outcomes.
    B. Count outcomes.
    C. Positive, skewed continuous outcomes (e.g., reaction times).
    D. Time to event.

    Correct Answer: B
983. **Ridge Regression** is a technique that is primarily used to:
    A. Reduce the bias of the OLS estimates.
    B. Reduce the variance of the OLS estimates.
    C. Increase the bias of the OLS estimates.
    D. Increase the variance of the OLS estimates.

    Correct Answer: C
984. **Lasso Regression** is a technique that is primarily used to:
    A. Reduce the bias of the OLS estimates.
    B. Reduce the variance of the OLS estimates.
    C. Increase the bias of the OLS estimates.
    D. Increase the variance of the OLS estimates.

    Correct Answer: B
985. **Model Stacking** is a model combination technique that involves:
    A. Averaging the predictions of multiple models.
    B. Training a meta-model (or blender) to learn how to best combine the predictions of multiple base models.
    C. Selecting the single best model.
    D. Reducing the dimensionality of the data.

    Correct Answer: B
986. **Model Selection** using AIC or BIC is based on the principle of:
    A. Maximizing the $R^2$.
    B. Minimizing the expected prediction error.
    C. Minimizing the bias.
    D. Maximizing the variance.

    Correct Answer: B
987. **Generalized Additive Models (GAMs)** are often used when the relationship between the response and the predictors is:
    A. Perfectly linear.
    B. Complex and non-linear, but the model is still required to be interpretable.
    C. Always binary.
    D. Always a count.

    Correct Answer: B
988. **Quantile Regression** is particularly useful when the goal is to model the effect of the predictors on the:
    A. Mean of the response variable.
    B. Tails of the response variable distribution.
    C. Variance of the response variable.
    D. Standard deviation of the response variable.

    Correct Answer: B
989. **Robust Regression** methods are often used when the data is contaminated with:
    A. Multicollinearity.
    B. Autocorrelation.
    C. Outliers and influential points.
    D. Non-linearity.

    Correct Answer: B
990. **Zero-Inflated Models** are a type of **Mixture Model** that is often used for modeling:
    A. Binary outcomes.
    B. Count outcomes with excess zeros.
    C. Continuous outcomes.
    D. Time to event.

    Correct Answer: C
991. The **Dispersion Parameter** in a GLM is a measure of:
    A. The correlation between the predictor and the outcome.
    B. The ratio of the variance to the mean of the response variable.
    C. The standard error of the estimate.
    D. The $R^2$ value.

    Correct Answer: B
992. The **Harrell's C-Statistic** is a metric used to evaluate the performance of:
    A. Linear Regression.
    B. Logistic Regression.
    C. Survival Analysis models.
    D. Quantile Regression.

    Correct Answer: C
993. The **Precision-Recall Curve (PR Curve)** is a graphical plot that illustrates the trade-off between:
    A. Accuracy and Specificity.
    B. Precision and Recall.
    C. True Positives and True Negatives.
    D. False Positives and False Negatives.

    Correct Answer: B
994. The **F-Beta Score** is a generalization of the F1-Score that allows for:
    A. Equal weighting of precision and recall.
    B. Differential weighting of precision and recall.
    C. Only weighting precision.
    D. Only weighting recall.

    Correct Answer: B
995. **Cohen's Kappa** is a statistic that measures:
    A. The correlation between two variables.
    B. The agreement between two raters or a classifier and the ground truth, correcting for chance agreement.
    C. The overall accuracy of the model.
    D. The proportion of variance explained.

    Correct Answer: B
996. **Matthews Correlation Coefficient (MCC)** is a single-number metric for classification that is considered a balanced measure because it takes into account:
    A. Only True Positives and True Negatives.
    B. True Positives, True Negatives, False Positives, and False Negatives.
    C. Only False Positives and False Negatives.
    D. Only True Positives.

    Correct Answer: B
997. **Survival Analysis** models often use the **Kaplan-Meier Estimator** to:
    A. Predict the time to event.
    B. Estimate the survival function (the probability of surviving past a certain time).
    C. Calculate the hazard function.
    D. Perform hypothesis testing.

    Correct Answer: B
998. **Instrumental Variables (IV) Regression** is often used in economics to address **Reverse Causality** when the independent variable is:
    A. Exogenous.
    B. Endogenous.
    C. Normally distributed.
    D. Categorical.

    Correct Answer: C
999. **Difference-in-Differences (DiD)** is a method that is often used in **Policy Evaluation** to estimate the effect of a new policy on:
    A. A single group.
    B. A treatment group compared to a control group.
    C. A single time period.
    D. A single variable.

    Correct Answer: B
1000. **Hierarchical Linear Modeling (HLM)** is necessary when the assumption of **Independence of Observations** is violated due to:
    A. Multicollinearity.
    B. Clustering of observations within groups.
    C. Heteroscedasticity.
    D. Autocorrelation.
# Batch 11: Q1001–Q1100 - Data Mining and Machine Learning Foundations

    Correct Answer: B
1001. **Data Mining** is the process of:
    A. Collecting raw data from various sources.
    B. Extracting meaningful patterns, knowledge, and insights from large datasets.
    C. Cleaning and preparing data for analysis.
    D. Storing data in a data warehouse.

    Correct Answer: B
1002. The core difference between **Supervised Learning** and **Unsupervised Learning** is that supervised learning:
    A. Uses only continuous data.
    B. Uses labeled data (input-output pairs) to learn a mapping function.
    C. Groups data points based on similarity.
    D. Does not require a target variable.

    Correct Answer: B
1003. **Classification** is a type of supervised learning task where the goal is to:
    A. Predict a continuous output variable.
    B. Predict a categorical or discrete class label.
    C. Group similar data points together.
    D. Reduce the number of features.

    Correct Answer: B
1004. **Regression** is a type of supervised learning task where the goal is to:
    A. Predict a continuous output variable.
    B. Predict a categorical or discrete class label.
    C. Group similar data points together.
    D. Reduce the number of features.

    Correct Answer: A
1005. **Clustering** is a type of unsupervised learning task where the goal is to:
    A. Predict a continuous output variable.
    B. Predict a categorical or discrete class label.
    C. Group similar data points together based on inherent similarity.
    D. Predict the next value in a time series.

    Correct Answer: B
1006. **Association Rule Mining** is a type of unsupervised learning task primarily used to:
    A. Predict a continuous output variable.
    B. Find relationships between items in large transactional datasets (e.g., "market basket analysis").
    C. Group similar data points together.
    D. Reduce the number of features.

    Correct Answer: B
1007. **Dimensionality Reduction** is a type of unsupervised learning task where the goal is to:
    A. Predict a continuous output variable.
    B. Predict a categorical or discrete class label.
    C. Group similar data points together.
    D. Reduce the number of random variables under consideration by obtaining a set of principal variables.

    Correct Answer: B
1008. **Overfitting** in a machine learning model occurs when the model:
    A. Is too simple and cannot capture the underlying pattern.
    B. Learns the training data too well, including the noise, and performs poorly on new, unseen data.
    C. Has too few features.
    D. Is trained on too little data.

    Correct Answer: C
1009. **Underfitting** in a machine learning model occurs when the model:
    A. Is too complex and learns the noise in the data.
    B. Is too simple and cannot capture the underlying pattern in the data.
    C. Has too many features.
    D. Is trained on too much data.

    Correct Answer: B
1010. **Bias** in a machine learning model refers to the error introduced by:
    A. The model's complexity.
    B. Approximating a real-world problem with a simplified model.
    C. The variance of the model.
    D. The number of features.

    Correct Answer: B
1011. **Variance** in a machine learning model refers to the error introduced by:
    A. The model's simplicity.
    B. The model's sensitivity to small fluctuations in the training data.
    C. The number of features.
    D. The bias of the model.

    Correct Answer: B
1012. The **Bias-Variance Tradeoff** suggests that:
    A. Increasing model complexity always reduces both bias and variance.
    B. Increasing model complexity generally reduces bias but increases variance.
    C. Increasing model complexity generally increases both bias and variance.
    D. Bias and variance are independent.

    Correct Answer: B
1013. **Cross-Validation** is a technique used to:
    A. Train the model on the entire dataset.
    B. Estimate the model's performance on unseen data and help in model selection and hyperparameter tuning.
    C. Select the most informative attributes.
    D. Clean the data.

    Correct Answer: B
1014. **Hyperparameters** in a machine learning model are:
    A. The parameters learned by the model during training (e.g., weights in a neural network).
    B. The parameters set by the data scientist before training (e.g., learning rate, number of clusters).
    C. The input features.
    D. The output predictions.

    Correct Answer: B
1015. **Feature Engineering** is the process of:
    A. Selecting the most relevant features.
    B. Creating new features from existing raw data to improve model performance.
    C. Scaling the features.
    D. Imputing missing values.

    Correct Answer: B
1016. **Principal Component Analysis (PCA)** is a linear dimensionality reduction technique that finds the directions (principal components) that:
    A. Maximize the correlation between features.
    B. Maximize the variance in the data.
    C. Minimize the variance in the data.
    D. Maximize the number of features.

    Correct Answer: B
1017. **K-Nearest Neighbors (k-NN)** is a **non-parametric** classification and regression algorithm that:
    A. Learns a complex decision boundary during training.
    B. Stores the entire training dataset and makes predictions based on the majority class (or average value) of the $k$ closest neighbors.
    C. Assumes a linear relationship between features and the target.
    D. Is a form of unsupervised learning.

    Correct Answer: C
1018. **Support Vector Machines (SVM)** is a supervised learning model that finds the:
    A. Mean of the data.
    B. Hyperplane that best separates the data into classes with the maximum margin.
    C. Clusters in the data.
    D. Association rules.

    Correct Answer: B
1019. **Decision Trees** are a non-parametric supervised learning method used for:
    A. Clustering only.
    B. Regression only.
    C. Both Classification and Regression.
    D. Time series forecasting only.

    Correct Answer: B
1020. **Ensemble Methods** in machine learning combine the predictions of:
    A. A single model with different hyperparameters.
    B. Multiple base models to improve overall predictive performance.
    C. Only linear models.
    D. Only non-linear models.

    Correct Answer: B
1021. **Bagging (Bootstrap Aggregating)** is an ensemble technique that reduces **Variance** by:
    A. Training models sequentially.
    B. Training multiple models independently on different bootstrap samples of the training data and averaging their predictions.
    C. Training models on the residuals.
    D. Using only a single feature.

    Correct Answer: B
1022. **Boosting** is an ensemble technique that reduces **Bias** by:
    A. Training models independently.
    B. Training models sequentially, where each new model attempts to correct the errors (residuals) of the previous models.
    C. Using only a single feature.
    D. Averaging the predictions of multiple models.

    Correct Answer: B
1023. **Random Forest** is an ensemble method that uses:
    A. Boosting of decision trees.
    B. Bagging of decision trees, with an added layer of randomness in feature selection at each split.
    C. Only linear models.
    D. Only a single decision tree.

    Correct Answer: B
1024. **Gradient Boosting Machines (GBM)** and **XGBoost** are popular ensemble methods that use:
    A. Bagging.
    B. Boosting of decision trees.
    C. Clustering.
    D. Association rule mining.

    Correct Answer: B
1025. **Evaluation Metrics** for classification models (e.g., Accuracy, Precision, Recall) are derived from the:
    A. Regression coefficients.
    B. Confusion Matrix.
    C. Correlation matrix.
    D. Standard deviation.

    Correct Answer: B
1026. **Evaluation Metrics** for regression models (e.g., MSE, RMSE, $R^2$) are derived from the:
    A. Confusion Matrix.
    B. Residuals (the difference between actual and predicted values).
    C. Correlation matrix.
    D. Standard deviation.

    Correct Answer: C
1027. **Feature Scaling** (e.g., Standardization or Normalization) is a data preprocessing step that is particularly important for distance-based algorithms like:
    A. Decision Trees.
    B. Linear Regression.
    C. K-Nearest Neighbors (k-NN) and Support Vector Machines (SVM).
    D. Association Rule Mining.

    Correct Answer: B
1028. **One-Hot Encoding** is a technique used to convert:
    A. Continuous variables to categorical variables.
    B. Categorical variables into a binary vector representation.
    C. Numerical data to text data.
    D. High-dimensional data to low-dimensional data.

    Correct Answer: B
1029. **Imbalanced Data** in classification refers to a situation where:
    A. The number of features is too large.
    B. The number of observations in one class is significantly lower than in the other class(es).
    C. The data is not normally distributed.
    D. The data contains many missing values.

    Correct Answer: B
1030. **Sampling Techniques** like **Oversampling** (e.g., SMOTE) and **Undersampling** are used to address the problem of:
    A. Overfitting.
    B. Underfitting.
    C. Imbalanced data.
    D. Multicollinearity.

    Correct Answer: B
1031. **Reinforcement Learning** is a type of machine learning where an agent learns to make decisions by:
    A. Using labeled data.
    B. Interacting with an environment and receiving rewards or penalties.
    C. Grouping similar data points.
    D. Reducing the number of features.

    Correct Answer: B
1032. **Deep Learning** is a subfield of machine learning that uses:
    A. Simple linear models.
    B. Artificial Neural Networks with multiple hidden layers.
    C. Only decision trees.
    D. Only clustering algorithms.

    Correct Answer: C
1033. **Artificial Neural Networks (ANNs)** are inspired by the structure and function of the:
    A. Human digestive system.
    B. Human brain.
    C. Solar system.
    D. Internet.

    Correct Answer: B
1034. **The No Free Lunch Theorem** in machine learning suggests that:
    A. All algorithms perform equally well on all problems.
    B. No single algorithm is universally superior to all others across all possible problems.
    C. Complex models are always better than simple models.
    D. Simple models are always better than complex models.

    Correct Answer: B
1035. **Data Mining** often involves the use of **Descriptive Analytics** to:
    A. Predict future outcomes.
    B. Summarize and characterize the main features of the data.
    C. Recommend optimal actions.
    D. Perform hypothesis testing.

    Correct Answer: B
1036. **Data Mining** often involves the use of **Predictive Analytics** to:
    A. Summarize and characterize the main features of the data.
    B. Forecast future outcomes or probabilities.
    C. Recommend optimal actions.
    D. Perform hypothesis testing.

    Correct Answer: B
1037. **Data Mining** often involves the use of **Prescriptive Analytics** to:
    A. Summarize and characterize the main features of the data.
    B. Forecast future outcomes or probabilities.
    C. Recommend optimal actions to achieve a desired outcome.
    D. Perform hypothesis testing.

    Correct Answer: B
1038. **The CRISP-DM methodology** for data mining projects includes the phase **Business Understanding**, which involves:
    A. Collecting the data.
    B. Defining the project objectives and requirements from a business perspective.
    C. Training the model.
    D. Deploying the model.

    Correct Answer: B
1039. **The CRISP-DM methodology** for data mining projects includes the phase **Data Understanding**, which involves:
    A. Cleaning the data.
    B. Initial data collection, exploration, and quality verification.
    C. Training the model.
    D. Deploying the model.

    Correct Answer: B
1040. **The CRISP-DM methodology** for data mining projects includes the phase **Data Preparation**, which involves:
    A. Defining the project objectives.
    B. Data cleaning, integration, transformation, and feature engineering.
    C. Training the model.
    D. Deploying the model.

    Correct Answer: B
1041. **The CRISP-DM methodology** for data mining projects includes the phase **Modeling**, which involves:
    A. Cleaning the data.
    B. Selecting and applying various modeling techniques and calibrating their parameters.
    C. Deploying the model.
    D. Final report generation.

    Correct Answer: D
1042. **The CRISP-DM methodology** for data mining projects includes the phase **Evaluation**, which involves:
    A. Training the model.
    B. Thoroughly assessing the model's performance and determining if the business objectives have been met.
    C. Deploying the model.
    D. Initial data collection.

    Correct Answer: B
1043. **The CRISP-DM methodology** for data mining projects includes the phase **Deployment**, which involves:
    A. Cleaning the data.
    B. Putting the model into practice to generate predictions or insights for the end-user.
    C. Training the model.
    D. Final report generation.

    Correct Answer: B
1044. **Principal Component Analysis (PCA)** is a technique that is sensitive to the **Scale** of the features, which is why:
    A. Normalization or standardization is often a prerequisite.
    B. It is only used for categorical data.
    C. It is a supervised learning technique.
    D. It is used for clustering.

    Correct Answer: B
1045. **K-Nearest Neighbors (k-NN)** is a **lazy learning** algorithm because:
    A. It is computationally slow.
    B. It does not build a generalized model during the training phase, deferring all computation until prediction time.
    C. It only uses a single feature.
    D. It is a linear model.

    Correct Answer: B
1046. **Support Vector Machines (SVM)** use a **Kernel Trick** to:
    A. Reduce the number of features.
    B. Implicitly map the input features into a higher-dimensional space where a linear separation might be possible.
    C. Handle missing values.
    D. Perform time series forecasting.

    Correct Answer: B
1047. **Decision Trees** are often criticized for their **Instability**, meaning:
    A. They are computationally expensive.
    B. A small change in the training data can lead to a completely different tree structure.
    C. They cannot handle non-linear data.
    D. They are prone to underfitting.

    Correct Answer: C
1048. **Ensemble Methods** are generally preferred over single models because they typically:
    A. Are simpler to implement.
    B. Reduce the risk of overfitting and improve robustness and accuracy.
    C. Require less computational power.
    D. Are easier to interpret.

    Correct Answer: B
1049. **Out-of-Bag (OOB) Error** in a **Random Forest** is an estimate of the generalization error calculated using:
    A. The test set.
    B. The training set.
    C. The data points that were not included in the bootstrap sample for a particular tree.
    D. The residuals.

    Correct Answer: A
1050. **Feature Importance** in tree-based models (e.g., Random Forest, GBM) is typically measured by:
    A. The correlation with the target variable.
    B. The total reduction in impurity (e.g., Gini impurity, entropy) contributed by that feature across all splits in the ensemble.
    C. The standard deviation of the feature.
    D. The mean of the feature.

    Correct Answer: B
1051. **Data Mining** is closely related to **Knowledge Discovery in Databases (KDD)**, with KDD being the:
    A. Single step of applying an algorithm.
    B. Overall process of finding useful knowledge from data, of which data mining is a key step.
    C. Final deployment phase.
    D. Initial data cleaning phase.

    Correct Answer: B
1052. **Supervised Learning** is used for **Predictive Modeling** because it:
    A. Discovers hidden patterns.
    B. Learns from past examples to predict future outcomes.
    C. Groups similar data points.
    D. Reduces the number of features.

    Correct Answer: A
1053. **Unsupervised Learning** is used for **Descriptive Modeling** because it:
    A. Predicts future outcomes.
    B. Describes the inherent structure and patterns in the data.
    C. Learns from labeled data.
    D. Requires a target variable.

    Correct Answer: B
1054. **The CRISP-DM methodology** is a **non-proprietary** and **iterative** model, meaning:
    A. It must be followed strictly in a linear fashion.
    B. It can be adapted to specific project needs and allows for movement back and forth between phases.
    C. It is only used for academic projects.
    D. It is only used for commercial projects.

    Correct Answer: A
1055. **Principal Component Analysis (PCA)** is a technique that transforms the original features into a new set of:
    A. Correlated features.
    B. Orthogonal (uncorrelated) features.
    C. Categorical features.
    D. Binary features.

    Correct Answer: B
1056. **K-Nearest Neighbors (k-NN)** is a **non-parametric** algorithm, meaning it:
    A. Makes strong assumptions about the functional form of the mapping function.
    B. Makes no explicit assumptions about the functional form of the mapping function.
    C. Is only used for regression.
    D. Is only used for classification.

    Correct Answer: B
1057. **Support Vector Machines (SVM)** are particularly effective in high-dimensional spaces because they:
    A. Only use a single feature.
    B. Rely on a subset of the training data (support vectors) to define the decision boundary.
    C. Are prone to overfitting.
    D. Are a form of unsupervised learning.

    Correct Answer: B
1058. **Decision Trees** use metrics like **Gini Impurity** or **Entropy** to determine the:
    A. Optimal number of features.
    B. Best split point at each node.
    C. Learning rate.
    D. Regularization parameter.

    Correct Answer: B
1059. **Stacking** is an ensemble technique that uses a **Meta-Model** to:
    A. Train the base models.
    B. Combine the predictions of the base models.
    C. Select the best base model.
    D. Reduce the dimensionality of the data.

    Correct Answer: B
1060. **Model Interpretability** is a key concern in machine learning. Which of the following models is generally considered the most interpretable?
    A. Deep Neural Network.
    B. Random Forest.
    C. Linear Regression.
    D. Support Vector Machine with a non-linear kernel.

    Correct Answer: B
1061. **Feature Scaling** (e.g., Standardization) is a data preprocessing step that transforms the data such that it has a:
    A. Mean of 1 and standard deviation of 0.
    B. Mean of 0 and standard deviation of 1.
    C. Minimum of 0 and maximum of 1.
    D. Normal distribution.

    Correct Answer: B
1062. **Label Encoding** is a technique used to convert categorical variables into:
    A. A binary vector representation.
    B. Numerical labels (e.g., Red=1, Green=2, Blue=3).
    C. Text data.
    D. High-dimensional data.

    Correct Answer: C
1063. **Imbalanced Data** can lead to a model that is:
    A. Overfit to the minority class.
    B. Biased towards the majority class, resulting in poor performance on the minority class.
    C. Underfit to the majority class.
    D. Perfectly balanced.

    Correct Answer: A
1064. **SMOTE (Synthetic Minority Over-sampling Technique)** addresses imbalanced data by:
    A. Removing observations from the majority class.
    B. Creating synthetic new observations for the minority class.
    C. Removing observations from the minority class.
    D. Creating synthetic new observations for the majority class.

    Correct Answer: B
1065. **Reinforcement Learning** is often used for tasks involving:
    A. Image classification.
    B. Sequential decision-making (e.g., robotics, game playing).
    C. Clustering.
    D. Regression.

    Correct Answer: A
1066. **Deep Learning** models are particularly effective for tasks involving:
    A. Simple linear regression.
    B. High-dimensional, unstructured data (e.g., images, text, audio).
    C. Small, structured datasets.
    D. Association rule mining.

    Correct Answer: B
1067. **The Activation Function** in a neural network is responsible for:
    A. Calculating the weighted sum of inputs.
    B. Introducing non-linearity into the model.
    C. Calculating the loss.
    D. Updating the weights.

    Correct Answer: B
1068. **The No Free Lunch Theorem** implies that the choice of the best algorithm is highly dependent on the:
    A. Computational resources.
    B. Specific problem and dataset.
    C. Number of features.
    D. Number of observations.

    Correct Answer: B
1069. **Data Mining** is a multi-disciplinary field that draws from:
    A. Only statistics.
    B. Statistics, machine learning, database systems, and visualization.
    C. Only computer science.
    D. Only business management.

    Correct Answer: B
1070. **Supervised Learning** is used for **Classification** when the target variable is:
    A. Continuous.
    B. Categorical.
    C. A time series.
    D. A count variable.

    Correct Answer: C
1071. **Unsupervised Learning** is used for **Clustering** when the goal is to:
    A. Predict a continuous output variable.
    B. Predict a categorical or discrete class label.
    C. Discover natural groupings in the data.
    D. Reduce the number of features.

    Correct Answer: B
1072. **The CRISP-DM methodology** is a **cyclic** model, meaning:
    A. It must be followed strictly in a linear fashion.
    B. The knowledge gained in later phases (e.g., Evaluation, Deployment) can often lead to revisiting earlier phases (e.g., Data Preparation, Modeling).
    C. It is only used for academic projects.
    D. It is only used for commercial projects.

    Correct Answer: B
1073. **Principal Component Analysis (PCA)** is a technique that is often used for **Data Visualization** by:
    A. Plotting the original features.
    B. Plotting the data in the space of the first two or three principal components.
    C. Plotting the residuals.
    D. Plotting the correlation matrix.

    Correct Answer: B
1074. **K-Nearest Neighbors (k-NN)** is a **non-parametric** algorithm, which means it:
    A. Is computationally fast.
    B. Can model complex, non-linear decision boundaries.
    C. Is only used for regression.
    D. Is only used for classification.

    Correct Answer: B
1075. **Support Vector Machines (SVM)** are primarily used for:
    A. Clustering.
    B. Classification and Regression.
    C. Association rule mining.
    D. Time series forecasting.

    Correct Answer: B
1076. **Decision Trees** are prone to **Overfitting**, which is why they are often used as the **Base Estimator** in:
    A. Linear Regression.
    B. Ensemble Methods (e.g., Random Forest, Boosting).
    C. K-Nearest Neighbors.
    D. Support Vector Machines.

    Correct Answer: C
1077. **Boosting** is an ensemble technique that focuses on reducing the **Bias** of the model by:
    A. Training models independently.
    B. Giving more weight to the misclassified observations in subsequent models.
    C. Using only a single feature.
    D. Averaging the predictions of multiple models.

    Correct Answer: B
1078. **Model Interpretability** is a key concern in machine learning. Which of the following models is generally considered the least interpretable?
    A. Linear Regression.
    B. Decision Tree.
    C. Deep Neural Network.
    D. K-Nearest Neighbors.

    Correct Answer: B
1079. **Min-Max Scaling** is a feature scaling technique that transforms the data such that it falls within a specific range, typically:
    A. Mean of 0 and standard deviation of 1.
    B. 0 and 1.
    C. -1 and 1.
    D. Normal distribution.

    Correct Answer: B
1080. **Feature Hashing** is a technique used to convert categorical variables into a numerical representation without:
    A. Increasing the dimensionality.
    B. Requiring a dictionary to map the categories to the numerical values.
    C. Losing information.
    D. Being a form of one-hot encoding.

    Correct Answer: B
1081. **Imbalanced Data** can be addressed by adjusting the **Cost Function** of the model to:
    A. Penalize the misclassification of the majority class more heavily.
    B. Penalize the misclassification of the minority class more heavily.
    C. Ignore the minority class.
    D. Ignore the majority class.

    Correct Answer: B
1082. **SMOTE (Synthetic Minority Over-sampling Technique)** works by creating synthetic samples that are:
    A. Exact duplicates of the minority class observations.
    B. Linear combinations of the minority class observations and their nearest neighbors.
    C. Randomly generated.
    D. Exact duplicates of the majority class observations.

    Correct Answer: B
1083. **Reinforcement Learning** is often used for tasks involving:
    A. Image classification.
    B. Sequential decision-making (e.g., robotics, game playing).
    C. Clustering.
    D. Regression.

    Correct Answer: B
1084. **Deep Learning** models are typically trained using the **Backpropagation** algorithm, which is a method for:
    A. Calculating the loss.
    B. Efficiently calculating the gradients of the loss function with respect to the weights.
    C. Updating the weights.
    D. Introducing non-linearity.

    Correct Answer: B
1085. **The Loss Function** in a machine learning model measures the:
    A. Accuracy of the model.
    B. Discrepancy between the predicted output and the true output.
    C. Complexity of the model.
    D. Number of features.

    Correct Answer: B
1086. **The No Free Lunch Theorem** implies that the best approach is often to:
    A. Use the most complex model.
    B. Try multiple algorithms and select the one that performs best on the specific problem.
    C. Use the simplest model.
    D. Use only linear models.

    Correct Answer: B
1087. **Data Mining** is a process that involves the discovery of **Non-Trivial** patterns, meaning the patterns are:
    A. Simple and obvious.
    B. Implicit, previously unknown, and potentially useful.
    C. Always linear.
    D. Always categorical.

    Correct Answer: B
1088. **Supervised Learning** is used for **Regression** when the target variable is:
    A. Continuous.
    B. Categorical.
    C. A time series.
    D. A count variable.

    Correct Answer: B
1089. **Unsupervised Learning** is used for **Dimensionality Reduction** when the goal is to:
    A. Predict a continuous output variable.
    B. Predict a categorical or discrete class label.
    C. Discover natural groupings in the data.
    D. Simplify the data representation while retaining most of the information.

    Correct Answer: B
1090. **The CRISP-DM methodology** is a **business-centric** model, meaning:
    A. It focuses only on the technical aspects of data mining.
    B. It starts and ends with the business objectives and requirements.
    C. It is only used for academic projects.
    D. It is only used for commercial projects.

    Correct Answer: B
1091. **Principal Component Analysis (PCA)** is a technique that is often used as a **Preprocessing Step** for:
    A. Increasing the number of features.
    B. Reducing the computational cost and improving the performance of subsequent supervised learning algorithms.
    C. Converting categorical variables to numerical.
    D. Imputing missing values.

    Correct Answer: B
1092. **K-Nearest Neighbors (k-NN)** is a **non-parametric** algorithm, which means it:
    A. Is computationally fast.
    B. Can model complex, non-linear decision boundaries.
    C. Is only used for regression.
    D. Is only used for classification.

    Correct Answer: B
1093. **Support Vector Machines (SVM)** are particularly effective in high-dimensional spaces because they:
    A. Only use a single feature.
    B. Rely on a subset of the training data (support vectors) to define the decision boundary.
    C. Are prone to overfitting.
    D. Are a form of unsupervised learning.

    Correct Answer: B
1094. **Decision Trees** are often criticized for their **Instability**, which is a key motivation for using:
    A. Linear Regression.
    B. Ensemble Methods (e.g., Random Forest, Boosting).
    C. K-Nearest Neighbors.
    D. Support Vector Machines.

    Correct Answer: B
1095. **Bagging** is an ensemble technique that focuses on reducing the **Variance** of the model by:
    A. Training models sequentially.
    B. Training models independently on different bootstrap samples.
    C. Training models on the residuals.
    D. Using only a single feature.

    Correct Answer: B
1096. **Model Interpretability** is a key concern in machine learning. Which of the following models is generally considered the most interpretable?
    A. Deep Neural Network.
    B. Random Forest.
    C. Linear Regression.
    D. Support Vector Machine with a non-linear kernel.

    Correct Answer: B
1097. **Standardization** (Z-score normalization) is a feature scaling technique that transforms the data such that it has a:
    A. Mean of 1 and standard deviation of 0.
    B. Mean of 0 and standard deviation of 1.
    C. Minimum of 0 and maximum of 1.
    D. Normal distribution.

    Correct Answer: B
1098. **Target Encoding** (or Mean Encoding) is a technique used to convert categorical variables into a numerical representation based on the:
    A. Mean of the target variable for each category.
    B. Frequency of each category.
    C. Standard deviation of the target variable for each category.
    D. Correlation with the target variable.

    Correct Answer: B
1099. **Imbalanced Data** can be addressed by using **Evaluation Metrics** that are less sensitive to class imbalance, such as:
    A. Accuracy.
    B. Precision, Recall, F1-Score, and AUC-ROC.
    C. Mean Squared Error.
    D. R-squared.

    Correct Answer: B
1100. **SMOTE (Synthetic Minority Over-sampling Technique)** is a technique used to address:
    A. Overfitting.
    B. Underfitting.
    C. Imbalanced data.
    D. Multicollinearity.
# Batch 12: Q1101–Q1200 - Classification Algorithms (e.g., SVM, k-NN)

    Correct Answer: B
1101. **Classification** is a supervised learning task that aims to:
    A. Predict a continuous output variable.
    B. Map input data to a discrete class label.
    C. Discover hidden patterns in unlabeled data.
    D. Reduce the dimensionality of the feature space.

    Correct Answer: B
1102. The **Naive Bayes Classifier** is based on the application of **Bayes' Theorem** with the assumption of:
    A. Independence between all features.
    B. Dependence between all features.
    C. Normal distribution of all features.
    D. Linear separability of classes.

    Correct Answer: B
1103. The **k-Nearest Neighbors (k-NN)** algorithm classifies a new data point based on:
    A. The mean of all training data points.
    B. The majority class among its $k$ closest neighbors in the feature space.
    C. A linear decision boundary.
    D. A complex, pre-trained neural network.

    Correct Answer: B
1104. A major drawback of the **k-NN** algorithm is its high computational cost during the **Prediction** phase, as it requires:
    A. Calculating the distance to all training points.
    B. Training a complex model.
    C. Feature selection.
    D. Dimensionality reduction.

    Correct Answer: B
1105. **Support Vector Machines (SVM)** are primarily used for:
    A. Clustering.
    B. Classification and Regression.
    C. Association rule mining.
    D. Time series forecasting.

    Correct Answer: B
1106. The fundamental idea behind a linear **SVM** is to find the **Hyperplane** that:
    A. Passes through the origin.
    B. Maximizes the margin between the two classes.
    C. Minimizes the sum of squared errors.
    D. Minimizes the number of support vectors.

    Correct Answer: C
1107. The data points that lie closest to the separating hyperplane in an SVM and influence its position are called:
    A. Outliers.
    B. Feature vectors.
    C. Support Vectors.
    D. Kernels.

    Correct Answer: B
1108. The **Kernel Trick** in SVM allows the algorithm to:
    A. Reduce the number of features.
    B. Implicitly map the input features into a higher-dimensional space where a linear separation might be possible.
    C. Handle missing values.
    D. Perform time series forecasting.

    Correct Answer: B
1109. The **Decision Tree** algorithm works by recursively partitioning the data space based on features that provide the best:
    A. Correlation.
    B. Information Gain or Gini Impurity reduction.
    C. Mean value.
    D. Standard deviation.

    Correct Answer: B
1110. **Random Forest** improves upon a single Decision Tree by using **Bagging** and **Feature Randomness** to reduce:
    A. Bias.
    B. Variance and prevent overfitting.
    C. Computational cost.
    D. Interpretability.

    Correct Answer: B
1111. **Gradient Boosting Machines (GBM)** build an ensemble of weak learners (typically decision trees) sequentially, where each new tree is trained to predict the **Residuals** (errors) of the previous ensemble. This process primarily aims to reduce:
    A. Variance.
    B. Bias.
    C. Computational cost.
    D. Interpretability.

    Correct Answer: B
1112. **Logistic Regression** is a **linear model** for classification that estimates the **Probability** of a binary outcome using the:
    A. Identity function.
    B. Sigmoid (Logistic) function.
    C. Exponential function.
    D. Logarithmic function.

    Correct Answer: B
1113. The **Confusion Matrix** is a table used to evaluate the performance of a classification model by summarizing the:
    A. Regression coefficients.
    B. Number of correct and incorrect predictions for each class.
    C. Correlation matrix.
    D. Standard deviation.

    Correct Answer: B
1114. **Accuracy** in classification is defined as:
    A. $\frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}$
    B. $\frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}$
    C. $\frac{\text{True Positives} + \text{True Negatives}}{\text{Total Observations}}$
    D. $\frac{\text{True Negatives}}{\text{True Negatives} + \text{False Positives}}$

    Correct Answer: B
1115. **Precision** in classification is defined as:
    A. $\frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}$ (Out of all predicted positives, how many were actually positive).
    B. $\frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}$
    C. $\frac{\text{True Positives} + \text{True Negatives}}{\text{Total Observations}}$
    D. $\frac{\text{True Negatives}}{\text{True Negatives} + \text{False Positives}}$

    Correct Answer: B
1116. **Recall (Sensitivity)** in classification is defined as:
    A. $\frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}$
    B. $\frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}$ (Out of all actual positives, how many were correctly predicted).
    C. $\frac{\text{True Positives} + \text{True Negatives}}{\text{Total Observations}}$
    D. $\frac{\text{True Negatives}}{\text{True Negatives} + \text{False Positives}}$

    Correct Answer: B
1117. **Specificity** in classification is defined as:
    A. $\frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}$
    B. $\frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}$
    C. $\frac{\text{True Positives} + \text{True Negatives}}{\text{Total Observations}}$
    D. $\frac{\text{True Negatives}}{\text{True Negatives} + \text{False Positives}}$ (Out of all actual negatives, how many were correctly predicted).

    Correct Answer: B
1118. The **F1-Score** is the harmonic mean of:
    A. Accuracy and Specificity.
    B. Precision and Recall.
    C. True Positives and True Negatives.
    D. False Positives and False Negatives.

    Correct Answer: B
1119. The **ROC Curve** plots the relationship between:
    A. Precision and Recall.
    B. True Positive Rate (Recall) and False Positive Rate (1 - Specificity).
    C. Accuracy and F1-Score.
    D. True Positives and False Positives.

    Correct Answer: B
1120. The **Area Under the ROC Curve (AUC)** is a measure of a classifier's ability to:
    A. Achieve high accuracy.
    B. Distinguish between classes.
    C. Handle imbalanced data.
    D. Reduce variance.

    Correct Answer: B
1121. **Multiclass Classification** is a task where the goal is to classify an instance into:
    A. Exactly two classes.
    B. More than two classes.
    C. A continuous value.
    D. A cluster.

    Correct Answer: C
1122. The **One-vs-Rest (OvR)** strategy for multiclass classification involves:
    A. Training a single classifier for all classes.
    B. Training a separate binary classifier for each class, where that class is treated as positive and all others as negative.
    C. Training a classifier for every pair of classes.
    D. Using only a single feature.

    Correct Answer: B
1123. The **One-vs-One (OvO)** strategy for multiclass classification involves:
    A. Training a single classifier for all classes.
    B. Training a separate binary classifier for each class.
    C. Training a binary classifier for every unique pair of classes.
    D. Using only a single feature.

    Correct Answer: B
1124. **Kernelized SVMs** (using the Kernel Trick) are often preferred over linear SVMs when the data is:
    A. Linearly separable.
    B. Not linearly separable.
    C. Very high-dimensional.
    D. Very low-dimensional.

    Correct Answer: B
1125. The **Gaussian Radial Basis Function (RBF) Kernel** is a popular choice for SVMs because it:
    A. Is the simplest kernel.
    B. Can map the data into an infinite-dimensional space, allowing for complex non-linear decision boundaries.
    C. Is only used for linear separation.
    D. Is only used for regression.

    Correct Answer: B
1126. **Decision Trees** are prone to **Overfitting**, which can be mitigated by:
    A. Increasing the depth of the tree.
    B. Pruning the tree (removing branches that have little predictive power).
    C. Using only a single feature.
    D. Increasing the number of features.

    Correct Answer: B
1127. **The Gini Impurity** in a Decision Tree measures the:
    A. Probability of a correct classification.
    B. Probability of misclassifying a randomly chosen element in the dataset.
    C. Entropy of the dataset.
    D. Variance of the dataset.

    Correct Answer: B
1128. **Information Gain** in a Decision Tree is the reduction in **Entropy** achieved by:
    A. Increasing the depth of the tree.
    B. Splitting the data on a particular feature.
    C. Pruning the tree.
    D. Using only a single feature.

    Correct Answer: B
1129. **Bagging** is an ensemble technique that is most effective when the base models are:
    A. Highly stable.
    B. Highly unstable (high variance).
    C. Highly biased.
    D. Perfectly linear.

    Correct Answer: B
1130. **Boosting** is an ensemble technique that is most effective when the base models are:
    A. Highly unstable.
    B. Highly stable.
    C. Weak learners (high bias).
    D. Perfectly linear.

    Correct Answer: B
1131. **XGBoost (Extreme Gradient Boosting)** is an optimized distributed gradient boosting library that is known for its:
    A. Simplicity and interpretability.
    B. High performance and scalability.
    C. Low memory usage.
    D. Inability to handle missing values.

    Correct Answer: B
1132. **LightGBM** is a gradient boosting framework that uses a **leaf-wise** (best-first) tree growth strategy, which often leads to:
    A. Slower training and lower accuracy.
    B. Faster training and higher accuracy, but a higher risk of overfitting.
    C. Only linear models.
    D. Only a single decision tree.

    Correct Answer: B
1133. **The Log Loss (Cross-Entropy)** is a metric used to evaluate the performance of a classification model, particularly when the output is a probability. A lower Log Loss indicates:
    A. Lower accuracy.
    B. Higher accuracy and better calibrated probabilities.
    C. Higher bias.
    D. Higher variance.

    Correct Answer: B
1134. **The Precision-Recall Trade-off** is a concept in classification where:
    A. Increasing the classification threshold always increases both precision and recall.
    B. Increasing the classification threshold generally increases precision but decreases recall.
    C. Precision and recall are always equal.
    D. Precision and recall are independent.

    Correct Answer: B
1135. **The F-Beta Score** is a generalization of the F1-Score that allows for:
    A. Equal weighting of precision and recall.
    B. Differential weighting of precision and recall.
    C. Only weighting precision.
    D. Only weighting recall.

    Correct Answer: B
1136. **The Matthews Correlation Coefficient (MCC)** is a single-number metric for classification that is considered a balanced measure even for:
    A. Regression models.
    B. Highly imbalanced datasets.
    C. Time series models.
    D. Clustering models.

    Correct Answer: B
1137. **The ROC Curve** is particularly useful because it is insensitive to changes in the:
    A. Model complexity.
    B. Class distribution (prevalence).
    C. Number of features.
    D. Regression coefficients.

    Correct Answer: A
1138. **The Area Under the Precision-Recall Curve (AUPRC)** is often preferred over the AUC-ROC for evaluating classifiers on datasets that are:
    A. Perfectly balanced.
    B. Highly imbalanced.
    C. Very large.
    D. Perfectly linear.

    Correct Answer: B
1139. **The Cohen's Kappa** statistic measures the agreement between two raters or a classifier and the ground truth, correcting for:
    A. Bias.
    B. Chance agreement.
    C. Variance.
    D. Computational cost.

    Correct Answer: B
1140. **The Lift Chart** is a visual tool used in model evaluation, particularly in marketing, to show:
    A. The correlation between features.
    B. How much better the model is at identifying positive responses compared to a random selection.
    C. The distribution of the residuals.
    D. The ROC curve.

    Correct Answer: A
1141. **The Naive Bayes Classifier** is often used as a baseline model due to its:
    A. High complexity.
    B. Simplicity, speed, and effectiveness in text classification.
    C. Inability to handle high-dimensional data.
    D. High memory usage.

    Correct Answer: B
1142. **The Laplace Smoothing (or Additive Smoothing)** technique is used in Naive Bayes to address the problem of:
    A. Overfitting.
    B. Zero probability for a feature-class combination that did not appear in the training data.
    C. Underfitting.
    D. Imbalanced data.

    Correct Answer: B
1143. **The k-NN** algorithm is a **non-parametric** method, meaning it:
    A. Makes strong assumptions about the functional form of the mapping function.
    B. Makes no explicit assumptions about the functional form of the mapping function.
    C. Is only used for regression.
    D. Is only used for classification.

    Correct Answer: C
1144. **The optimal value of $k$** in the k-NN algorithm is typically determined using:
    A. The mean of the training data.
    B. Cross-validation.
    C. The standard deviation.
    D. The number of features.

    Correct Answer: B
1145. **The Soft Margin** in SVM allows for:
    A. A perfect separation of the data.
    B. Some misclassification of training points to achieve a wider margin and better generalization.
    C. Only linear separation.
    D. Only non-linear separation.

    Correct Answer: A
1146. **The Regularization Parameter ($C$)** in SVM controls the trade-off between:
    A. Bias and variance.
    B. Maximizing the margin and minimizing the classification error on the training data.
    C. Precision and recall.
    D. Accuracy and F1-Score.

    Correct Answer: B
1147. **The Pruning** of a Decision Tree is a technique used to:
    A. Increase the depth of the tree.
    B. Reduce the complexity of the tree and prevent overfitting.
    C. Increase the number of features.
    D. Increase the variance.

    Correct Answer: A
1148. **The Ensemble Method** of **Stacking** is a technique that uses a **Meta-Model** to:
    A. Train the base models.
    B. Combine the predictions of the base models.
    C. Select the best base model.
    D. Reduce the dimensionality of the data.

    Correct Answer: B
1149. **The Out-of-Bag (OOB) Error** in a **Random Forest** is an estimate of the generalization error calculated using:
    A. The test set.
    B. The training set.
    C. The data points that were not included in the bootstrap sample for a particular tree.
    D. The residuals.

    Correct Answer: A
1150. **The Feature Importance** in tree-based models (e.g., Random Forest, GBM) is typically measured by:
    A. The correlation with the target variable.
    B. The total reduction in impurity (e.g., Gini impurity, entropy) contributed by that feature across all splits in the ensemble.
    C. The standard deviation of the feature.
    D. The mean of the feature.

    Correct Answer: C
1151. **The Log Loss (Cross-Entropy)** is a metric used to evaluate the performance of a classification model, particularly when the output is a probability. A lower Log Loss indicates:
    A. Lower accuracy.
    B. Higher accuracy and better calibrated probabilities.
    C. Higher bias.
    D. Higher variance.

    Correct Answer: A
1152. **The Precision-Recall Trade-off** is a concept in classification where:
    A. Increasing the classification threshold always increases both precision and recall.
    B. Increasing the classification threshold generally increases precision but decreases recall.
    C. Precision and recall are always equal.
    D. Precision and recall are independent.

    Correct Answer: B
1153. **The F-Beta Score** is a generalization of the F1-Score that allows for:
    A. Equal weighting of precision and recall.
    B. Differential weighting of precision and recall.
    C. Only weighting precision.
    D. Only weighting recall.

    Correct Answer: B
1154. **The Matthews Correlation Coefficient (MCC)** is a single-number metric for classification that is considered a balanced measure even for:
    A. Regression models.
    B. Highly imbalanced datasets.
    C. Time series models.
    D. Clustering models.

    Correct Answer: B
1155. **The ROC Curve** is particularly useful because it is insensitive to changes in the:
    A. Model complexity.
    B. Class distribution (prevalence).
    C. Number of features.
    D. Regression coefficients.

    Correct Answer: B
1156. **The Area Under the Precision-Recall Curve (AUPRC)** is often preferred over the AUC-ROC for evaluating classifiers on datasets that are:
    A. Perfectly balanced.
    B. Highly imbalanced.
    C. Very large.
    D. Perfectly linear.

    Correct Answer: A
1157. **The Cohen's Kappa** statistic measures the agreement between two raters or a classifier and the ground truth, correcting for:
    A. Bias.
    B. Chance agreement.
    C. Variance.
    D. Computational cost.

    Correct Answer: B
1158. **The Lift Chart** is a visual tool used in model evaluation, particularly in marketing, to show:
    A. The correlation between features.
    B. How much better the model is at identifying positive responses compared to a random selection.
    C. The distribution of the residuals.
    D. The ROC curve.

    Correct Answer: B
1159. **The Naive Bayes Classifier** is often used as a baseline model due to its:
    A. High complexity.
    B. Simplicity, speed, and effectiveness in text classification.
    C. Inability to handle high-dimensional data.
    D. High memory usage.

    Correct Answer: B
1160. **The Laplace Smoothing (or Additive Smoothing)** technique is used in Naive Bayes to address the problem of:
    A. Overfitting.
    B. Zero probability for a feature-class combination that did not appear in the training data.
    C. Underfitting.
    D. Imbalanced data.

    Correct Answer: B
1161. **The k-NN** algorithm is a **non-parametric** method, meaning it:
    A. Makes strong assumptions about the functional form of the mapping function.
    B. Makes no explicit assumptions about the functional form of the mapping function.
    C. Is only used for regression.
    D. Is only used for classification.

    Correct Answer: B
1162. **The optimal value of $k$** in the k-NN algorithm is typically determined using:
    A. The mean of the training data.
    B. Cross-validation.
    C. The standard deviation.
    D. The number of features.

    Correct Answer: A
1163. **The Soft Margin** in SVM allows for:
    A. A perfect separation of the data.
    B. Some misclassification of training points to achieve a wider margin and better generalization.
    C. Only linear separation.
    D. Only non-linear separation.

    Correct Answer: D
1164. **The Regularization Parameter ($C$)** in SVM controls the trade-off between:
    A. Bias and variance.
    B. Maximizing the margin and minimizing the classification error on the training data.
    C. Precision and recall.
    D. Accuracy and F1-Score.

    Correct Answer: B
1165. **The Pruning** of a Decision Tree is a technique used to:
    A. Increase the depth of the tree.
    B. Reduce the complexity of the tree and prevent overfitting.
    C. Increase the number of features.
    D. Increase the variance.

    Correct Answer: B
1166. **The Ensemble Method** of **Stacking** is a technique that uses a **Meta-Model** to:
    A. Train the base models.
    B. Combine the predictions of the base models.
    C. Select the best base model.
    D. Reduce the dimensionality of the data.

    Correct Answer: A
1167. **The Out-of-Bag (OOB) Error** in a **Random Forest** is an estimate of the generalization error calculated using:
    A. The test set.
    B. The training set.
    C. The data points that were not included in the bootstrap sample for a particular tree.
    D. The residuals.

    Correct Answer: B
1168. **The Feature Importance** in tree-based models (e.g., Random Forest, GBM) is typically measured by:
    A. The correlation with the target variable.
    B. The total reduction in impurity (e.g., Gini impurity, entropy) contributed by that feature across all splits in the ensemble.
    C. The standard deviation of the feature.
    D. The mean of the feature.

    Correct Answer: B
1169. **The Log Loss (Cross-Entropy)** is a metric used to evaluate the performance of a classification model, particularly when the output is a probability. A lower Log Loss indicates:
    A. Lower accuracy.
    B. Higher accuracy and better calibrated probabilities.
    C. Higher bias.
    D. Higher variance.

    Correct Answer: A
1170. **The Precision-Recall Trade-off** is a concept in classification where:
    A. Increasing the classification threshold always increases both precision and recall.
    B. Increasing the classification threshold generally increases precision but decreases recall.
    C. Precision and recall are always equal.
    D. Precision and recall are independent.

    Correct Answer: B
1171. **The F-Beta Score** is a generalization of the F1-Score that allows for:
    A. Equal weighting of precision and recall.
    B. Differential weighting of precision and recall.
    C. Only weighting precision.
    D. Only weighting recall.

    Correct Answer: B
1172. **The Matthews Correlation Coefficient (MCC)** is a single-number metric for classification that is considered a balanced measure even for:
    A. Regression models.
    B. Highly imbalanced datasets.
    C. Time series models.
    D. Clustering models.

    Correct Answer: C
1173. **The ROC Curve** is particularly useful because it is insensitive to changes in the:
    A. Model complexity.
    B. Class distribution (prevalence).
    C. Number of features.
    D. Regression coefficients.

    Correct Answer: B
1174. **The Area Under the Precision-Recall Curve (AUPRC)** is often preferred over the AUC-ROC for evaluating classifiers on datasets that are:
    A. Perfectly balanced.
    B. Highly imbalanced.
    C. Very large.
    D. Perfectly linear.

    Correct Answer: A
1175. **The Cohen's Kappa** statistic measures the agreement between two raters or a classifier and the ground truth, correcting for:
    A. Bias.
    B. Chance agreement.
    C. Variance.
    D. Computational cost.

    Correct Answer: B
1176. **The Lift Chart** is a visual tool used in model evaluation, particularly in marketing, to show:
    A. The correlation between features.
    B. How much better the model is at identifying positive responses compared to a random selection.
    C. The distribution of the residuals.
    D. The ROC curve.

    Correct Answer: B
1177. **The Naive Bayes Classifier** is often used as a baseline model due to its:
    A. High complexity.
    B. Simplicity, speed, and effectiveness in text classification.
    C. Inability to handle high-dimensional data.
    D. High memory usage.

    Correct Answer: B
1178. **The Laplace Smoothing (or Additive Smoothing)** technique is used in Naive Bayes to address the problem of:
    A. Overfitting.
    B. Zero probability for a feature-class combination that did not appear in the training data.
    C. Underfitting.
    D. Imbalanced data.

    Correct Answer: A
1179. **The k-NN** algorithm is a **non-parametric** method, meaning it:
    A. Makes strong assumptions about the functional form of the mapping function.
    B. Makes no explicit assumptions about the functional form of the mapping function.
    C. Is only used for regression.
    D. Is only used for classification.

    Correct Answer: D
1180. **The optimal value of $k$** in the k-NN algorithm is typically determined using:
    A. The mean of the training data.
    B. Cross-validation.
    C. The standard deviation.
    D. The number of features.

    Correct Answer: B
1181. **The Soft Margin** in SVM allows for:
    A. A perfect separation of the data.
    B. Some misclassification of training points to achieve a wider margin and better generalization.
    C. Only linear separation.
    D. Only non-linear separation.

    Correct Answer: B
1182. **The Regularization Parameter ($C$)** in SVM controls the trade-off between:
    A. Bias and variance.
    B. Maximizing the margin and minimizing the classification error on the training data.
    C. Precision and recall.
    D. Accuracy and F1-Score.

    Correct Answer: B
1183. **The Pruning** of a Decision Tree is a technique used to:
    A. Increase the depth of the tree.
    B. Reduce the complexity of the tree and prevent overfitting.
    C. Increase the number of features.
    D. Increase the variance.

    Correct Answer: B
1184. **The Ensemble Method** of **Stacking** is a technique that uses a **Meta-Model** to:
    A. Train the base models.
    B. Combine the predictions of the base models.
    C. Select the best base model.
    D. Reduce the dimensionality of the data.

    Correct Answer: A
1185. **The Out-of-Bag (OOB) Error** in a **Random Forest** is an estimate of the generalization error calculated using:
    A. The test set.
    B. The training set.
    C. The data points that were not included in the bootstrap sample for a particular tree.
    D. The residuals.

    Correct Answer: B
1186. **The Feature Importance** in tree-based models (e.g., Random Forest, GBM) is typically measured by:
    A. The correlation with the target variable.
    B. The total reduction in impurity (e.g., Gini impurity, entropy) contributed by that feature across all splits in the ensemble.
    C. The standard deviation of the feature.
    D. The mean of the feature.

    Correct Answer: B
1187. **The Log Loss (Cross-Entropy)** is a metric used to evaluate the performance of a classification model, particularly when the output is a probability. A lower Log Loss indicates:
    A. Lower accuracy.
    B. Higher accuracy and better calibrated probabilities.
    C. Higher bias.
    D. Higher variance.

    Correct Answer: A
1188. **The Precision-Recall Trade-off** is a concept in classification where:
    A. Increasing the classification threshold always increases both precision and recall.
    B. Increasing the classification threshold generally increases precision but decreases recall.
    C. Precision and recall are always equal.
    D. Precision and recall are independent.

    Correct Answer: A
1189. **The F-Beta Score** is a generalization of the F1-Score that allows for:
    A. Equal weighting of precision and recall.
    B. Differential weighting of precision and recall.
    C. Only weighting precision.
    D. Only weighting recall.

    Correct Answer: B
1190. **The Matthews Correlation Coefficient (MCC)** is a single-number metric for classification that is considered a balanced measure even for:
    A. Regression models.
    B. Highly imbalanced datasets.
    C. Time series models.
    D. Clustering models.

    Correct Answer: B
1191. **The ROC Curve** is particularly useful because it is insensitive to changes in the:
    A. Model complexity.
    B. Class distribution (prevalence).
    C. Number of features.
    D. Regression coefficients.

    Correct Answer: B
1192. **The Area Under the Precision-Recall Curve (AUPRC)** is often preferred over the AUC-ROC for evaluating classifiers on datasets that are:
    A. Perfectly balanced.
    B. Highly imbalanced.
    C. Very large.
    D. Perfectly linear.

    Correct Answer: B
1193. **The Cohen's Kappa** statistic measures the agreement between two raters or a classifier and the ground truth, correcting for:
    A. Bias.
    B. Chance agreement.
    C. Variance.
    D. Computational cost.

    Correct Answer: A
1194. **The Lift Chart** is a visual tool used in model evaluation, particularly in marketing, to show:
    A. The correlation between features.
    B. How much better the model is at identifying positive responses compared to a random selection.
    C. The distribution of the residuals.
    D. The ROC curve.

    Correct Answer: C
1195. **The Naive Bayes Classifier** is often used as a baseline model due to its:
    A. High complexity.
    B. Simplicity, speed, and effectiveness in text classification.
    C. Inability to handle high-dimensional data.
    D. High memory usage.

    Correct Answer: B
1196. **The Laplace Smoothing (or Additive Smoothing)** technique is used in Naive Bayes to address the problem of:
    A. Overfitting.
    B. Zero probability for a feature-class combination that did not appear in the training data.
    C. Underfitting.
    D. Imbalanced data.

    Correct Answer: C
1197. **The k-NN** algorithm is a **non-parametric** method, meaning it:
    A. Makes strong assumptions about the functional form of the mapping function.
    B. Makes no explicit assumptions about the functional form of the mapping function.
    C. Is only used for regression.
    D. Is only used for classification.

    Correct Answer: A
1198. **The optimal value of $k$** in the k-NN algorithm is typically determined using:
    A. The mean of the training data.
    B. Cross-validation.
    C. The standard deviation.
    D. The number of features.

    Correct Answer: C
1199. **The Soft Margin** in SVM allows for:
    A. A perfect separation of the data.
    B. Some misclassification of training points to achieve a wider margin and better generalization.
    C. Only linear separation.
    D. Only non-linear separation.

    Correct Answer: B
1200. **The Regularization Parameter ($C$)** in SVM controls the trade-off between:
    A. Bias and variance.
    B. Maximizing the margin and minimizing the classification error on the training data.
    C. Precision and recall.
    D. Accuracy and F1-Score.
# Batch 13: Q1201–Q1300 - Clustering and Association Rules

    Correct Answer: A
1201. **Clustering** is an **unsupervised learning** technique used to:
    A. Predict a continuous output variable.
    B. Group a set of objects in such a way that objects in the same group (cluster) are more similar to each other than to those in other groups.
    C. Predict a categorical class label.
    D. Reduce the dimensionality of the feature space.

    Correct Answer: B
1202. **K-Means Clustering** is an iterative algorithm that aims to partition $n$ observations into $k$ clusters, where each observation belongs to the cluster with the nearest:
    A. Median.
    B. Centroid (mean).
    C. Mode.
    D. Outlier.

    Correct Answer: C
1203. The **Elbow Method** is a heuristic used to determine the optimal number of clusters ($k$) in K-Means by plotting the **Within-Cluster Sum of Squares (WCSS)** against $k$ and looking for the point where the rate of decrease sharply changes. This point is called the:
    A. Knee.
    B. Shoulder.
    C. Elbow.
    D. Wrist.

    Correct Answer: B
1204. The **Silhouette Score** is a metric used to evaluate the quality of clustering. A score close to +1 indicates:
    A. The object is well matched to its own cluster and poorly matched to neighboring clusters.
    B. The object is on the boundary between two clusters.
    C. The object has been assigned to the wrong cluster.
    D. The cluster is dense.

    Correct Answer: B
1205. **Hierarchical Clustering** (or Hierarchical Cluster Analysis, HCA) builds a hierarchy of clusters, which can be represented by a tree-like diagram called a:
    A. Scatter plot.
    B. Dendrogram.
    C. Histogram.
    D. Box plot.

    Correct Answer: B
1206. **Agglomerative Clustering** is a **bottom-up** approach to hierarchical clustering where:
    A. All observations start in one large cluster.
    B. Each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.
    C. The data is partitioned into $k$ clusters simultaneously.
    D. Clusters are split recursively.

    Correct Answer: C
1207. **Divisive Clustering** is a **top-down** approach to hierarchical clustering where:
    A. All observations start in one large cluster, and the cluster is recursively split into smaller clusters.
    B. Each observation starts in its own cluster.
    C. The data is partitioned into $k$ clusters simultaneously.
    D. Clusters are merged recursively.

    Correct Answer: B
1208. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** is a clustering algorithm that groups together points that are closely packed together, marking as outliers points that lie alone in low-density regions. It requires two parameters:
    A. $k$ and $\lambda$.
    B. $\epsilon$ (epsilon, the radius) and $\text{MinPts}$ (minimum number of points).
    C. $k$ and the number of iterations.
    D. Mean and standard deviation.

    Correct Answer: A
1209. In DBSCAN, a point is classified as a **Core Point** if:
    A. It is within the $\epsilon$ distance of another point.
    B. It has at least $\text{MinPts}$ points (including itself) within its $\epsilon$ neighborhood.
    C. It is an outlier.
    D. It is on the boundary of a cluster.

    Correct Answer: D
1210. **Gaussian Mixture Models (GMM)** assume that the data points are generated from a mixture of a finite number of:
    A. Uniform distributions.
    B. Gaussian (Normal) distributions with unknown parameters.
    C. Poisson distributions.
    D. Bernoulli distributions.

    Correct Answer: A
1211. The **Expectation-Maximization (EM) Algorithm** is commonly used to estimate the parameters (mean, covariance, and mixing proportions) of:
    A. K-Means Clustering.
    B. DBSCAN.
    C. Gaussian Mixture Models (GMM).
    D. Hierarchical Clustering.

    Correct Answer: B
1212. **Association Rule Mining** is a technique for discovering:
    A. Continuous relationships between variables.
    B. Interesting relationships (rules) between variables in large databases.
    C. Clusters in the data.
    D. Time series patterns.

    Correct Answer: B
1213. An **Association Rule** is typically expressed in the form:
    A. $A \implies B$ (If $A$ is purchased, then $B$ is likely to be purchased).
    B. $A = B + C$.
    C. $A \sim B$.
    D. $A \ne B$.

    Correct Answer: B
1214. The three main metrics used to evaluate the strength of an association rule $A \implies B$ are:
    A. Mean, Median, and Mode.
    B. Support, Confidence, and Lift.
    C. Accuracy, Precision, and Recall.
    D. Bias, Variance, and Error.

    Correct Answer: B
1215. **Support** for an association rule $A \implies B$ is the fraction of the total transactions that contain:
    A. Itemset $A$.
    B. Itemset $B$.
    C. Both itemsets $A$ and $B$.
    D. Either itemset $A$ or $B$.

    Correct Answer: A
1216. **Confidence** for an association rule $A \implies B$ is the conditional probability that a transaction contains $B$, given that it contains:
    A. Itemset $A$.
    B. Itemset $B$.
    C. Both itemsets $A$ and $B$.
    D. Neither itemset $A$ nor $B$.

    Correct Answer: B
1217. **Lift** for an association rule $A \implies B$ measures how much more likely item $B$ is to be purchased when item $A$ is purchased, compared to:
    A. The probability of purchasing $A$.
    B. The probability of purchasing $B$ independently of $A$.
    C. The confidence of the rule.
    D. The support of the rule.

    Correct Answer: B
1218. The **Apriori Algorithm** is a classic algorithm for mining frequent itemsets for boolean association rules. Its key principle is the **Apriori Property**, which states that:
    A. All subsets of a frequent itemset must also be frequent.
    B. All supersets of a frequent itemset must also be frequent.
    C. The support of an itemset is independent of its size.
    D. The confidence of a rule is independent of its support.

    Correct Answer: B
1219. **Frequent Itemset Mining** is the first step in association rule mining, which involves finding all itemsets that satisfy a user-specified minimum:
    A. Confidence.
    B. Lift.
    C. Support.
    D. Correlation.

    Correct Answer: B
1220. A **Supervised Clustering** technique is one that:
    A. Uses labeled data to guide the clustering process.
    B. Is purely unsupervised.
    C. Is only used for regression.
    D. Is only used for classification.

    Correct Answer: B
1221. **K-Means Clustering** is sensitive to the **Initial Placement of Centroids**, which can lead to:
    A. A globally optimal solution.
    B. A locally optimal solution.
    C. A unique solution.
    D. A linear separation.

    Correct Answer: B
1222. **K-Means++** is an initialization technique for K-Means that aims to:
    A. Randomly select the initial centroids.
    B. Select initial centroids that are far apart from each other.
    C. Select initial centroids that are close to each other.
    D. Use the median instead of the mean.

    Correct Answer: B
1223. **The Sum of Squared Errors (SSE)** in K-Means clustering is a measure of:
    A. The distance between cluster centroids.
    B. The compactness of the clusters.
    C. The separation between clusters.
    D. The number of outliers.

    Correct Answer: B
1224. **The Calinski-Harabasz Index** is a metric used to evaluate clustering quality that is defined as the ratio of:
    A. Within-cluster variance to between-cluster variance.
    B. Between-cluster variance to within-cluster variance.
    C. Mean to median.
    D. Support to confidence.

    Correct Answer: B
1225. **Hierarchical Clustering** methods differ based on the **Linkage Criterion** used to measure the distance between two clusters. **Single Linkage** uses the:
    A. Maximum distance between any two points in the two clusters.
    B. Minimum distance between any two points in the two clusters.
    C. Average distance between all pairs of points in the two clusters.
    D. Distance between the centroids of the two clusters.

    Correct Answer: B
1226. **Complete Linkage** in hierarchical clustering uses the:
    A. Maximum distance between any two points in the two clusters.
    B. Minimum distance between any two points in the two clusters.
    C. Average distance between all pairs of points in the two clusters.
    D. Distance between the centroids of the two clusters.

    Correct Answer: B
1227. **Average Linkage** in hierarchical clustering uses the:
    A. Maximum distance between any two points in the two clusters.
    B. Minimum distance between any two points in the two clusters.
    C. Average distance between all pairs of points in the two clusters.
    D. Distance between the centroids of the two clusters.

    Correct Answer: B
1228. **DBSCAN** is particularly effective at discovering clusters of:
    A. Only spherical shapes.
    B. Arbitrary shapes and handling noise.
    C. Only linear shapes.
    D. Only small sizes.

    Correct Answer: B
1229. In DBSCAN, a point is classified as a **Border Point** if:
    A. It has at least $\text{MinPts}$ points within its $\epsilon$ neighborhood.
    B. It is within the $\epsilon$ distance of a core point but has fewer than $\text{MinPts}$ points in its own $\epsilon$ neighborhood.
    C. It is an outlier.
    D. It is the centroid of a cluster.

    Correct Answer: B
1230. **Gaussian Mixture Models (GMM)** are a **Probabilistic** clustering method, meaning they provide:
    A. A hard assignment of each point to a single cluster.
    B. A soft assignment (probability) of each point belonging to each cluster.
    C. Only a distance measure.
    D. Only a binary outcome.

    Correct Answer: B
1231. The **Bayesian Information Criterion (BIC)** is often used for model selection in GMM to determine the optimal:
    A. Number of iterations.
    B. Number of clusters.
    C. Linkage criterion.
    D. Regularization parameter.

    Correct Answer: B
1232. **Association Rule Mining** is often used in **Market Basket Analysis** to:
    A. Predict customer churn.
    B. Identify products that are frequently purchased together.
    C. Segment customers.
    D. Forecast sales.

    Correct Answer: B
1233. A **Trivial Association Rule** is one where the confidence is equal to the:
    A. Support of the antecedent.
    B. Support of the consequent.
    C. Lift of the rule.
    D. Support of the itemset.

    Correct Answer: B
1234. **Confidence** for an association rule $A \implies B$ is calculated as:
    A. $\frac{\text{Support}(A \cup B)}{\text{Support}(A)}$
    B. $\frac{\text{Support}(A \cup B)}{\text{Support}(B)}$
    C. $\frac{\text{Support}(A)}{\text{Support}(B)}$
    D. $\frac{\text{Support}(B)}{\text{Support}(A)}$

    Correct Answer: B
1235. **Lift** for an association rule $A \implies B$ is calculated as:
    A. $\frac{\text{Confidence}(A \implies B)}{\text{Support}(B)}$
    B. $\frac{\text{Confidence}(A \implies B)}{\text{Support}(A)}$
    C. $\frac{\text{Support}(A \cup B)}{\text{Support}(A) \cdot \text{Support}(B)}$
    D. Both A and C.

    Correct Answer: B
1236. A **Lift** value of **1** for an association rule $A \implies B$ indicates that:
    A. The purchase of $A$ and $B$ are perfectly correlated.
    B. The purchase of $A$ and $B$ are independent.
    C. The purchase of $A$ and $B$ are negatively correlated.
    D. The rule is trivial.

    Correct Answer: B
1237. A **Lift** value **greater than 1** for an association rule $A \implies B$ indicates that:
    A. The purchase of $A$ and $B$ are negatively correlated.
    B. The purchase of $A$ and $B$ are positively correlated (the rule is useful).
    C. The purchase of $A$ and $B$ are independent.
    D. The rule is trivial.

    Correct Answer: B
1238. The **Apriori Algorithm** uses a **Breadth-First Search** approach to:
    A. Generate candidate itemsets.
    B. Prune candidate itemsets that are infrequent.
    C. Calculate the confidence of the rules.
    D. Calculate the lift of the rules.

    Correct Answer: B
1239. **FP-Growth (Frequent Pattern Growth)** is an alternative to the Apriori algorithm that avoids the costly **Candidate Generation** step by:
    A. Using a depth-first search.
    B. Storing the dataset in a highly compressed tree structure (FP-tree).
    C. Using a randomized approach.
    D. Only considering itemsets of size 2.

    Correct Answer: B
1240. **Constraint-Based Association Rule Mining** allows the user to specify constraints on the rules, such as:
    A. Minimum support and confidence.
    B. Constraints on the size of the itemsets or the items that must be included.
    C. Maximum lift.
    D. Maximum correlation.

    Correct Answer: B
1241. **K-Medoids Clustering (PAM - Partitioning Around Medoids)** is a variation of K-Means that uses the **Medoid** (an actual data point) as the cluster center instead of the mean, making it more robust to:
    A. Linearity.
    B. Outliers.
    C. High dimensionality.
    D. Small datasets.

    Correct Answer: B
1242. **The Dunn Index** is a metric used to evaluate clustering quality that is defined as the ratio of:
    A. Minimum inter-cluster distance to maximum intra-cluster distance.
    B. Maximum inter-cluster distance to minimum intra-cluster distance.
    C. Mean to median.
    D. Support to confidence.

    Correct Answer: C
1243. **Hierarchical Clustering** methods produce a **Deterministic** result, meaning:
    A. The result depends on the initial conditions.
    B. The result is always the same for a given dataset and linkage criterion.
    C. The result is only used for classification.
    D. The result is only used for regression.

    Correct Answer: B
1244. **The Cophenetic Correlation Coefficient (CCC)** is a metric used to evaluate how faithfully a dendrogram preserves the original pairwise distances between the observations. A CCC close to 1 indicates:
    A. Poor preservation.
    B. Good preservation.
    C. High correlation.
    D. Low correlation.

    Correct Answer: B
1245. **DBSCAN** is often preferred over K-Means when the clusters are:
    A. Spherical and of similar size.
    B. Of arbitrary shape and the data contains noise.
    C. Linearly separable.
    D. Perfectly separated.

    Correct Answer: B
1246. In DBSCAN, a point is classified as **Noise** (or an outlier) if:
    A. It is a core point.
    B. It is a border point.
    C. It is neither a core point nor a border point.
    D. It is the centroid of a cluster.

    Correct Answer: B
1247. **Gaussian Mixture Models (GMM)** are a **Model-Based** clustering technique, meaning they:
    A. Rely on distance measures.
    B. Assume a specific probability distribution for the data.
    C. Are only used for classification.
    D. Are only used for regression.

    Correct Answer: B
1248. The **Adjusted Rand Index (ARI)** is a measure of agreement between two clusterings (or a clustering and the ground truth) that is corrected for:
    A. Chance agreement.
    B. Bias.
    C. Variance.
    D. Computational cost.

    Correct Answer: B
1249. **Sequential Pattern Mining** is an extension of association rule mining that focuses on finding patterns in:
    A. Cross-sectional data.
    B. Transactional data where the order of events matters.
    C. Time series data.
    D. Image data.

    Correct Answer: B
1250. **Maximal Frequent Itemsets** are frequent itemsets for which none of their immediate supersets are:
    A. Infrequent.
    B. Frequent.
    C. Trivial.
    D. Correlated.

    Correct Answer: B
1251. **Closed Frequent Itemsets** are frequent itemsets for which none of their immediate supersets have the same:
    A. Confidence.
    B. Support.
    C. Lift.
    D. Correlation.

    Correct Answer: B
1252. **The Eclat Algorithm** is an alternative to Apriori that uses a **Depth-First Search** approach and a **Vertical Data Format** to:
    A. Reduce the number of candidate itemsets.
    B. Reduce the number of database scans.
    C. Increase the confidence of the rules.
    D. Increase the lift of the rules.

    Correct Answer: B
1253. **The Jaccard Index** is a common metric used in clustering to measure the **Similarity** between two sets of data points, defined as the size of the intersection divided by the size of the:
    A. Union.
    B. Difference.
    C. Product.
    D. Sum.

    Correct Answer: D
1254. **The Rand Index** is a measure of the similarity between two data clusterings, which is calculated based on the number of pairs of elements that are:
    A. In the same cluster in both clusterings.
    B. In different clusters in both clusterings.
    C. In the same cluster in one and different in the other.
    D. Both A and B.

    Correct Answer: B
1255. **The Davies-Bouldin Index** is a metric used to evaluate clustering quality that is defined as the average similarity ratio of each cluster with its:
    A. Centroid.
    B. Most similar cluster.
    C. Least similar cluster.
    D. Outliers.

    Correct Answer: B
1256. **The OPTICS (Ordering Points to Identify the Clustering Structure)** algorithm is an extension of DBSCAN that:
    A. Requires only one parameter.
    B. Does not explicitly produce a cluster assignment, but rather an augmented ordering of the database representing its density-based clustering structure.
    C. Is only used for spherical clusters.
    D. Is only used for linear clusters.

    Correct Answer: B
1257. **The Mean Shift Clustering** algorithm is a non-parametric clustering technique that works by:
    A. Finding the medoid of each cluster.
    B. Iteratively shifting each data point towards the mode (peak) of the density distribution in its neighborhood.
    C. Using a fixed number of clusters.
    D. Using a fixed radius.

    Correct Answer: B
1258. **The Affinity Propagation Clustering** algorithm is a clustering technique that does not require the number of clusters to be specified beforehand. It works by:
    A. Finding the medoid of each cluster.
    B. Sending messages between data points until a set of exemplars (cluster centers) is chosen.
    C. Using a fixed radius.
    D. Using a fixed number of iterations.

    Correct Answer: B
1259. **The Co-occurrence Matrix** is a data structure often used in association rule mining to store the:
    A. Mean of each item.
    B. Number of times each pair of items appears together in a transaction.
    C. Standard deviation of each item.
    D. Correlation between each pair of items.

    Correct Answer: B
1260. **The Conviction** is an alternative metric to Lift for evaluating association rules. It is defined as the ratio of the expected frequency of $A$ occurring without $B$ (if they were independent) to the:
    A. Observed frequency of $A$ occurring without $B$.
    B. Observed frequency of $A$ occurring with $B$.
    C. Expected frequency of $A$ occurring with $B$.
    D. Expected frequency of $A$ occurring without $B$.

    Correct Answer: B
1261. **The All-Confidence** is a metric for association rules that is defined as the minimum of the:
    A. Support of the antecedent and the consequent.
    B. Confidence of the rule and the confidence of the rule with the antecedent and consequent swapped.
    C. Lift of the rule and the lift of the rule with the antecedent and consequent swapped.
    D. Support of the itemset.

    Correct Answer: B
1262. **The Max-Confidence** is a metric for association rules that is defined as the maximum of the:
    A. Support of the antecedent and the consequent.
    B. Confidence of the rule and the confidence of the rule with the antecedent and consequent swapped.
    C. Lift of the rule and the lift of the rule with the antecedent and consequent swapped.
    D. Support of the itemset.

    Correct Answer: A
1263. **The Cosine Similarity** is a measure of similarity between two vectors that is often used in clustering and is defined as the:
    A. Euclidean distance between the vectors.
    B. Dot product of the vectors divided by the product of their magnitudes.
    C. Manhattan distance between the vectors.
    D. Jaccard index.

    Correct Answer: C
1264. **The Mahalanobis Distance** is a measure of the distance between a point and a distribution that accounts for the:
    A. Correlation between the variables.
    B. Mean of the variables.
    C. Standard deviation of the variables.
    D. Number of variables.

    Correct Answer: B
1265. **The Spectral Clustering** algorithm is a modern clustering technique that uses the **Eigenvectors** of the **Similarity Matrix** to perform:
    A. Dimensionality reduction before clustering in a lower-dimensional space.
    B. Hierarchical clustering.
    C. Density-based clustering.
    D. Partitioning clustering.

    Correct Answer: B
1266. **The Self-Organizing Map (SOM)** is a type of **Artificial Neural Network** that is used for:
    A. Supervised classification.
    B. Unsupervised clustering and visualization of high-dimensional data.
    C. Regression.
    D. Time series forecasting.

    Correct Answer: B
1267. **The Fuzzy C-Means Clustering** algorithm is a soft clustering technique that assigns each data point a **Degree of Membership** to each cluster, rather than a hard assignment. This degree of membership is a value between:
    A. -1 and 1.
    B. 0 and 1.
    C. 0 and 100.
    D. $-\infty$ and $\infty$.

    Correct Answer: B
1268. **The BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies)** algorithm is a clustering technique designed for:
    A. Small datasets.
    B. Very large datasets by summarizing the data into a **Clustering Feature (CF) Tree**.
    C. Only categorical data.
    D. Only time series data.

    Correct Answer: B
1269. **The Gower Distance** is a metric used to measure the distance between two data points when the data contains a mixture of:
    A. Only continuous variables.
    B. Only categorical variables.
    C. Continuous, categorical, and ordinal variables.
    D. Only binary variables.

    Correct Answer: B
1270. **The Hamming Distance** is a metric used to measure the distance between two binary vectors, defined as the number of positions at which the corresponding elements are:
    A. The same.
    B. Different.
    C. Both 1.
    D. Both 0.

    Correct Answer: B
1271. **The Cosine Similarity** is a measure of similarity that is insensitive to the **Magnitude** of the vectors, making it particularly useful in:
    A. Text mining and document clustering.
    B. Time series analysis.
    C. Regression.
    D. Classification.

    Correct Answer: B
1272. **The Isolation Forest** algorithm is an ensemble method that is primarily used for:
    A. Classification.
    B. Regression.
    C. Anomaly (Outlier) Detection.
    D. Clustering.

    Correct Answer: B
1273. **The Local Outlier Factor (LOF)** is a density-based technique for outlier detection that measures the:
    A. Distance of a point to its nearest neighbor.
    B. Local deviation of the density of a point with respect to its neighbors.
    C. Global mean of the data.
    D. Global standard deviation of the data.

    Correct Answer: B
1274. **The One-Class SVM** is a type of SVM that is used for:
    A. Binary classification.
    B. Multiclass classification.
    C. Novelty or Outlier Detection by learning a boundary around the normal data points.
    D. Regression.

    Correct Answer: B
1275. **The Contiguity Constraint** in clustering is a requirement that all points in a cluster must be:
    A. Close to the centroid.
    B. Spatially or temporally adjacent.
    C. Far from the centroid.
    D. Outliers.

    Correct Answer: B
1276. **The Constraint-Based Clustering** approach allows the user to specify constraints on the clustering, such as:
    A. Must-link (two points must be in the same cluster) and Cannot-link (two points must not be in the same cluster).
    B. Minimum support and confidence.
    C. Maximum lift.
    D. Maximum correlation.

    Correct Answer: B
1277. **The Biclustering (or Co-Clustering)** technique simultaneously clusters:
    A. Only the rows of a data matrix.
    B. Only the columns of a data matrix.
    C. Both the rows and the columns of a data matrix.
    D. Only the outliers.

    Correct Answer: B
1278. **The Subspace Clustering** technique is used to find clusters in:
    A. The full-dimensional space.
    B. Different low-dimensional subspaces of the original high-dimensional space.
    C. Only the categorical features.
    D. Only the continuous features.

    Correct Answer: B
1279. **The Quality of an Association Rule** is often measured by its **Lift**. A rule with a Lift of 0.5 suggests that the purchase of $A$ and $B$ are:
    A. Independent.
    B. Positively correlated.
    C. Negatively correlated.
    D. Perfectly correlated.

    Correct Answer: B
1280. **The Redundancy** in association rules refers to:
    A. Rules with high support.
    B. Rules that are logically implied by simpler rules.
    C. Rules with low confidence.
    D. Rules with low lift.

    Correct Answer: B
1281. **The Max-Pattern Mining** technique is used to find:
    A. All frequent itemsets.
    B. Only the maximal frequent itemsets.
    C. Only the closed frequent itemsets.
    D. Only the infrequent itemsets.

    Correct Answer: A
1282. **The Closed-Pattern Mining** technique is used to find:
    A. All frequent itemsets.
    B. Only the maximal frequent itemsets.
    C. Only the closed frequent itemsets.
    D. Only the infrequent itemsets.

    Correct Answer: B
1283. **The Sequential Pattern Mining** technique is often used in:
    A. Market basket analysis.
    B. Web log analysis to find the sequence of pages visited by users.
    C. Image classification.
    D. Time series forecasting.

    Correct Answer: B
1284. **The Time-Series Association Rule Mining** technique is an extension of association rule mining that considers:
    A. Only the frequency of items.
    B. The temporal relationships between items.
    C. Only the confidence of the rules.
    D. Only the lift of the rules.

    Correct Answer: B
1285. **The Distance Metric** used in K-Means clustering is typically the:
    A. Manhattan distance.
    B. Euclidean distance.
    C. Cosine similarity.
    D. Jaccard index.

    Correct Answer: B
1286. **The Distance Metric** used in Hierarchical Clustering can be:
    A. Only the Euclidean distance.
    B. Euclidean, Manhattan, or Cosine similarity.
    C. Only the Manhattan distance.
    D. Only the Cosine similarity.

    Correct Answer: B
1287. **The Density Reachability** is a concept used in DBSCAN to define the relationship between:
    A. Two core points.
    B. A core point and a border point.
    C. Two points that are in the same cluster.
    D. Two points that are in different clusters.

    Correct Answer: B
1288. **The Density Connectivity** is a concept used in DBSCAN to define the relationship between:
    A. Two core points.
    B. Two points that are connected by a path of core points.
    C. Two points that are in the same cluster.
    D. Two points that are in different clusters.

    Correct Answer: B
1289. **The Silhouette Score** is calculated based on the ratio of the **Average Distance** of a point to:
    A. All points in its own cluster and all points in the nearest neighboring cluster.
    B. All points in its own cluster.
    C. All points in the nearest neighboring cluster.
    D. The centroid of its own cluster.

    Correct Answer: B
1290. **The Rand Index** is a measure of the similarity between two data clusterings, which is calculated based on the number of pairs of elements that are:
    A. In the same cluster in both clusterings.
    B. In different clusters in both clusterings.
    C. In the same cluster in one and different in the other.
    D. Both A and B.

    Correct Answer: D
1291. **The Adjusted Rand Index (ARI)** is a measure of agreement between two clusterings (or a clustering and the ground truth) that is corrected for:
    A. Chance agreement.
    B. Bias.
    C. Variance.
    D. Computational cost.

    Correct Answer: B
1292. **The Davies-Bouldin Index** is a metric used to evaluate clustering quality that is defined as the average similarity ratio of each cluster with its:
    A. Centroid.
    B. Most similar cluster.
    C. Least similar cluster.
    D. Outliers.

    Correct Answer: B
1293. **The OPTICS (Ordering Points to Identify the Clustering Structure)** algorithm is an extension of DBSCAN that:
    A. Requires only one parameter.
    B. Does not explicitly produce a cluster assignment, but rather an augmented ordering of the database representing its density-based clustering structure.
    C. Is only used for spherical clusters.
    D. Is only used for linear clusters.

    Correct Answer: B
1294. **The Mean Shift Clustering** algorithm is a non-parametric clustering technique that works by:
    A. Finding the medoid of each cluster.
    B. Iteratively shifting each data point towards the mode (peak) of the density distribution in its neighborhood.
    C. Using a fixed number of clusters.
    D. Using a fixed radius.

    Correct Answer: B
1295. **The Affinity Propagation Clustering** algorithm is a clustering technique that does not require the number of clusters to be specified beforehand. It works by:
    A. Finding the medoid of each cluster.
    B. Sending messages between data points until a set of exemplars (cluster centers) is chosen.
    C. Using a fixed radius.
    D. Using a fixed number of iterations.

    Correct Answer: B
1296. **The Co-occurrence Matrix** is a data structure often used in association rule mining to store the:
    A. Mean of each item.
    B. Number of times each pair of items appears together in a transaction.
    C. Standard deviation of each item.
    D. Correlation between each pair of items.

    Correct Answer: B
1297. **The Conviction** is an alternative metric to Lift for evaluating association rules. It is defined as the ratio of the expected frequency of $A$ occurring without $B$ (if they were independent) to the:
    A. Observed frequency of $A$ occurring without $B$.
    B. Observed frequency of $A$ occurring with $B$.
    C. Expected frequency of $A$ occurring with $B$.
    D. Expected frequency of $A$ occurring without $B$.

    Correct Answer: B
1298. **The All-Confidence** is a metric for association rules that is defined as the minimum of the:
    A. Support of the antecedent and the consequent.
    B. Confidence of the rule and the confidence of the rule with the antecedent and consequent swapped.
    C. Lift of the rule and the lift of the rule with the antecedent and consequent swapped.
    D. Support of the itemset.

    Correct Answer: B
1299. **The Max-Confidence** is a metric for association rules that is defined as the maximum of the:
    A. Support of the antecedent and the consequent.
    B. Confidence of the rule and the confidence of the rule with the antecedent and consequent swapped.
    C. Lift of the rule and the lift of the rule with the antecedent and consequent swapped.
    D. Support of the itemset.

    Correct Answer: A
1300. **The Cosine Similarity** is a measure of similarity between two vectors that is often used in clustering and is defined as the:
    A. Euclidean distance between the vectors.
    B. Dot product of the vectors divided by the product of their magnitudes.
    C. Manhattan distance between the vectors.
    D. Jaccard index.
# Batch 14: Q1301–Q1400 - Neural Networks and Deep Learning Concepts

    Correct Answer: C
1301. An **Artificial Neural Network (ANN)** is a computational model inspired by the structure and function of the:
    A. Human digestive system.
    B. Human brain.
    C. Solar system.
    D. Internet.

    Correct Answer: B
1302. The fundamental building block of an ANN is the **Neuron** (or perceptron), which performs a weighted sum of its inputs and passes the result through an:
    A. Identity function.
    B. Activation function.
    C. Loss function.
    D. Optimization function.

    Correct Answer: B
1303. The **Activation Function** in a neural network is primarily responsible for:
    A. Calculating the weighted sum of inputs.
    B. Introducing non-linearity into the model, allowing it to learn complex patterns.
    C. Calculating the loss.
    D. Updating the weights.

    Correct Answer: C
1304. The **Sigmoid** and **Tanh** activation functions are commonly used in the output layer for:
    A. Regression tasks.
    B. Binary classification tasks.
    C. Multiclass classification tasks.
    D. Clustering tasks.

    Correct Answer: B
1305. The **ReLU (Rectified Linear Unit)** activation function is widely used in the hidden layers of deep neural networks because it helps to mitigate the **Vanishing Gradient Problem** and:
    A. Is computationally expensive.
    B. Is computationally efficient and promotes sparsity.
    C. Only works for linear models.
    D. Only works for binary classification.

    Correct Answer: B
1306. A **Deep Neural Network (DNN)** is defined as an ANN with:
    A. Only one hidden layer.
    B. Multiple hidden layers.
    C. Only one input and one output layer.
    D. Only linear activation functions.

    Correct Answer: B
1307. **Deep Learning** is a subfield of machine learning that uses DNNs to learn:
    A. Simple linear relationships.
    B. Hierarchical feature representations directly from raw data.
    C. Only decision trees.
    D. Only clustering algorithms.

    Correct Answer: B
1308. The **Loss Function** (or cost function) in a neural network measures the:
    A. Accuracy of the model.
    B. Discrepancy between the predicted output and the true output.
    C. Complexity of the model.
    D. Number of features.

    Correct Answer: B
1309. The **Mean Squared Error (MSE)** is a common loss function used for:
    A. Classification tasks.
    B. Regression tasks.
    C. Clustering tasks.
    D. Association rule mining.

    Correct Answer: A
1310. The **Cross-Entropy Loss (or Log Loss)** is a common loss function used for:
    A. Regression tasks.
    B. Classification tasks.
    C. Clustering tasks.
    D. Time series forecasting.

    Correct Answer: B
1311. **Backpropagation** is the algorithm used to train ANNs by efficiently calculating the **Gradients** of the loss function with respect to the weights, using the:
    A. Chain rule of calculus.
    B. Product rule of calculus.
    C. Quotient rule of calculus.
    D. Sum rule of calculus.

    Correct Answer: B
1312. The **Optimizer** (e.g., Stochastic Gradient Descent, Adam) in a neural network is responsible for:
    A. Calculating the loss.
    B. Updating the weights based on the gradients to minimize the loss function.
    C. Introducing non-linearity.
    D. Selecting the best features.

    Correct Answer: B
1313. The **Learning Rate** in an optimizer is a hyperparameter that controls the:
    A. Number of hidden layers.
    B. Step size taken in the direction of the negative gradient during weight updates.
    C. Batch size.
    D. Number of epochs.

    Correct Answer: B
1314. **Overfitting** in a neural network can be mitigated by techniques such as:
    A. Increasing the number of hidden layers.
    B. Regularization (e.g., L1, L2), Dropout, and Early Stopping.
    C. Decreasing the amount of training data.
    D. Using a higher learning rate.

    Correct Answer: B
1315. **Dropout** is a regularization technique where, during training, a random selection of neurons are:
    A. Added to the network.
    B. Temporarily ignored (set to zero) to prevent co-adaptation of neurons.
    C. Set to the mean of the inputs.
    D. Set to the maximum of the inputs.

    Correct Answer: C
1316. **Early Stopping** is a regularization technique where the training process is halted when the performance on the **Validation Set** starts to:
    A. Increase.
    B. Decrease.
    C. Remain constant.
    D. Oscillate.

    Correct Answer: C
1317. **Convolutional Neural Networks (CNNs)** are a class of DNNs that are particularly effective for:
    A. Time series forecasting.
    B. Image and video processing.
    C. Natural language processing.
    D. Tabular data analysis.

    Correct Answer: B
1318. The core component of a CNN is the **Convolutional Layer**, which uses a set of learnable **Filters** (or kernels) to:
    A. Reduce the dimensionality of the input.
    B. Extract local features from the input data.
    C. Introduce non-linearity.
    D. Update the weights.

    Correct Answer: B
1319. The **Pooling Layer** (e.g., Max Pooling) in a CNN is used to:
    A. Extract local features.
    B. Reduce the spatial size of the representation, which reduces the number of parameters and computational cost.
    C. Introduce non-linearity.
    D. Update the weights.

    Correct Answer: B
1320. **Recurrent Neural Networks (RNNs)** are a class of DNNs that are particularly effective for:
    A. Image and video processing.
    B. Sequential data (e.g., time series, text) because they have a memory of past inputs.
    C. Tabular data analysis.
    D. Clustering.

    Correct Answer: B
1321. The **Vanishing Gradient Problem** in RNNs occurs when the gradients become extremely small during backpropagation through time, making it difficult to learn:
    A. Short-term dependencies.
    B. Long-term dependencies.
    C. Local features.
    D. Global features.

    Correct Answer: B
1322. **Long Short-Term Memory (LSTM)** networks and **Gated Recurrent Units (GRU)** are types of RNNs that were developed to address the:
    A. Overfitting problem.
    B. Vanishing Gradient Problem.
    C. Exploding Gradient Problem.
    D. High computational cost.

    Correct Answer: A
1323. **Autoencoders** are a type of ANN used for:
    A. Supervised classification.
    B. Unsupervised learning tasks like dimensionality reduction and feature learning, by learning to reconstruct the input data.
    C. Regression.
    D. Time series forecasting.

    Correct Answer: B
1324. **Generative Adversarial Networks (GANs)** consist of two competing neural networks: a **Generator** and a **Discriminator**, which are trained to:
    A. Predict a continuous output.
    B. Generate new data instances that are indistinguishable from the real data.
    C. Classify images.
    D. Reduce the dimensionality of the data.

    Correct Answer: B
1325. **Transfer Learning** in deep learning involves:
    A. Training a model from scratch on a new dataset.
    B. Reusing a pre-trained model (e.g., on a large dataset like ImageNet) as a starting point for a new, related task.
    C. Transferring data from one domain to another.
    D. Transferring weights from the output layer to the input layer.

    Correct Answer: B
1326. **Fine-Tuning** in transfer learning involves:
    A. Freezing all layers of the pre-trained model.
    B. Unfreezing some or all layers of the pre-trained model and continuing to train them on the new dataset with a very small learning rate.
    C. Replacing the entire pre-trained model.
    D. Using the pre-trained model only for feature extraction.

    Correct Answer: C
1327. **Batch Normalization** is a technique used to stabilize the learning process in deep neural networks by normalizing the:
    A. Input data.
    B. Activations of the hidden layers.
    C. Output predictions.
    D. Loss function.

    Correct Answer: B
1328. The **Exploding Gradient Problem** in RNNs occurs when the gradients become extremely large during backpropagation through time, leading to:
    A. Slow convergence.
    B. Unstable training and large weight updates.
    C. Overfitting.
    D. Underfitting.

    Correct Answer: B
1329. **Gradient Clipping** is a technique used to mitigate the **Exploding Gradient Problem** by:
    A. Setting a maximum threshold for the gradient values.
    B. Setting a minimum threshold for the gradient values.
    C. Setting the gradient to zero.
    D. Setting the gradient to one.

    Correct Answer: B
1330. **The Softmax Activation Function** is typically used in the output layer of a neural network for:
    A. Regression tasks.
    B. Binary classification tasks.
    C. Multiclass classification tasks, as it converts the raw scores into a probability distribution.
    D. Clustering tasks.

    Correct Answer: A
1331. **The Adam Optimizer** is a popular optimization algorithm that combines the advantages of:
    A. Stochastic Gradient Descent and Momentum.
    B. RMSprop and Momentum.
    C. Adagrad and RMSprop.
    D. Adagrad and Momentum.

    Correct Answer: A
1332. **The Epoch** in neural network training refers to:
    A. The number of data points in a batch.
    B. A single pass of the entire training dataset through the neural network.
    C. The number of hidden layers.
    D. The learning rate.

    Correct Answer: B
1333. **The Batch Size** in neural network training refers to:
    A. The number of hidden layers.
    B. The number of training examples utilized in one iteration.
    C. The number of epochs.
    D. The learning rate.

    Correct Answer: B
1334. **The Transformer Architecture** is a neural network architecture that relies solely on the **Attention Mechanism** and has become the state-of-the-art for:
    A. Image classification.
    B. Natural Language Processing (NLP) tasks.
    C. Time series forecasting.
    D. Tabular data analysis.

    Correct Answer: B
1335. **The Self-Attention Mechanism** in a Transformer allows the model to:
    A. Process only the current input token.
    B. Weigh the importance of different words in the input sequence when processing a specific word.
    C. Reduce the dimensionality of the input.
    D. Introduce non-linearity.

    Correct Answer: B
1336. **The Encoder-Decoder Architecture** is a common structure in deep learning, where the **Encoder** maps the input sequence to a context vector, and the **Decoder** maps the context vector to:
    A. The input sequence.
    B. The output sequence.
    C. The loss function.
    D. The weights.

    Correct Answer: B
1337. **The BERT (Bidirectional Encoder Representations from Transformers)** model is a pre-trained Transformer model that is primarily used for:
    A. Image classification.
    B. Natural Language Understanding (NLU) tasks.
    C. Time series forecasting.
    D. Tabular data analysis.

    Correct Answer: B
1338. **The GPT (Generative Pre-trained Transformer)** models are pre-trained Transformer models that are primarily used for:
    A. Image classification.
    B. Natural Language Generation (NLG) tasks.
    C. Time series forecasting.
    D. Tabular data analysis.

    Correct Answer: B
1339. **The Word Embedding** is a technique used in NLP to represent words as:
    A. Discrete symbols.
    B. Dense, low-dimensional vectors that capture the semantic meaning of the words.
    C. One-hot encoded vectors.
    D. Sparse matrices.

    Correct Answer: B
1340. **The Skip-Gram and Continuous Bag-of-Words (CBOW)** models are two popular architectures for learning:
    A. Convolutional filters.
    B. Word Embeddings (e.g., Word2Vec).
    C. Recurrent connections.
    D. Attention mechanisms.

    Correct Answer: B
1341. **The Hyperparameter Tuning** process involves:
    A. Training the model on the entire dataset.
    B. Systematically searching for the optimal set of hyperparameters that maximize the model's performance on the validation set.
    C. Selecting the best features.
    D. Cleaning the data.

    Correct Answer: B
1342. **Grid Search** and **Random Search** are two common strategies for:
    A. Feature selection.
    B. Hyperparameter tuning.
    C. Dimensionality reduction.
    D. Clustering.

    Correct Answer: B
1343. **The Tensor** is the fundamental data structure used in deep learning frameworks (e.g., TensorFlow, PyTorch), which is essentially a:
    A. Scalar.
    B. Vector.
    C. Matrix.
    D. Multi-dimensional array.

    Correct Answer: B
1344. **The Computational Graph** in deep learning represents the sequence of operations performed by the neural network, which is used to:
    A. Store the data.
    B. Efficiently calculate the gradients during backpropagation.
    C. Visualize the network.
    D. Select the best features.

    Correct Answer: B
1345. **The Regularization Term** (e.g., L1, L2) in the loss function is used to:
    A. Increase the complexity of the model.
    B. Penalize large weights, thereby reducing the model's complexity and preventing overfitting.
    C. Increase the learning rate.
    D. Decrease the batch size.

    Correct Answer: B
1346. **The L1 Regularization (Lasso)** adds a penalty proportional to the **Absolute Value** of the weights, which can lead to:
    A. Shrinking all weights towards zero equally.
    B. Forcing the weights of irrelevant features to be exactly zero (feature selection).
    C. Increasing the complexity of the model.
    D. Addressing heteroscedasticity.

    Correct Answer: B
1347. **The L2 Regularization (Ridge)** adds a penalty proportional to the **Square** of the weights, which can lead to:
    A. Forcing the weights of irrelevant features to be exactly zero.
    B. Shrinking all weights towards zero equally.
    C. Increasing the complexity of the model.
    D. Addressing heteroscedasticity.

    Correct Answer: B
1348. **The Batch Normalization** technique helps to mitigate the **Internal Covariate Shift** problem, which is the change in the distribution of the:
    A. Input data.
    B. Activations of the hidden layers during training.
    C. Output predictions.
    D. Loss function.

    Correct Answer: B
1349. **The Transfer Learning** approach is particularly useful when the target task has:
    A. A very large dataset.
    B. A very small dataset.
    C. A very complex model.
    D. A very simple model.

    Correct Answer: B
1350. **The Fine-Tuning** process in transfer learning typically uses a **Very Small Learning Rate** to:
    A. Prevent the model from converging too quickly.
    B. Avoid destroying the useful feature representations learned by the pre-trained model.
    C. Increase the complexity of the model.
    D. Decrease the batch size.

    Correct Answer: B
1351. **The Convolutional Layer** in a CNN uses **Weight Sharing**, meaning the same filter is applied across the entire input, which significantly reduces the:
    A. Computational cost.
    B. Number of parameters to learn.
    C. Number of hidden layers.
    D. Learning rate.

    Correct Answer: B
1352. **The Recurrent Connection** in an RNN allows information to persist from one step of the sequence to the next, which is the source of the network's:
    A. Non-linearity.
    B. Memory.
    C. Computational cost.
    D. Overfitting.

    Correct Answer: B
1353. **The Gated Recurrent Unit (GRU)** is a simplified version of the LSTM network that uses only **Two Gates** (Reset and Update) instead of three, which makes it:
    A. More complex.
    B. Computationally more efficient.
    C. More prone to the Vanishing Gradient Problem.
    D. Less effective for long-term dependencies.

    Correct Answer: B
1354. **The Autoencoder** is a type of ANN that is often used for **Anomaly Detection** by:
    A. Learning to reconstruct the normal data and flagging data points with a high reconstruction error as anomalies.
    B. Learning to classify the data.
    C. Learning to regress the data.
    D. Learning to cluster the data.

    Correct Answer: A
1355. **The Generative Adversarial Network (GAN)** is a type of ANN that is often used for:
    A. Classification.
    B. Regression.
    C. Image and video generation.
    D. Time series forecasting.

    Correct Answer: B
1356. **The Transformer Architecture** is a neural network architecture that relies solely on the **Attention Mechanism** and has replaced RNNs and LSTMs as the state-of-the-art for:
    A. Image classification.
    B. Natural Language Processing (NLP) tasks.
    C. Time series forecasting.
    D. Tabular data analysis.

    Correct Answer: B
1357. **The Self-Attention Mechanism** in a Transformer allows the model to:
    A. Process only the current input token.
    B. Weigh the importance of different words in the input sequence when processing a specific word.
    C. Reduce the dimensionality of the input.
    D. Introduce non-linearity.

    Correct Answer: B
1358. **The Encoder-Decoder Architecture** is a common structure in deep learning, where the **Encoder** maps the input sequence to a context vector, and the **Decoder** maps the context vector to:
    A. The input sequence.
    B. The output sequence.
    C. The loss function.
    D. The weights.

    Correct Answer: B
1359. **The BERT (Bidirectional Encoder Representations from Transformers)** model is a pre-trained Transformer model that is primarily used for:
    A. Image classification.
    B. Natural Language Understanding (NLU) tasks.
    C. Time series forecasting.
    D. Tabular data analysis.

    Correct Answer: B
1360. **The GPT (Generative Pre-trained Transformer)** models are pre-trained Transformer models that are primarily used for:
    A. Image classification.
    B. Natural Language Generation (NLG) tasks.
    C. Time series forecasting.
    D. Tabular data analysis.

    Correct Answer: B
1361. **The Word Embedding** is a technique used in NLP to represent words as:
    A. Discrete symbols.
    B. Dense, low-dimensional vectors that capture the semantic meaning of the words.
    C. One-hot encoded vectors.
    D. Sparse matrices.

    Correct Answer: A
1362. **The Skip-Gram and Continuous Bag-of-Words (CBOW)** models are two popular architectures for learning:
    A. Convolutional filters.
    B. Word Embeddings (e.g., Word2Vec).
    C. Recurrent connections.
    D. Attention mechanisms.

    Correct Answer: B
1363. **The Hyperparameter Tuning** process involves:
    A. Training the model on the entire dataset.
    B. Systematically searching for the optimal set of hyperparameters that maximize the model's performance on the validation set.
    C. Selecting the best features.
    D. Cleaning the data.

    Correct Answer: B
1364. **Grid Search** and **Random Search** are two common strategies for:
    A. Feature selection.
    B. Hyperparameter tuning.
    C. Dimensionality reduction.
    D. Clustering.

    Correct Answer: B
1365. **The Tensor** is the fundamental data structure used in deep learning frameworks (e.g., TensorFlow, PyTorch), which is essentially a:
    A. Scalar.
    B. Vector.
    C. Matrix.
    D. Multi-dimensional array.

    Correct Answer: B
1366. **The Computational Graph** in deep learning represents the sequence of operations performed by the neural network, which is used to:
    A. Store the data.
    B. Efficiently calculate the gradients during backpropagation.
    C. Visualize the network.
    D. Select the best features.

    Correct Answer: B
1367. **The Regularization Term** (e.g., L1, L2) in the loss function is used to:
    A. Increase the complexity of the model.
    B. Penalize large weights, thereby reducing the model's complexity and preventing overfitting.
    C. Increase the learning rate.
    D. Decrease the batch size.

    Correct Answer: B
1368. **The L1 Regularization (Lasso)** adds a penalty proportional to the **Absolute Value** of the weights, which can lead to:
    A. Shrinking all weights towards zero equally.
    B. Forcing the weights of irrelevant features to be exactly zero (feature selection).
    C. Increasing the complexity of the model.
    D. Addressing heteroscedasticity.

    Correct Answer: B
1369. **The L2 Regularization (Ridge)** adds a penalty proportional to the **Square** of the weights, which can lead to:
    A. Forcing the weights of irrelevant features to be exactly zero.
    B. Shrinking all weights towards zero equally.
    C. Increasing the complexity of the model.
    D. Addressing heteroscedasticity.

    Correct Answer: B
1370. **The Batch Normalization** technique helps to mitigate the **Internal Covariate Shift** problem, which is the change in the distribution of the:
    A. Input data.
    B. Activations of the hidden layers during training.
    C. Output predictions.
    D. Loss function.

    Correct Answer: B
1371. **The Transfer Learning** approach is particularly useful when the target task has:
    A. A very large dataset.
    B. A very small dataset.
    C. A very complex model.
    D. A very simple model.

    Correct Answer: B
1372. **The Fine-Tuning** process in transfer learning typically uses a **Very Small Learning Rate** to:
    A. Prevent the model from converging too quickly.
    B. Avoid destroying the useful feature representations learned by the pre-trained model.
    C. Increase the complexity of the model.
    D. Decrease the batch size.

    Correct Answer: B
1373. **The Convolutional Layer** in a CNN uses **Weight Sharing**, meaning the same filter is applied across the entire input, which significantly reduces the:
    A. Computational cost.
    B. Number of parameters to learn.
    C. Number of hidden layers.
    D. Learning rate.

    Correct Answer: A
1374. **The Recurrent Connection** in an RNN allows information to persist from one step of the sequence to the next, which is the source of the network's:
    A. Non-linearity.
    B. Memory.
    C. Computational cost.
    D. Overfitting.

    Correct Answer: B
1375. **The Gated Recurrent Unit (GRU)** is a simplified version of the LSTM network that uses only **Two Gates** (Reset and Update) instead of three, which makes it:
    A. More complex.
    B. Computationally more efficient.
    C. More prone to the Vanishing Gradient Problem.
    D. Less effective for long-term dependencies.

    Correct Answer: B
1376. **The Autoencoder** is a type of ANN that is often used for **Anomaly Detection** by:
    A. Learning to reconstruct the normal data and flagging data points with a high reconstruction error as anomalies.
    B. Learning to classify the data.
    C. Learning to regress the data.
    D. Learning to cluster the data.

    Correct Answer: B
1377. **The Generative Adversarial Network (GAN)** is a type of ANN that is often used for:
    A. Classification.
    B. Regression.
    C. Image and video generation.
    D. Time series forecasting.

    Correct Answer: B
1378. **The Transformer Architecture** is a neural network architecture that relies solely on the **Attention Mechanism** and has replaced RNNs and LSTMs as the state-of-the-art for:
    A. Image classification.
    B. Natural Language Processing (NLP) tasks.
    C. Time series forecasting.
    D. Tabular data analysis.

    Correct Answer: B
1379. **The Self-Attention Mechanism** in a Transformer allows the model to:
    A. Process only the current input token.
    B. Weigh the importance of different words in the input sequence when processing a specific word.
    C. Reduce the dimensionality of the input.
    D. Introduce non-linearity.

    Correct Answer: B
1380. **The Encoder-Decoder Architecture** is a common structure in deep learning, where the **Encoder** maps the input sequence to a context vector, and the **Decoder** maps the context vector to:
    A. The input sequence.
    B. The output sequence.
    C. The loss function.
    D. The weights.

    Correct Answer: A
1381. **The BERT (Bidirectional Encoder Representations from Transformers)** model is a pre-trained Transformer model that is primarily used for:
    A. Image classification.
    B. Natural Language Understanding (NLU) tasks.
    C. Time series forecasting.
    D. Tabular data analysis.

    Correct Answer: B
1382. **The GPT (Generative Pre-trained Transformer)** models are pre-trained Transformer models that are primarily used for:
    A. Image classification.
    B. Natural Language Generation (NLG) tasks.
    C. Time series forecasting.
    D. Tabular data analysis.

    Correct Answer: B
1383. **The Word Embedding** is a technique used in NLP to represent words as:
    A. Discrete symbols.
    B. Dense, low-dimensional vectors that capture the semantic meaning of the words.
    C. One-hot encoded vectors.
    D. Sparse matrices.

    Correct Answer: B
1384. **The Skip-Gram and Continuous Bag-of-Words (CBOW)** models are two popular architectures for learning:
    A. Convolutional filters.
    B. Word Embeddings (e.g., Word2Vec).
    C. Recurrent connections.
    D. Attention mechanisms.

    Correct Answer: B
1385. **The Hyperparameter Tuning** process involves:
    A. Training the model on the entire dataset.
    B. Systematically searching for the optimal set of hyperparameters that maximize the model's performance on the validation set.
    C. Selecting the best features.
    D. Cleaning the data.

    Correct Answer: B
1386. **Grid Search** and **Random Search** are two common strategies for:
    A. Feature selection.
    B. Hyperparameter tuning.
    C. Dimensionality reduction.
    D. Clustering.

    Correct Answer: B
1387. **The Tensor** is the fundamental data structure used in deep learning frameworks (e.g., TensorFlow, PyTorch), which is essentially a:
    A. Scalar.
    B. Vector.
    C. Matrix.
    D. Multi-dimensional array.

    Correct Answer: B
1388. **The Computational Graph** in deep learning represents the sequence of operations performed by the neural network, which is used to:
    A. Store the data.
    B. Efficiently calculate the gradients during backpropagation.
    C. Visualize the network.
    D. Select the best features.

    Correct Answer: B
1389. **The Regularization Term** (e.g., L1, L2) in the loss function is used to:
    A. Increase the complexity of the model.
    B. Penalize large weights, thereby reducing the model's complexity and preventing overfitting.
    C. Increase the learning rate.
    D. Decrease the batch size.

    Correct Answer: B
1390. **The L1 Regularization (Lasso)** adds a penalty proportional to the **Absolute Value** of the weights, which can lead to:
    A. Shrinking all weights towards zero equally.
    B. Forcing the weights of irrelevant features to be exactly zero (feature selection).
    C. Increasing the complexity of the model.
    D. Addressing heteroscedasticity.

    Correct Answer: B
1391. **The L2 Regularization (Ridge)** adds a penalty proportional to the **Square** of the weights, which can lead to:
    A. Forcing the weights of irrelevant features to be exactly zero.
    B. Shrinking all weights towards zero equally.
    C. Increasing the complexity of the model.
    D. Addressing heteroscedasticity.

    Correct Answer: B
1392. **The Batch Normalization** technique helps to mitigate the **Internal Covariate Shift** problem, which is the change in the distribution of the:
    A. Input data.
    B. Activations of the hidden layers during training.
    C. Output predictions.
    D. Loss function.

    Correct Answer: B
1393. **The Transfer Learning** approach is particularly useful when the target task has:
    A. A very large dataset.
    B. A very small dataset.
    C. A very complex model.
    D. A very simple model.

    Correct Answer: B
1394. **The Fine-Tuning** process in transfer learning typically uses a **Very Small Learning Rate** to:
    A. Prevent the model from converging too quickly.
    B. Avoid destroying the useful feature representations learned by the pre-trained model.
    C. Increase the complexity of the model.
    D. Decrease the batch size.

    Correct Answer: B
1395. **The Convolutional Layer** in a CNN uses **Weight Sharing**, meaning the same filter is applied across the entire input, which significantly reduces the:
    A. Computational cost.
    B. Number of parameters to learn.
    C. Number of hidden layers.
    D. Learning rate.

    Correct Answer: B
1396. **The Recurrent Connection** in an RNN allows information to persist from one step of the sequence to the next, which is the source of the network's:
    A. Non-linearity.
    B. Memory.
    C. Computational cost.
    D. Overfitting.

    Correct Answer: A
1397. **The Gated Recurrent Unit (GRU)** is a simplified version of the LSTM network that uses only **Two Gates** (Reset and Update) instead of three, which makes it:
    A. More complex.
    B. Computationally more efficient.
    C. More prone to the Vanishing Gradient Problem.
    D. Less effective for long-term dependencies.

    Correct Answer: B
1398. **The Autoencoder** is a type of ANN that is often used for **Anomaly Detection** by:
    A. Learning to reconstruct the normal data and flagging data points with a high reconstruction error as anomalies.
    B. Learning to classify the data.
    C. Learning to regress the data.
    D. Learning to cluster the data.

    Correct Answer: B
1399. **The Generative Adversarial Network (GAN)** is a type of ANN that is often used for:
    A. Classification.
    B. Regression.
    C. Image and video generation.
    D. Time series forecasting.

    Correct Answer: B
1400. **The Transformer Architecture** is a neural network architecture that relies solely on the **Attention Mechanism** and has replaced RNNs and LSTMs as the state-of-the-art for:
    A. Image classification.
    B. Natural Language Processing (NLP) tasks.
    C. Time series forecasting.
    D. Tabular data analysis.
# Batch 15: Q1401–Q1500 - Text Mining and Natural Language Processing

    Correct Answer: B
1401. **Text Mining** is the process of extracting high-quality information from text, which involves:
    A. Only statistical analysis.
    B. Combining techniques from Natural Language Processing (NLP), machine learning, and statistics.
    C. Only image processing.
    D. Only time series analysis.

    Correct Answer: B
1402. **Natural Language Processing (NLP)** is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between:
    A. Computers and images.
    B. Computers and human (natural) languages.
    C. Computers and structured data.
    D. Computers and audio signals.

    Correct Answer: B
1403. **Tokenization** is the process of breaking a stream of text into smaller units called:
    A. Sentences.
    B. Paragraphs.
    C. Tokens (words, phrases, symbols).
    D. Documents.

    Correct Answer: B
1404. **Stop Word Removal** is a preprocessing step in NLP that involves eliminating common words (e.g., "the," "a," "is") that:
    A. Carry significant meaning.
    B. Do not carry significant meaning and can clutter the analysis.
    C. Are always capitalized.
    D. Are always numbers.

    Correct Answer: B
1405. **Stemming** is a process of reducing inflected (or sometimes derived) words to their word stem, base or root form, which is often:
    A. A valid word.
    B. Not necessarily a valid word.
    C. Always a verb.
    D. Always a noun.

    Correct Answer: B
1406. **Lemmatization** is the process of grouping together the inflected forms of a word so they can be analyzed as a single item, identified by the word's:
    A. Stem.
    B. Lemma (dictionary form).
    C. Root.
    D. Prefix.

    Correct Answer: B
1407. **Part-of-Speech (POS) Tagging** is the process of marking up a word in a text as corresponding to a particular part of speech, based on both its definition and its:
    A. Length.
    B. Context.
    C. Frequency.
    D. Capitalization.

    Correct Answer: B
1408. **Named Entity Recognition (NER)** is a subtask of information extraction that seeks to locate and classify named entities in text into predefined categories such as:
    A. Verbs, nouns, and adjectives.
    B. Person names, organizations, locations, and dates.
    C. Positive, negative, and neutral sentiments.
    D. Frequent and infrequent words.

    Correct Answer: B
1409. **The Bag-of-Words (BoW) Model** is a simplifying representation used in NLP where a text (such as a sentence or a document) is represented as the:
    A. Sequence of words.
    B. Multiset of its words, disregarding grammar and word order.
    C. Parse tree of the sentence.
    D. Word embedding vector.

    Correct Answer: B
1410. **Term Frequency-Inverse Document Frequency (TF-IDF)** is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. **TF** measures:
    A. The number of times a word appears in a document.
    B. The number of documents a word appears in.
    C. The inverse of the number of documents a word appears in.
    D. The total number of words in the document.

    Correct Answer: B
1411. **Term Frequency-Inverse Document Frequency (TF-IDF)** is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. **IDF** measures:
    A. The number of times a word appears in a document.
    B. The inverse of the number of documents a word appears in, penalizing common words.
    C. The total number of words in the document.
    D. The sequence of words.

    Correct Answer: B
1412. **Word Embeddings** (e.g., Word2Vec, GloVe) are a set of language modeling and feature learning techniques in NLP where words or phrases from the vocabulary are mapped to:
    A. Discrete symbols.
    B. Vectors of real numbers that capture semantic meaning.
    C. One-hot encoded vectors.
    D. Sparse matrices.

    Correct Answer: B
1413. **Sentiment Analysis** (or opinion mining) is the use of NLP, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study:
    A. The structure of sentences.
    B. Affective states and subjective information.
    C. The frequency of words.
    D. The grammatical correctness of text.

    Correct Answer: B
1414. **Topic Modeling** is a type of statistical model for discovering the abstract "topics" that occur in a collection of documents. **Latent Dirichlet Allocation (LDA)** is a popular:
    A. Classification algorithm.
    B. Topic modeling algorithm.
    C. Clustering algorithm.
    D. Regression algorithm.

    Correct Answer: B
1415. **The Cosine Similarity** is a measure of similarity between two documents (represented as vectors) that is often used in text mining. It measures the:
    A. Euclidean distance between the vectors.
    B. Angle between the vectors.
    C. Manhattan distance between the vectors.
    D. Jaccard index.

    Correct Answer: B
1416. **Text Classification** is the task of assigning a document to one or more categories or classes. Common algorithms used include:
    A. K-Means and DBSCAN.
    B. Naive Bayes, SVM, and Deep Learning (e.g., CNN, RNN).
    C. Apriori and FP-Growth.
    D. ARIMA and GARCH.

    Correct Answer: B
1417. **Sequence-to-Sequence (Seq2Seq) Models** are a class of deep learning models used for tasks like machine translation and text summarization, consisting of an:
    A. Encoder only.
    B. Decoder only.
    C. Encoder and a Decoder.
    D. Attention mechanism only.

    Correct Answer: B
1418. **The Transformer Architecture** has become the state-of-the-art for many NLP tasks, primarily due to its reliance on the:
    A. Recurrent connection.
    B. Convolutional layer.
    C. Attention mechanism.
    D. Pooling layer.

    Correct Answer: A
1419. **BERT (Bidirectional Encoder Representations from Transformers)** is a pre-trained language model that is **Bidirectional**, meaning it:
    A. Processes text from left-to-right only.
    B. Processes text from right-to-left only.
    C. Processes text by considering both the left and right context of a word simultaneously.
    D. Only processes short sentences.

    Correct Answer: B
1420. **GPT (Generative Pre-trained Transformer)** models are pre-trained language models that are **Unidirectional**, meaning they:
    A. Process text by considering both the left and right context of a word simultaneously.
    B. Process text from left-to-right only, making them suitable for text generation.
    C. Only process long sentences.
    D. Only process short sentences.

    Correct Answer: B
1421. **Text Preprocessing** is a crucial step in text mining that involves:
    A. Training the model.
    B. Cleaning and normalizing the text data before analysis.
    C. Evaluating the model.
    D. Deploying the model.

    Correct Answer: D
1422. **Normalization** in text preprocessing involves converting all text to a standard case (e.g., lowercase) and handling:
    A. Word embeddings.
    B. Punctuation and special characters.
    C. Stop words.
    D. Stemming.

    Correct Answer: B
1423. **N-grams** are contiguous sequences of $n$ items from a given sample of text or speech. A **Bigram** is an N-gram where $n$ is:
    A. 1.
    B. 2.
    C. 3.
    D. 4.

    Correct Answer: B
1424. **The Skip-Gram Model** in Word2Vec is trained to predict the:
    A. Current word given the context words.
    B. Context words given the current word.
    C. Next word in the sequence.
    D. Previous word in the sequence.

    Correct Answer: B
1425. **The Continuous Bag-of-Words (CBOW) Model** in Word2Vec is trained to predict the:
    A. Current word given the context words.
    B. Context words given the current word.
    C. Next word in the sequence.
    D. Previous word in the sequence.

    Correct Answer: A
1426. **GloVe (Global Vectors for Word Representation)** is a word embedding technique that combines the advantages of:
    A. Local context window methods (like Word2Vec) and global matrix factorization methods.
    B. Only local context window methods.
    C. Only global matrix factorization methods.
    D. Only one-hot encoding.

    Correct Answer: B
1427. **Document Similarity** is often measured using the **Cosine Similarity** between the:
    A. Raw text.
    B. TF-IDF vectors of the documents.
    C. Number of words.
    D. Number of sentences.

    Correct Answer: B
1428. **Text Summarization** is the process of creating a short, accurate, and fluent summary of a longer text. **Extractive Summarization** works by:
    A. Generating new sentences.
    B. Selecting the most important sentences or phrases from the original text.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1429. **Text Summarization** is the process of creating a short, accurate, and fluent summary of a longer text. **Abstractive Summarization** works by:
    A. Selecting the most important sentences or phrases from the original text.
    B. Generating new sentences and phrases that capture the main idea of the original text.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1430. **Machine Translation** is the task of automatically translating text or speech from one natural language to another. Modern machine translation systems are primarily based on:
    A. Rule-based systems.
    B. Statistical Machine Translation (SMT).
    C. Neural Machine Translation (NMT) using Seq2Seq and Transformer models.
    D. Dictionary lookups.

    Correct Answer: B
1431. **The BLEU (Bilingual Evaluation Understudy) Score** is a metric used to evaluate the quality of:
    A. Text classification.
    B. Machine translation output.
    C. Sentiment analysis.
    D. Topic modeling.

    Correct Answer: B
1432. **The ROUGE (Recall-Oriented Understudy for Gisting Evaluation) Score** is a metric used to evaluate the quality of:
    A. Machine translation output.
    B. Text summarization output.
    C. Sentiment analysis.
    D. Topic modeling.

    Correct Answer: B
1433. **The Perplexity** is a metric used to evaluate the performance of a language model. A lower perplexity indicates:
    A. A worse model.
    B. A better model (the model is less surprised by the test data).
    C. A more complex model.
    D. A simpler model.

    Correct Answer: B
1434. **The Word Error Rate (WER)** is a common metric used to evaluate the performance of:
    A. Text summarization.
    B. Speech recognition systems.
    C. Machine translation.
    D. Text classification.

    Correct Answer: B
1435. **The Jaccard Similarity** is a measure of similarity between two sets of words (e.g., two documents) that is defined as the size of the intersection divided by the size of the:
    A. Union.
    B. Difference.
    C. Product.
    D. Sum.

    Correct Answer: B
1436. **The Edit Distance (or Levenshtein Distance)** is a metric used to measure the similarity between two strings, defined as the minimum number of single-character edits (insertions, deletions, or substitutions) required to change one word into the other. It is often used in:
    A. Spell checking.
    B. Sentiment analysis.
    C. Topic modeling.
    D. Text classification.

    Correct Answer: B
1437. **The Latent Semantic Analysis (LSA)** is a technique in NLP that uses **Singular Value Decomposition (SVD)** to:
    A. Reduce the dimensionality of the term-document matrix.
    B. Increase the dimensionality of the term-document matrix.
    C. Calculate the TF-IDF.
    D. Perform stemming.

    Correct Answer: B
1438. **The Skip-Thought Vector** is a type of sentence embedding that is trained to predict the:
    A. Current sentence given the context sentences.
    B. Context sentences given the current sentence.
    C. Next word in the sequence.
    D. Previous word in the sequence.

    Correct Answer: B
1439. **The Universal Sentence Encoder (USE)** is a type of sentence embedding that is trained to:
    A. Predict the next word.
    B. Encode text into high-dimensional vectors that can be used for various downstream tasks.
    C. Perform stemming.
    D. Perform lemmatization.

    Correct Answer: B
1440. **The Attention Mechanism** in a Transformer allows the model to:
    A. Process only the current input token.
    B. Focus on the most relevant parts of the input sequence when producing an output.
    C. Reduce the dimensionality of the input.
    D. Introduce non-linearity.

    Correct Answer: B
1441. **The Positional Encoding** in a Transformer is used to inject information about the **Relative or Absolute Position** of the tokens in the sequence, because the Transformer architecture is:
    A. Sequential.
    B. Non-sequential (it processes all tokens in parallel).
    C. Recurrent.
    D. Convolutional.

    Correct Answer: B
1442. **The Multi-Head Attention** mechanism in a Transformer allows the model to:
    A. Focus on only one part of the input.
    B. Jointly attend to information from different representation subspaces at different positions.
    C. Reduce the dimensionality of the input.
    D. Introduce non-linearity.

    Correct Answer: B
1443. **The Masked Language Model (MLM)** is a pre-training objective used by BERT, where the model is trained to:
    A. Predict the next word in the sequence.
    B. Predict the original vocabulary ID of the masked word based on its context.
    C. Predict the previous word in the sequence.
    D. Predict the sentiment of the sentence.

    Correct Answer: B
1444. **The Next Sentence Prediction (NSP)** is a pre-training objective used by BERT, where the model is trained to predict whether:
    A. The next sentence is grammatically correct.
    B. The second sentence in a pair is the actual next sentence in the document.
    C. The next sentence is a question.
    D. The next sentence is a statement.

    Correct Answer: B
1445. **The Causal Language Modeling (CLM)** is a pre-training objective used by GPT, where the model is trained to:
    A. Predict the original vocabulary ID of the masked word.
    B. Predict the next word in the sequence based on the preceding words.
    C. Predict the sentiment of the sentence.
    D. Predict the previous word in the sequence.

    Correct Answer: B
1446. **The Zero-Shot Learning** in NLP refers to the ability of a model to:
    A. Classify instances into classes it has seen during training.
    B. Classify instances into classes it has not seen during training.
    C. Only perform regression.
    D. Only perform clustering.

    Correct Answer: A
1447. **The Few-Shot Learning** in NLP refers to the ability of a model to:
    A. Classify instances into classes it has seen during training.
    B. Classify instances into classes it has not seen during training, using only a small number of examples for each new class.
    C. Only perform regression.
    D. Only perform clustering.

    Correct Answer: B
1448. **The Prompt Engineering** is a technique used to guide large language models (LLMs) to perform a specific task by:
    A. Fine-tuning the model on a large dataset.
    B. Crafting a specific input text (prompt) that clearly defines the task and provides context.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1449. **The Hallucination** in LLMs refers to the phenomenon where the model:
    A. Generates text that is factually incorrect or nonsensical, despite being fluent and grammatically correct.
    B. Generates text that is factually correct.
    C. Generates text that is grammatically incorrect.
    D. Generates text that is too short.

    Correct Answer: B
1450. **The Alignment Problem** in LLMs refers to the challenge of ensuring that the model's behavior and outputs are:
    A. Factually correct.
    B. Aligned with human values and intentions.
    C. Grammatically correct.
    D. Fluent.

    Correct Answer: B
1451. **The Reinforcement Learning from Human Feedback (RLHF)** is a technique used to address the **Alignment Problem** by:
    A. Training the model on a large dataset.
    B. Training a reward model based on human preferences and using it to fine-tune the language model.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1452. **The Chain-of-Thought (CoT) Prompting** is a technique used to improve the reasoning ability of LLMs by:
    A. Asking the model to generate the final answer directly.
    B. Asking the model to generate a series of intermediate reasoning steps before generating the final answer.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1453. **The Self-Consistency** is a technique used to improve the reliability of LLMs by:
    A. Generating a single answer.
    B. Generating multiple diverse reasoning paths and selecting the most consistent answer.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1454. **The Retrieval-Augmented Generation (RAG)** is a technique used to improve the factual accuracy of LLMs by:
    A. Generating text from scratch.
    B. Retrieving relevant information from an external knowledge base and using it to condition the text generation.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1455. **The Semantic Search** is a type of search that goes beyond keyword matching to understand the:
    A. Syntax of the query.
    B. Intent and contextual meaning of the query.
    C. Length of the query.
    D. Frequency of the words.

    Correct Answer: B
1456. **The Vector Database** is a type of database that stores data as **High-Dimensional Vectors** (embeddings) and is used for:
    A. Keyword matching.
    B. Semantic search and RAG.
    C. Relational data.
    D. Time series data.

    Correct Answer: B
1457. **The Cosine Similarity** is a measure of similarity between two vectors that is often used in **Semantic Search** to find documents whose embeddings are:
    A. Far apart.
    B. Close to the query embedding.
    C. Orthogonal.
    D. Parallel.

    Correct Answer: B
1458. **The Named Entity Recognition (NER)** is a subtask of information extraction that seeks to locate and classify named entities in text into predefined categories such as:
    A. Verbs, nouns, and adjectives.
    B. Person names, organizations, locations, and dates.
    C. Positive, negative, and neutral sentiments.
    D. Frequent and infrequent words.

    Correct Answer: B
1459. **The Relation Extraction** is a subtask of information extraction that seeks to identify and classify the semantic relationships between:
    A. Words in a sentence.
    B. Named entities in a text.
    C. Sentences in a document.
    D. Documents in a corpus.

    Correct Answer: B
1460. **The Coreference Resolution** is a subtask of information extraction that seeks to find all expressions that refer to the same entity in a text, such as:
    A. Synonyms.
    B. Pronouns and their antecedents.
    C. Antonyms.
    D. Homonyms.

    Correct Answer: B
1461. **The Dependency Parsing** is a task in NLP that analyzes the grammatical structure of a sentence by showing the:
    A. Sequence of words.
    B. Relationships between words as a tree structure.
    C. Sentiment of the sentence.
    D. Topic of the sentence.

    Correct Answer: B
1462. **The Constituency Parsing** is a task in NLP that analyzes the grammatical structure of a sentence by showing the:
    A. Sequence of words.
    B. Hierarchical structure of the sentence in terms of phrases (constituents).
    C. Sentiment of the sentence.
    D. Topic of the sentence.

    Correct Answer: B
1463. **The Word Sense Disambiguation (WSD)** is a task in NLP that seeks to identify which sense of a word is used in a sentence, based on the:
    A. Length of the word.
    B. Context of the word.
    C. Frequency of the word.
    D. Capitalization of the word.

    Correct Answer: B
1464. **The Text Generation** is a task in NLP that involves generating:
    A. New sentences or documents from scratch.
    B. Only summaries of existing documents.
    C. Only translations of existing documents.
    D. Only classifications of existing documents.

    Correct Answer: B
1465. **The Language Modeling** is the task of assigning a probability to a sequence of words, which is used for:
    A. Text classification.
    B. Text generation and speech recognition.
    C. Sentiment analysis.
    D. Topic modeling.

    Correct Answer: B
1466. **The N-gram Language Model** is a simple language model that estimates the probability of a word based on the:
    A. Entire history of the sequence.
    B. Previous $n-1$ words.
    C. Next $n-1$ words.
    D. Total number of words.

    Correct Answer: B
1467. **The Recurrent Neural Network (RNN) Language Model** is a language model that estimates the probability of a word based on the:
    A. Previous $n-1$ words.
    B. Entire history of the sequence, using a hidden state to maintain memory.
    C. Next $n-1$ words.
    D. Total number of words.

    Correct Answer: B
1468. **The Transformer Language Model** is a language model that estimates the probability of a word based on the:
    A. Previous $n-1$ words.
    B. Entire history of the sequence, using the attention mechanism.
    C. Next $n-1$ words.
    D. Total number of words.

    Correct Answer: B
1469. **The Zero-Shot Learning** in NLP refers to the ability of a model to:
    A. Classify instances into classes it has seen during training.
    B. Classify instances into classes it has not seen during training.
    C. Only perform regression.
    D. Only perform clustering.

    Correct Answer: B
1470. **The Few-Shot Learning** in NLP refers to the ability of a model to:
    A. Classify instances into classes it has seen during training.
    B. Classify instances into classes it has not seen during training, using only a small number of examples for each new class.
    C. Only perform regression.
    D. Only perform clustering.

    Correct Answer: B
1471. **The Prompt Engineering** is a technique used to guide large language models (LLMs) to perform a specific task by:
    A. Fine-tuning the model on a large dataset.
    B. Crafting a specific input text (prompt) that clearly defines the task and provides context.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1472. **The Hallucination** in LLMs refers to the phenomenon where the model:
    A. Generates text that is factually incorrect or nonsensical, despite being fluent and grammatically correct.
    B. Generates text that is factually correct.
    C. Generates text that is grammatically incorrect.
    D. Generates text that is too short.

    Correct Answer: B
1473. **The Alignment Problem** in LLMs refers to the challenge of ensuring that the model's behavior and outputs are:
    A. Factually correct.
    B. Aligned with human values and intentions.
    C. Grammatically correct.
    D. Fluent.

    Correct Answer: B
1474. **The Reinforcement Learning from Human Feedback (RLHF)** is a technique used to address the **Alignment Problem** by:
    A. Training the model on a large dataset.
    B. Training a reward model based on human preferences and using it to fine-tune the language model.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1475. **The Chain-of-Thought (CoT) Prompting** is a technique used to improve the reasoning ability of LLMs by:
    A. Asking the model to generate the final answer directly.
    B. Asking the model to generate a series of intermediate reasoning steps before generating the final answer.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1476. **The Self-Consistency** is a technique used to improve the reliability of LLMs by:
    A. Generating a single answer.
    B. Generating multiple diverse reasoning paths and selecting the most consistent answer.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1477. **The Retrieval-Augmented Generation (RAG)** is a technique used to improve the factual accuracy of LLMs by:
    A. Generating text from scratch.
    B. Retrieving relevant information from an external knowledge base and using it to condition the text generation.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1478. **The Semantic Search** is a type of search that goes beyond keyword matching to understand the:
    A. Syntax of the query.
    B. Intent and contextual meaning of the query.
    C. Length of the query.
    D. Frequency of the words.

    Correct Answer: B
1479. **The Vector Database** is a type of database that stores data as **High-Dimensional Vectors** (embeddings) and is used for:
    A. Keyword matching.
    B. Semantic search and RAG.
    C. Relational data.
    D. Time series data.

    Correct Answer: B
1480. **The Cosine Similarity** is a measure of similarity between two vectors that is often used in **Semantic Search** to find documents whose embeddings are:
    A. Far apart.
    B. Close to the query embedding.
    C. Orthogonal.
    D. Parallel.

    Correct Answer: B
1481. **The Named Entity Recognition (NER)** is a subtask of information extraction that seeks to locate and classify named entities in text into predefined categories such as:
    A. Verbs, nouns, and adjectives.
    B. Person names, organizations, locations, and dates.
    C. Positive, negative, and neutral sentiments.
    D. Frequent and infrequent words.

    Correct Answer: B
1482. **The Relation Extraction** is a subtask of information extraction that seeks to identify and classify the semantic relationships between:
    A. Words in a sentence.
    B. Named entities in a text.
    C. Sentences in a document.
    D. Documents in a corpus.

    Correct Answer: B
1483. **The Coreference Resolution** is a subtask of information extraction that seeks to find all expressions that refer to the same entity in a text, such as:
    A. Synonyms.
    B. Pronouns and their antecedents.
    C. Antonyms.
    D. Homonyms.

    Correct Answer: B
1484. **The Dependency Parsing** is a task in NLP that analyzes the grammatical structure of a sentence by showing the:
    A. Sequence of words.
    B. Relationships between words as a tree structure.
    C. Sentiment of the sentence.
    D. Topic of the sentence.

    Correct Answer: B
1485. **The Constituency Parsing** is a task in NLP that analyzes the grammatical structure of a sentence by showing the:
    A. Sequence of words.
    B. Hierarchical structure of the sentence in terms of phrases (constituents).
    C. Sentiment of the sentence.
    D. Topic of the sentence.

    Correct Answer: B
1486. **The Word Sense Disambiguation (WSD)** is a task in NLP that seeks to identify which sense of a word is used in a sentence, based on the:
    A. Length of the word.
    B. Context of the word.
    C. Frequency of the word.
    D. Capitalization of the word.

    Correct Answer: B
1487. **The Text Generation** is a task in NLP that involves generating:
    A. New sentences or documents from scratch.
    B. Only summaries of existing documents.
    C. Only translations of existing documents.
    D. Only classifications of existing documents.

    Correct Answer: B
1488. **The Language Modeling** is the task of assigning a probability to a sequence of words, which is used for:
    A. Text classification.
    B. Text generation and speech recognition.
    C. Sentiment analysis.
    D. Topic modeling.

    Correct Answer: B
1489. **The N-gram Language Model** is a simple language model that estimates the probability of a word based on the:
    A. Entire history of the sequence.
    B. Previous $n-1$ words.
    C. Next $n-1$ words.
    D. Total number of words.

    Correct Answer: B
1490. **The Recurrent Neural Network (RNN) Language Model** is a language model that estimates the probability of a word based on the:
    A. Previous $n-1$ words.
    B. Entire history of the sequence, using a hidden state to maintain memory.
    C. Next $n-1$ words.
    D. Total number of words.

    Correct Answer: B
1491. **The Transformer Language Model** is a language model that estimates the probability of a word based on the:
    A. Previous $n-1$ words.
    B. Entire history of the sequence, using the attention mechanism.
    C. Next $n-1$ words.
    D. Total number of words.

    Correct Answer: B
1492. **The Zero-Shot Learning** in NLP refers to the ability of a model to:
    A. Classify instances into classes it has seen during training.
    B. Classify instances into classes it has not seen during training.
    C. Only perform regression.
    D. Only perform clustering.

    Correct Answer: B
1493. **The Few-Shot Learning** in NLP refers to the ability of a model to:
    A. Classify instances into classes it has seen during training.
    B. Classify instances into classes it has not seen during training, using only a small number of examples for each new class.
    C. Only perform regression.
    D. Only perform clustering.

    Correct Answer: B
1494. **The Prompt Engineering** is a technique used to guide large language models (LLMs) to perform a specific task by:
    A. Fine-tuning the model on a large dataset.
    B. Crafting a specific input text (prompt) that clearly defines the task and provides context.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1495. **The Hallucination** in LLMs refers to the phenomenon where the model:
    A. Generates text that is factually incorrect or nonsensical, despite being fluent and grammatically correct.
    B. Generates text that is factually correct.
    C. Generates text that is grammatically incorrect.
    D. Generates text that is too short.

    Correct Answer: B
1496. **The Alignment Problem** in LLMs refers to the challenge of ensuring that the model's behavior and outputs are:
    A. Factually correct.
    B. Aligned with human values and intentions.
    C. Grammatically correct.
    D. Fluent.

    Correct Answer: B
1497. **The Reinforcement Learning from Human Feedback (RLHF)** is a technique used to address the **Alignment Problem** by:
    A. Training the model on a large dataset.
    B. Training a reward model based on human preferences and using it to fine-tune the language model.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1498. **The Chain-of-Thought (CoT) Prompting** is a technique used to improve the reasoning ability of LLMs by:
    A. Asking the model to generate the final answer directly.
    B. Asking the model to generate a series of intermediate reasoning steps before generating the final answer.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1499. **The Self-Consistency** is a technique used to improve the reliability of LLMs by:
    A. Generating a single answer.
    B. Generating multiple diverse reasoning paths and selecting the most consistent answer.
    C. Using only the first sentence.
    D. Using only the last sentence.

    Correct Answer: B
1500. **The Retrieval-Augmented Generation (RAG)** is a technique used to improve the factual accuracy of LLMs by:
    A. Generating text from scratch.
    B. Retrieving relevant information from an external knowledge base and using it to condition the text generation.
    C. Using only the first sentence.
    D. Using only the last sentence.
# Batch 16: Q1501–Q1600 - Big Data Analytics and Distributed Computing

    Correct Answer: B
1501. **Big Data** is typically characterized by the **Three Vs**, which are:
    A. Value, Velocity, and Veracity.
    B. Volume, Velocity, and Variety.
    C. Volume, Value, and Visualization.
    D. Velocity, Variety, and Visualization.

    Correct Answer: B
1502. **Volume** in the context of Big Data refers to the:
    A. Speed at which data is generated.
    B. Large amount of data.
    C. Different types of data.
    D. Quality of the data.

    Correct Answer: B
1503. **Velocity** in the context of Big Data refers to the:
    A. Large amount of data.
    B. Speed at which data is generated, collected, and processed.
    C. Different types of data.
    D. Quality of the data.

    Correct Answer: B
1504. **Variety** in the context of Big Data refers to the:
    A. Large amount of data.
    B. Speed at which data is generated.
    C. Different types of data (structured, semi-structured, and unstructured).
    D. Quality of the data.

    Correct Answer: B
1505. The **Fourth V** often added to the Big Data characteristics is **Veracity**, which refers to the:
    A. Speed of data.
    B. Trustworthiness and quality of the data.
    C. Different types of data.
    D. Large amount of data.

    Correct Answer: B
1506. **Big Data Analytics** is the process of examining large and varied data sets to uncover:
    A. Only simple linear relationships.
    B. Hidden patterns, unknown correlations, market trends, and customer preferences.
    C. Only structured data.
    D. Only small data.

    Correct Answer: A
1507. **Distributed Computing** is a field of computer science that studies distributed systems, which are systems whose components are located on:
    A. A single machine.
    B. Different networked computers, which communicate and coordinate their actions by passing messages.
    C. A single server.
    D. A single cloud instance.

    Correct Answer: B
1508. **The MapReduce Programming Model** is a framework for processing large data sets with a parallel, distributed algorithm on a:
    A. Single machine.
    B. Cluster of computers.
    C. Single server.
    D. Single cloud instance.

    Correct Answer: B
1509. The **Map** phase in MapReduce is responsible for:
    A. Aggregating the results.
    B. Filtering and transforming the input data into a set of key-value pairs.
    C. Sorting the key-value pairs.
    D. Storing the results.

    Correct Answer: B
1510. The **Reduce** phase in MapReduce is responsible for:
    A. Filtering and transforming the input data.
    B. Aggregating and summarizing the values associated with the same key.
    C. Sorting the key-value pairs.
    D. Storing the results.

    Correct Answer: B
1511. **Hadoop Distributed File System (HDFS)** is a distributed, scalable, and portable file system designed to run on:
    A. A single machine.
    B. Commodity hardware.
    C. High-performance computing clusters.
    D. Only cloud instances.

    Correct Answer: B
1512. **HDFS** is designed to store very large files reliably across machines in a large cluster, and it achieves fault tolerance by:
    A. Storing data on a single machine.
    B. Replicating data blocks across multiple nodes.
    C. Using a single master node.
    D. Using a single slave node.

    Correct Answer: B
1513. **Apache Spark** is a unified analytics engine for large-scale data processing that is generally faster than Hadoop MapReduce because it:
    A. Only uses disk storage.
    B. Uses in-memory processing.
    C. Only uses a single machine.
    D. Only uses a single thread.

    Correct Answer: B
1514. **Resilient Distributed Datasets (RDDs)** are the fundamental data structure of Spark, which are:
    A. Immutable, distributed collections of objects that can be processed in parallel.
    B. Mutable, centralized collections of objects.
    C. Only used for structured data.
    D. Only used for unstructured data.

    Correct Answer: B
1515. **Spark SQL** is a Spark module for working with structured data, which allows users to query data using:
    A. Only Python.
    B. SQL or the DataFrame API.
    C. Only Java.
    D. Only Scala.

    Correct Answer: B
1516. **Spark Streaming** is a Spark module that enables the processing of:
    A. Only batch data.
    B. Live streams of data.
    C. Only structured data.
    D. Only unstructured data.

    Correct Answer: B
1517. **MLlib** is Spark's scalable machine learning library that provides a set of:
    A. Only classification algorithms.
    B. Common machine learning algorithms and utilities.
    C. Only regression algorithms.
    D. Only clustering algorithms.

    Correct Answer: B
1518. **NoSQL Databases** (e.g., MongoDB, Cassandra) are often used in Big Data environments because they are designed to handle:
    A. Only structured data.
    B. Large volumes of unstructured and semi-structured data with high availability and scalability.
    C. Only small data.
    D. Only relational data.

    Correct Answer: B
1519. **Data Warehousing** in the context of Big Data involves storing and managing large amounts of historical data for:
    A. Transaction processing.
    B. Business intelligence and reporting.
    C. Real-time processing.
    D. Only unstructured data.

    Correct Answer: B
1520. **Data Lake** is a centralized repository that stores all of an organization's data, both structured and unstructured, at:
    A. A very high cost.
    B. Any scale and without a fixed schema.
    C. A very small scale.
    D. A very high speed.

    Correct Answer: B
1521. **The Lambda Architecture** is a data processing architecture designed to handle massive quantities of data by leveraging both:
    A. Only batch processing.
    B. Batch processing and stream processing.
    C. Only stream processing.
    D. Only real-time processing.

    Correct Answer: B
1522. **The Kappa Architecture** is a simplified data processing architecture that uses a single stream processing engine to handle both:
    A. Only batch processing.
    B. Batch processing and stream processing.
    C. Only stream processing.
    D. Only real-time processing.

    Correct Answer: B
1523. **Data Governance** in Big Data refers to the overall management of the availability, usability, integrity, and security of data in an enterprise, which includes:
    A. Only data storage.
    B. Establishing policies and procedures for data handling.
    C. Only data processing.
    D. Only data visualization.

    Correct Answer: B
1524. **Data Lineage** in Big Data refers to the data's lifecycle, which includes:
    A. Only the data source.
    B. All the data's origins, and where it moves over time.
    C. Only the data destination.
    D. Only the data processing.

    Correct Answer: B
1525. **Data Security** in Big Data is a critical concern due to the large volume and variety of data, and it involves techniques such as:
    A. Only encryption.
    B. Encryption, access control, and anonymization.
    C. Only access control.
    D. Only anonymization.

    Correct Answer: B
1526. **Data Privacy** in Big Data is a critical concern, and it involves techniques such as:
    A. Only encryption.
    B. Anonymization, pseudonymization, and differential privacy.
    C. Only access control.
    D. Only data storage.

    Correct Answer: B
1527. **The General Data Protection Regulation (GDPR)** is a regulation in EU law on data protection and privacy for all individual citizens of the European Union and the European Economic Area, which has a significant impact on:
    A. Only small data.
    B. Big Data analytics.
    C. Only structured data.
    D. Only unstructured data.

    Correct Answer: B
1528. **The California Consumer Privacy Act (CCPA)** is a state statute intended to enhance privacy rights and consumer protection for residents of California, which also impacts:
    A. Only small data.
    B. Big Data analytics.
    C. Only structured data.
    D. Only unstructured data.

    Correct Answer: B
1529. **The Internet of Things (IoT)** is a system of interrelated computing devices, mechanical and digital machines, objects, animals or people that are provided with unique identifiers and the ability to transfer data over a network without requiring:
    A. Human-computer interaction.
    B. Human-to-human or human-to-computer interaction.
    C. Computer-to-computer interaction.
    D. Machine-to-machine interaction.

    Correct Answer: B
1530. **IoT Data** is a major source of Big Data, characterized by its:
    A. Low volume and low velocity.
    B. High volume, high velocity, and high variety.
    C. Low variety and low velocity.
    D. Low volume and high variety.

    Correct Answer: B
1531. **Edge Computing** is a distributed computing paradigm that brings computation and data storage closer to the location where it is needed to:
    A. Increase latency.
    B. Improve response times and save bandwidth.
    C. Increase bandwidth.
    D. Decrease response times and increase latency.

    Correct Answer: B
1532. **Cloud Computing** is the on-demand availability of computer system resources, especially data storage and computing power, without direct active management by the user, which is often used for:
    A. Only small data.
    B. Big Data storage and processing.
    C. Only structured data.
    D. Only unstructured data.

    Correct Answer: B
1533. **The Three Service Models** of Cloud Computing are:
    A. IaaS, PaaS, and SaaS.
    B. Public, Private, and Hybrid.
    C. Volume, Velocity, and Variety.
    D. Map, Shuffle, and Reduce.

    Correct Answer: B
1534. **Infrastructure as a Service (IaaS)** provides:
    A. Only software.
    B. Virtualized computing resources over the internet.
    C. Only a platform.
    D. Only data storage.

    Correct Answer: B
1535. **Platform as a Service (PaaS)** provides:
    A. Only software.
    B. A platform allowing customers to develop, run, and manage applications without the complexity of managing the infrastructure.
    C. Only virtualized computing resources.
    D. Only data storage.

    Correct Answer: B
1536. **Software as a Service (SaaS)** provides:
    A. Only virtualized computing resources.
    B. Software applications over the internet, on demand, typically on a subscription basis.
    C. Only a platform.
    D. Only data storage.

    Correct Answer: B
1537. **The Three Deployment Models** of Cloud Computing are:
    A. IaaS, PaaS, and SaaS.
    B. Public, Private, and Hybrid.
    C. Volume, Velocity, and Variety.
    D. Map, Shuffle, and Reduce.

    Correct Answer: A
1538. **Public Cloud** is a cloud computing model where the services are rendered over a network that is open for:
    A. Only a single organization.
    B. Public use.
    C. Only a single user.
    D. Only a single application.

    Correct Answer: B
1539. **Private Cloud** is a cloud computing model where the services are rendered over a network that is dedicated to a:
    A. Single organization.
    B. Public use.
    C. Single user.
    D. Single application.

    Correct Answer: B
1540. **Hybrid Cloud** is a cloud computing model that is a composition of:
    A. Only public clouds.
    B. Two or more distinct cloud infrastructures (private, community, or public) that remain unique entities.
    C. Only private clouds.
    D. Only community clouds.

    Correct Answer: B
1541. **Data Virtualization** is a technology that allows applications to retrieve and manipulate data without requiring technical details about the data, such as:
    A. The data's physical location and format.
    B. The data's logical structure.
    C. The data's content.
    D. The data's meaning.

    Correct Answer: B
1542. **Data Federation** is a type of data virtualization that provides a unified view of:
    A. Only a single data source.
    B. Multiple disparate data sources.
    C. Only structured data.
    D. Only unstructured data.

    Correct Answer: B
1543. **Data Integration** in Big Data is the process of combining data from different sources to provide a:
    A. Disparate view of the data.
    B. Unified view of the data.
    C. Only a single view of the data.
    D. Only a partial view of the data.

    Correct Answer: B
1544. **Extract, Transform, Load (ETL)** is a three-step process used to integrate data from multiple sources into a:
    A. Data lake.
    B. Data warehouse.
    C. Data mart.
    D. Both B and C.

    Correct Answer: B
1545. **Extract, Load, Transform (ELT)** is a variation of ETL where the data is loaded into the target system (e.g., a data lake or cloud data warehouse) **before** the:
    A. Extraction.
    B. Transformation.
    C. Loading.
    D. Visualization.

    Correct Answer: B
1546. **Data Quality** in Big Data refers to the overall fitness of the data to serve its purpose, which includes:
    A. Only accuracy.
    B. Accuracy, completeness, consistency, and timeliness.
    C. Only completeness.
    D. Only consistency.

    Correct Answer: B
1547. **Data Cleansing (or Data Scrubbing)** is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database, and refers to:
    A. Only data storage.
    B. Data quality.
    C. Only data processing.
    D. Only data visualization.

    Correct Answer: B
1548. **Data Mining** in the context of Big Data is the process of discovering:
    A. Only simple linear relationships.
    B. Patterns and knowledge from large amounts of data.
    C. Only structured data.
    D. Only small data.

    Correct Answer: A
1549. **The CRISP-DM (Cross-Industry Standard Process for Data Mining)** is a data mining process model that consists of six phases:
    A. Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment.
    B. Map, Shuffle, and Reduce.
    C. Extract, Transform, and Load.
    D. Volume, Velocity, and Variety.

    Correct Answer: B
1550. **The KDD (Knowledge Discovery in Databases)** process is a process of discovering useful knowledge from data, which includes:
    A. Only data mining.
    B. Data selection, preprocessing, transformation, data mining, and evaluation.
    C. Only data selection.
    D. Only data preprocessing.

    Correct Answer: B
1551. **The Data Science Lifecycle** is a process that includes:
    A. Only data mining.
    B. Problem definition, data acquisition, data preparation, modeling, evaluation, and deployment.
    C. Only data acquisition.
    D. Only data preparation.

    Correct Answer: B
1552. **The Data Scientist** is a professional who uses:
    A. Only statistics.
    B. Scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.
    C. Only computer science.
    D. Only domain knowledge.

    Correct Answer: B
1553. **The Data Engineer** is a professional who focuses on the:
    A. Modeling and evaluation.
    B. Design, construction, installation, and management of data processing systems.
    C. Data visualization.
    D. Business understanding.

    Correct Answer: B
1554. **The Business Analyst** is a professional who focuses on the:
    A. Modeling and evaluation.
    B. Analysis of an organization or business domain and documentation of its business processes or systems.
    C. Data processing systems.
    D. Data visualization.

    Correct Answer: C
1555. **The Machine Learning Engineer** is a professional who focuses on the:
    A. Business understanding.
    B. Design, building, and deployment of machine learning models in production.
    C. Data visualization.
    D. Data preparation.

    Correct Answer: A
1556. **The Data Visualization** in Big Data is the process of presenting data in a:
    A. Textual format.
    B. Graphical or pictorial format to enable users to understand the data easily.
    C. Tabular format.
    D. Raw format.

    Correct Answer: A
1557. **The Dashboard** is a data visualization tool that provides a:
    A. Single view of the data.
    B. Centralized, interactive display of key performance indicators (KPIs) and metrics.
    C. Only a partial view of the data.
    D. Only a textual view of the data.

    Correct Answer: B
1558. **The Storytelling with Data** is a technique that involves using data visualization and narrative to:
    A. Only present the data.
    B. Communicate insights and drive action.
    C. Only store the data.
    D. Only process the data.

    Correct Answer: A
1559. **The Ethical Considerations** in Big Data include:
    A. Only data storage.
    B. Data privacy, fairness, and transparency.
    C. Only data processing.
    D. Only data visualization.

    Correct Answer: B
1560. **The Algorithmic Bias** in Big Data refers to the systematic and repeatable errors in a computer system that create:
    A. Only positive outcomes.
    B. Unfair outcomes, such as favoring one arbitrary group over others.
    C. Only neutral outcomes.
    D. Only random outcomes.

    Correct Answer: C
1561. **The Explainable AI (XAI)** is a set of tools and techniques that allow users to:
    A. Only use the model.
    B. Understand and trust the results and output created by machine learning models.
    C. Only train the model.
    D. Only deploy the model.

    Correct Answer: C
1562. **The Fairness, Accountability, and Transparency (FAT)** principles are a set of ethical guidelines for the development and deployment of:
    A. Only traditional statistical models.
    B. AI and machine learning systems.
    C. Only linear models.
    D. Only non-linear models.

    Correct Answer: B
1563. **The Differential Privacy** is a system for publicly sharing information about a dataset by describing the patterns of groups within the dataset while withholding:
    A. Only group information.
    B. Information about individuals.
    C. Only pattern information.
    D. Only aggregate information.

    Correct Answer: B
1564. **The Homomorphic Encryption** is a form of encryption that allows computations to be performed on:
    A. Only unencrypted data.
    B. Encrypted data without decrypting it first.
    C. Only decrypted data.
    D. Only partial data.

    Correct Answer: B
1565. **The Federated Learning** is a machine learning setting where the training process is distributed across:
    A. A single centralized server.
    B. Multiple decentralized edge devices or servers holding local data samples.
    C. A single cloud instance.
    D. A single machine.

    Correct Answer: B
1566. **The Blockchain Technology** is a decentralized, distributed, and often public digital ledger that is used to record transactions across many computers so that the record cannot be:
    A. Only read.
    B. Altered retroactively without the alteration of all subsequent blocks and the consensus of the network.
    C. Only written.
    D. Only stored.

    Correct Answer: B
1567. **The Smart Contracts** are self-executing contracts with the terms of the agreement directly written into:
    A. Natural language.
    B. Code.
    C. Legal documents.
    D. Paper.

    Correct Answer: B
1568. **The Decentralized Autonomous Organization (DAO)** is an organization represented by rules encoded as a transparent computer program, controlled by:
    A. A central authority.
    B. Organization members, and not influenced by a central government.
    C. A single user.
    D. A single application.

    Correct Answer: B
1569. **The Web3** is an idea for a new iteration of the World Wide Web based on:
    A. Centralized systems.
    B. Blockchain technology, which incorporates concepts such as decentralization and token-based economics.
    C. Only centralized servers.
    D. Only a single database.

    Correct Answer: B
1570. **The Metaverse** is a hypothetical iteration of the Internet as a single, universal, and immersive virtual world that is facilitated by the use of:
    A. Only text.
    B. Virtual and augmented reality headsets.
    C. Only audio.
    D. Only images.

    Correct Answer: B
1571. **The Digital Twin** is a virtual representation of a physical object or system across its lifecycle, which is updated from:
    A. Only historical data.
    B. Real-time data and uses simulation, machine learning, and reasoning to aid decision-making.
    C. Only simulated data.
    D. Only machine learning data.

    Correct Answer: B
1572. **The Quantum Computing** is a type of computation that harnesses the collective properties of quantum states, such as:
    A. Only bits.
    B. Superposition and entanglement, to perform calculations.
    C. Only bytes.
    D. Only classical logic.

    Correct Answer: C
1573. **The Quantum Machine Learning** is an emerging field that explores how quantum computing can be used to:
    A. Only solve classical machine learning problems.
    B. Enhance machine learning algorithms and speed up the training process.
    C. Only solve quantum physics problems.
    D. Only solve classical physics problems.

    Correct Answer: B
1574. **The Neuromorphic Computing** is a type of computing that mimics the:
    A. Structure and function of the human brain.
    B. Structure and function of the human digestive system.
    C. Structure and function of the solar system.
    D. Structure and function of the internet.

    Correct Answer: B
1575. **The Artificial General Intelligence (AGI)** is a hypothetical type of intelligent agent that could:
    A. Only solve a single task.
    B. Understand, learn, and apply its intelligence to solve any problem that a human being can.
    C. Only solve a limited set of tasks.
    D. Only solve mathematical problems.

    Correct Answer: B
1576. **The Singularity** is a hypothetical future point in time when technological growth becomes:
    A. Slow.
    B. Uncontrollable and irreversible, resulting in unfathomable changes to human civilization.
    C. Linear.
    D. Predictable.

    Correct Answer: B
1577. **The Data Mesh** is a decentralized data architecture that organizes data by:
    A. Centralized data teams.
    B. Specific business domains.
    C. Data type.
    D. Data source.

    Correct Answer: B
1578. **The Data Fabric** is a design concept that serves as a single, consistent data management platform across:
    A. A single cloud.
    B. Multiple clouds, on-premises, and edge environments.
    C. A single on-premises environment.
    D. A single edge environment.

    Correct Answer: B
1579. **The Data Vault** is a detail-oriented, historical tracking, and uniquely linked set of normalized tables that support:
    A. Only a single business process.
    B. One or more functional areas of the business.
    C. Only a single data source.
    D. Only a single data type.

    Correct Answer: B
1580. **The Data Mart** is a subset of the data warehouse that is designed to serve a:
    A. Single business process.
    B. Specific business function or team.
    C. Single data source.
    D. Single data type.

    Correct Answer: B
1581. **The Data Catalog** is a tool that provides an inventory of all data assets in an organization, which includes:
    A. Only the data location.
    B. Metadata, data lineage, and data quality information.
    C. Only the data content.
    D. Only the data meaning.

    Correct Answer: B
1582. **The Metadata** is data that provides information about:
    A. The data content.
    B. Other data.
    C. The data meaning.
    D. The data location.

    Correct Answer: A
1583. **The Data Lineage** in Big Data refers to the data's lifecycle, which includes:
    A. Only the data source.
    B. All the data's origins, and where it moves over time.
    C. Only the data destination.
    D. Only the data processing.

    Correct Answer: A
1584. **The Data Quality** in Big Data refers to the overall fitness of the data to serve its purpose, which includes:
    A. Only accuracy.
    B. Accuracy, completeness, consistency, and timeliness.
    C. Only completeness.
    D. Only consistency.

    Correct Answer: B
1585. **The Data Cleansing (or Data Scrubbing)** is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database, and refers to:
    A. Only data storage.
    B. Data quality.
    C. Only data processing.
    D. Only data visualization.

    Correct Answer: B
1586. **The Data Mining** in the context of Big Data is the process of discovering:
    A. Only simple linear relationships.
    B. Patterns and knowledge from large amounts of data.
    C. Only structured data.
    D. Only small data.

    Correct Answer: B
1587. **The CRISP-DM (Cross-Industry Standard Process for Data Mining)** is a data mining process model that consists of six phases:
    A. Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment.
    B. Map, Shuffle, and Reduce.
    C. Extract, Transform, and Load.
    D. Volume, Velocity, and Variety.

    Correct Answer: B
1588. **The KDD (Knowledge Discovery in Databases)** process is a process of discovering useful knowledge from data, which includes:
    A. Only data mining.
    B. Data selection, preprocessing, transformation, data mining, and evaluation.
    C. Only data selection.
    D. Only data preprocessing.

    Correct Answer: B
1589. **The Data Science Lifecycle** is a process that includes:
    A. Only data mining.
    B. Problem definition, data acquisition, data preparation, modeling, evaluation, and deployment.
    C. Only data acquisition.
    D. Only data preparation.

    Correct Answer: C
1590. **The Data Scientist** is a professional who uses:
    A. Only statistics.
    B. Scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.
    C. Only computer science.
    D. Only domain knowledge.

    Correct Answer: D
1591. **The Data Engineer** is a professional who focuses on the:
    A. Modeling and evaluation.
    B. Design, construction, installation, and management of data processing systems.
    C. Data visualization.
    D. Business understanding.

    Correct Answer: B
1592. **The Business Analyst** is a professional who focuses on the:
    A. Modeling and evaluation.
    B. Analysis of an organization or business domain and documentation of its business processes or systems.
    C. Data processing systems.
    D. Data visualization.

    Correct Answer: B
1593. **The Machine Learning Engineer** is a professional who focuses on the:
    A. Business understanding.
    B. Design, building, and deployment of machine learning models in production.
    C. Data visualization.
    D. Data preparation.

    Correct Answer: B
1594. **The Data Visualization** in Big Data is the process of presenting data in a:
    A. Textual format.
    B. Graphical or pictorial format to enable users to understand the data easily.
    C. Tabular format.
    D. Raw format.

    Correct Answer: D
1595. **The Dashboard** is a data visualization tool that provides a:
    A. Single view of the data.
    B. Centralized, interactive display of key performance indicators (KPIs) and metrics.
    C. Only a partial view of the data.
    D. Only a textual view of the data.

    Correct Answer: B
1596. **The Storytelling with Data** is a technique that involves using data visualization and narrative to:
    A. Only present the data.
    B. Communicate insights and drive action.
    C. Only store the data.
    D. Only process the data.

    Correct Answer: B
1597. **The Ethical Considerations** in Big Data include:
    A. Only data storage.
    B. Data privacy, fairness, and transparency.
    C. Only data processing.
    D. Only data visualization.

    Correct Answer: B
1598. **The Algorithmic Bias** in Big Data refers to the systematic and repeatable errors in a computer system that create:
    A. Only positive outcomes.
    B. Unfair outcomes, such as favoring one arbitrary group over others.
    C. Only neutral outcomes.
    D. Only random outcomes.

    Correct Answer: B
1599. **The Explainable AI (XAI)** is a set of tools and techniques that allow users to:
    A. Only use the model.
    B. Understand and trust the results and output created by machine learning models.
    C. Only train the model.
    D. Only deploy the model.

    Correct Answer: B
1600. **The Fairness, Accountability, and Transparency (FAT)** principles are a set of ethical guidelines for the development and deployment of:
    A. Only traditional statistical models.
    B. AI and machine learning systems.
    C. Only linear models.
    D. Only non-linear models.
# Batch 17: Q1601–Q1700 - Ethical and Legal Issues in Analytics

    Correct Answer: B
1601. **Data Ethics** is a branch of ethics that evaluates data practices, focusing on the moral obligations related to:
    A. Data storage and processing speed.
    B. Data collection, sharing, and use.
    C. Data visualization techniques.
    D. Data mining algorithms.

    Correct Answer: B
1602. **Privacy** in data analytics primarily concerns the right of individuals to:
    A. Have their data stored indefinitely.
    B. Control the collection and use of their personal information.
    C. Access all data collected about them.
    D. Have their data publicly shared.

    Correct Answer: B
1603. **The General Data Protection Regulation (GDPR)** is a comprehensive data protection law in the European Union that grants individuals greater control over their personal data and imposes strict rules on:
    A. Data storage capacity.
    B. Data processing and handling.
    C. Data visualization.
    D. Data modeling.

    Correct Answer: A
1604. A core principle of GDPR is **Lawfulness, Fairness, and Transparency**, which requires that personal data be processed:
    A. Only with explicit consent.
    B. Lawfully, fairly, and in a transparent manner in relation to the data subject.
    C. Only for marketing purposes.
    D. Only for research purposes.

    Correct Answer: B
1605. The **Right to be Forgotten (Right to Erasure)** under GDPR allows individuals to:
    A. Request a copy of their data.
    B. Request the deletion of their personal data under certain conditions.
    C. Correct inaccurate data.
    D. Restrict the processing of their data.

    Correct Answer: B
1606. **The California Consumer Privacy Act (CCPA)** grants California consumers the right to know what personal information is being collected about them and the right to:
    A. Demand a public apology.
    B. Opt-out of the sale of their personal information.
    C. Demand a full refund.
    D. Force a company to use a specific algorithm.

    Correct Answer: B
1607. **Anonymization** is a data processing technique that removes or modifies personally identifiable information (PII) so that the data subject:
    A. Can be easily identified.
    B. Cannot be identified directly or indirectly.
    C. Can be identified by a third party.
    D. Can be identified by a pseudonym.

    Correct Answer: B
1608. **Pseudonymization** is a data management and de-identification technique by which PII fields within a data record are replaced by one or more:
    A. Random numbers.
    B. Artificial identifiers (pseudonyms).
    C. Real names.
    D. Email addresses.

    Correct Answer: A
1609. **Differential Privacy** is a system for publicly sharing information about a dataset by describing the patterns of groups within the dataset while withholding:
    A. Only group information.
    B. Information about individuals.
    C. Only pattern information.
    D. Only aggregate information.

    Correct Answer: B
1610. **Algorithmic Bias** occurs when a computer system reflects the implicit or explicit biases present in the:
    A. Hardware.
    B. Training data or the design of the algorithm.
    C. Output visualization.
    D. Deployment environment.

    Correct Answer: B
1611. **Fairness** in AI and analytics aims to ensure that the models do not produce systematically less favorable outcomes for:
    A. All individuals.
    B. Certain groups of individuals based on sensitive attributes (e.g., race, gender).
    C. Only the training data.
    D. Only the test data.

    Correct Answer: B
1612. **Transparency** in AI and analytics refers to the ability to:
    A. Hide the model's inner workings.
    B. Understand how a model works and why it made a particular decision.
    C. Only view the input data.
    D. Only view the output data.

    Correct Answer: B
1613. **Explainable AI (XAI)** is a set of tools and techniques that allow users to:
    A. Only use the model.
    B. Understand and trust the results and output created by machine learning models.
    C. Only train the model.
    D. Only deploy the model.

    Correct Answer: B
1614. **The Right to Explanation** is a proposed right under GDPR that would allow individuals to:
    A. Demand the source code of the algorithm.
    B. Obtain an explanation for a decision made by an automated system that significantly affects them.
    C. Demand a public apology.
    D. Force a company to use a specific algorithm.

    Correct Answer: B
1615. **Accountability** in AI and analytics requires that there is a clear mechanism for:
    A. Blaming the user for errors.
    B. Determining who is responsible when an AI system causes harm or makes an error.
    C. Ignoring the errors.
    D. Hiding the errors.

    Correct Answer: B
1616. **Data Ownership** is a complex legal and ethical issue that concerns:
    A. Who is responsible for data storage.
    B. Who has the right to possess and use a piece of data.
    C. Who is responsible for data processing.
    D. Who is responsible for data visualization.

    Correct Answer: B
1617. **Intellectual Property (IP)** rights, such as **Copyright** and **Patents**, are relevant in analytics because they protect:
    A. The raw data.
    B. The algorithms, models, and the unique insights derived from the data.
    C. The hardware used for processing.
    D. The user's personal information.

    Correct Answer: B
1618. **Data Security** is an ethical and legal obligation to protect data from:
    A. Only internal threats.
    B. Unauthorized access, use, disclosure, disruption, modification, or destruction.
    C. Only external threats.
    D. Only accidental deletion.

    Correct Answer: B
1619. **Data Minimization** is a principle that states that personal data collected should be:
    A. As much as possible.
    B. Adequate, relevant, and limited to what is necessary in relation to the purposes for which they are processed.
    C. Only for marketing purposes.
    D. Only for research purposes.

    Correct Answer: B
1620. **Purpose Limitation** is a principle that states that personal data should be collected for:
    A. Any purpose.
    B. Specified, explicit, and legitimate purposes and not further processed in a manner that is incompatible with those purposes.
    C. Only for marketing purposes.
    D. Only for research purposes.

    Correct Answer: B
1621. **Accuracy** in data processing requires that personal data be:
    A. As inaccurate as possible.
    B. Accurate and, where necessary, kept up to date.
    C. Only for marketing purposes.
    D. Only for research purposes.

    Correct Answer: B
1622. **Storage Limitation** is a principle that states that personal data should be kept in a form which permits identification of data subjects for:
    A. An indefinite period.
    B. No longer than is necessary for the purposes for which the personal data are processed.
    C. Only for marketing purposes.
    D. Only for research purposes.

    Correct Answer: B
1623. **Integrity and Confidentiality** in data processing requires that personal data be processed in a manner that ensures:
    A. Only confidentiality.
    B. Appropriate security of the personal data, including protection against unauthorized or unlawful processing and against accidental loss, destruction, or damage.
    C. Only integrity.
    D. Only availability.

    Correct Answer: B
1624. **The Data Protection Officer (DPO)** is a role mandated by GDPR to oversee data protection strategy and ensure compliance with GDPR requirements, acting as a point of contact for:
    A. Only the company.
    B. Supervisory authorities and data subjects.
    C. Only the supervisory authorities.
    D. Only the data subjects.

    Correct Answer: B
1625. **The Right to Data Portability** under GDPR allows individuals to:
    A. Request the deletion of their data.
    B. Receive their personal data in a structured, commonly used, and machine-readable format and have the right to transmit that data to another controller.
    C. Correct inaccurate data.
    D. Restrict the processing of their data.

    Correct Answer: B
1626. **The Right to Rectification** under GDPR allows individuals to:
    A. Request the deletion of their data.
    B. Have inaccurate personal data concerning them rectified without undue delay.
    C. Restrict the processing of their data.
    D. Receive their personal data in a portable format.

    Correct Answer: B
1627. **The Right to Restriction of Processing** under GDPR allows individuals to:
    A. Request the deletion of their data.
    B. Obtain from the controller restriction of processing under certain conditions.
    C. Correct inaccurate data.
    D. Receive their personal data in a portable format.

    Correct Answer: B
1628. **The Right to Object** under GDPR allows individuals to:
    A. Request the deletion of their data.
    B. Object to the processing of personal data concerning them, including processing for direct marketing purposes.
    C. Correct inaccurate data.
    D. Receive their personal data in a portable format.

    Correct Answer: B
1629. **The Privacy by Design** principle requires that data protection and privacy measures be:
    A. Added at the end of the development process.
    B. Integrated into the design and operation of information systems from the outset.
    C. Only for marketing purposes.
    D. Only for research purposes.

    Correct Answer: B
1630. **The Data Protection Impact Assessment (DPIA)** is a process designed to help systematically analyze, identify, and minimize the data protection risks of a project or plan, and is mandatory under GDPR for:
    A. All processing operations.
    B. Processing that is likely to result in a high risk to the rights and freedoms of natural persons.
    C. Only low-risk processing operations.
    D. Only marketing processing operations.

    Correct Answer: A
1631. **The Ethical Dilemma** in analytics often arises when there is a conflict between:
    A. Data storage and data processing.
    B. Maximizing business value and protecting individual rights.
    C. Data visualization and data modeling.
    D. Data mining and data warehousing.

    Correct Answer: A
1632. **The Principle of Non-Maleficence** in data ethics states that data practices should:
    A. Maximize benefits.
    B. Avoid causing harm to individuals or groups.
    C. Be transparent.
    D. Be fair.

    Correct Answer: B
1633. **The Principle of Beneficence** in data ethics states that data practices should:
    A. Avoid causing harm.
    B. Maximize benefits and minimize potential harms.
    C. Be transparent.
    D. Be fair.

    Correct Answer: B
1634. **The Principle of Autonomy** in data ethics states that individuals should have the right to:
    A. Have their data stored indefinitely.
    B. Make informed decisions about the use of their personal data.
    C. Access all data collected about them.
    D. Have their data publicly shared.

    Correct Answer: A
1635. **The Principle of Justice** in data ethics states that the benefits and burdens of data practices should be:
    A. Unequally distributed.
    B. Fairly distributed across different groups.
    C. Only for marketing purposes.
    D. Only for research purposes.

    Correct Answer: A
1636. **The Homomorphic Encryption** is a form of encryption that allows computations to be performed on:
    A. Only unencrypted data.
    B. Encrypted data without decrypting it first.
    C. Only decrypted data.
    D. Only partial data.

    Correct Answer: B
1637. **The Federated Learning** is a machine learning setting where the training process is distributed across:
    A. A single centralized server.
    B. Multiple decentralized edge devices or servers holding local data samples.
    C. A single cloud instance.
    D. A single machine.

    Correct Answer: B
1638. **The Blockchain Technology** is a decentralized, distributed, and often public digital ledger that is used to record transactions across many computers so that the record cannot be:
    A. Only read.
    B. Altered retroactively without the alteration of all subsequent blocks and the consensus of the network.
    C. Only written.
    D. Only stored.

    Correct Answer: B
1639. **The Smart Contracts** are self-executing contracts with the terms of the agreement directly written into:
    A. Natural language.
    B. Code.
    C. Legal documents.
    D. Paper.

    Correct Answer: B
1640. **The Decentralized Autonomous Organization (DAO)** is an organization represented by rules encoded as a transparent computer program, controlled by:
    A. A central authority.
    B. Organization members, and not influenced by a central government.
    C. A single user.
    D. A single application.

    Correct Answer: B
1641. **The Web3** is an idea for a new iteration of the World Wide Web based on:
    A. Centralized systems.
    B. Blockchain technology, which incorporates concepts such as decentralization and token-based economics.
    C. Only centralized servers.
    D. Only a single database.

    Correct Answer: B
1642. **The Metaverse** is a hypothetical iteration of the Internet as a single, universal, and immersive virtual world that is facilitated by the use of:
    A. Only text.
    B. Virtual and augmented reality headsets.
    C. Only audio.
    D. Only images.

    Correct Answer: B
1643. **The Digital Twin** is a virtual representation of a physical object or system across its lifecycle, which is updated from:
    A. Only historical data.
    B. Real-time data and uses simulation, machine learning, and reasoning to aid decision-making.
    C. Only simulated data.
    D. Only machine learning data.

    Correct Answer: B
1644. **The Quantum Computing** is a type of computation that harnesses the collective properties of quantum states, such as:
    A. Only bits.
    B. Superposition and entanglement, to perform calculations.
    C. Only bytes.
    D. Only classical logic.

    Correct Answer: B
1645. **The Quantum Machine Learning** is an emerging field that explores how quantum computing can be used to:
    A. Only solve classical machine learning problems.
    B. Enhance machine learning algorithms and speed up the training process.
    C. Only solve quantum physics problems.
    D. Only solve classical physics problems.

    Correct Answer: B
1646. **The Neuromorphic Computing** is a type of computing that mimics the:
    A. Structure and function of the human brain.
    B. Structure and function of the human digestive system.
    C. Structure and function of the solar system.
    D. Structure and function of the internet.

    Correct Answer: B
1647. **The Artificial General Intelligence (AGI)** is a hypothetical type of intelligent agent that could:
    A. Only solve a single task.
    B. Understand, learn, and apply its intelligence to solve any problem that a human being can.
    C. Only solve a limited set of tasks.
    D. Only solve mathematical problems.

    Correct Answer: B
1648. **The Singularity** is a hypothetical future point in time when technological growth becomes:
    A. Slow.
    B. Uncontrollable and irreversible, resulting in unfathomable changes to human civilization.
    C. Linear.
    D. Predictable.

    Correct Answer: B
1649. **The Data Mesh** is a decentralized data architecture that organizes data by:
    A. Centralized data teams.
    B. Specific business domains.
    C. Data type.
    D. Data source.

    Correct Answer: B
1650. **The Data Fabric** is a design concept that serves as a single, consistent data management platform across:
    A. A single cloud.
    B. Multiple clouds, on-premises, and edge environments.
    C. A single on-premises environment.
    D. A single edge environment.

    Correct Answer: B
1651. **The Data Vault** is a detail-oriented, historical tracking, and uniquely linked set of normalized tables that support:
    A. Only a single business process.
    B. One or more functional areas of the business.
    C. Only a single data source.
    D. Only a single data type.

    Correct Answer: B
1652. **The Data Mart** is a subset of the data warehouse that is designed to serve a:
    A. Single business process.
    B. Specific business function or team.
    C. Single data source.
    D. Single data type.

    Correct Answer: B
1653. **The Data Catalog** is a tool that provides an inventory of all data assets in an organization, which includes:
    A. Only the data location.
    B. Metadata, data lineage, and data quality information.
    C. Only the data content.
    D. Only the data meaning.

    Correct Answer: B
1654. **The Metadata** is data that provides information about:
    A. The data content.
    B. Other data.
    C. The data meaning.
    D. The data location.

    Correct Answer: B
1655. **The Data Lineage** in Big Data refers to the data's lifecycle, which includes:
    A. Only the data source.
    B. All the data's origins, and where it moves over time.
    C. Only the data destination.
    D. Only the data processing.

    Correct Answer: B
1656. **The Data Quality** in Big Data refers to the overall fitness of the data to serve its purpose, which includes:
    A. Only accuracy.
    B. Accuracy, completeness, consistency, and timeliness.
    C. Only completeness.
    D. Only consistency.

    Correct Answer: B
1657. **The Data Cleansing (or Data Scrubbing)** is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database, and refers to:
    A. Only data storage.
    B. Data quality.
    C. Only data processing.
    D. Only data visualization.

    Correct Answer: B
1658. **The Data Mining** in the context of Big Data is the process of discovering:
    A. Only simple linear relationships.
    B. Patterns and knowledge from large amounts of data.
    C. Only structured data.
    D. Only small data.

    Correct Answer: A
1659. **The CRISP-DM (Cross-Industry Standard Process for Data Mining)** is a data mining process model that consists of six phases:
    A. Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment.
    B. Map, Shuffle, and Reduce.
    C. Extract, Transform, and Load.
    D. Volume, Velocity, and Variety.

    Correct Answer: B
1660. **The KDD (Knowledge Discovery in Databases)** process is a process of discovering useful knowledge from data, which includes:
    A. Only data mining.
    B. Data selection, preprocessing, transformation, data mining, and evaluation.
    C. Only data selection.
    D. Only data preprocessing.

    Correct Answer: B
1661. **The Data Science Lifecycle** is a process that includes:
    A. Only data mining.
    B. Problem definition, data acquisition, data preparation, modeling, evaluation, and deployment.
    C. Only data acquisition.
    D. Only data preparation.

    Correct Answer: B
1662. **The Data Scientist** is a professional who uses:
    A. Only statistics.
    B. Scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.
    C. Only computer science.
    D. Only domain knowledge.

    Correct Answer: B
1663. **The Data Engineer** is a professional who focuses on the:
    A. Modeling and evaluation.
    B. Design, construction, installation, and management of data processing systems.
    C. Data visualization.
    D. Business understanding.

    Correct Answer: B
1664. **The Business Analyst** is a professional who focuses on the:
    A. Modeling and evaluation.
    B. Analysis of an organization or business domain and documentation of its business processes or systems.
    C. Data processing systems.
    D. Data visualization.

    Correct Answer: B
1665. **The Machine Learning Engineer** is a professional who focuses on the:
    A. Business understanding.
    B. Design, building, and deployment of machine learning models in production.
    C. Data visualization.
    D. Data preparation.

    Correct Answer: B
1666. **The Data Visualization** in Big Data is the process of presenting data in a:
    A. Textual format.
    B. Graphical or pictorial format to enable users to understand the data easily.
    C. Tabular format.
    D. Raw format.

    Correct Answer: B
1667. **The Dashboard** is a data visualization tool that provides a:
    A. Single view of the data.
    B. Centralized, interactive display of key performance indicators (KPIs) and metrics.
    C. Only a partial view of the data.
    D. Only a textual view of the data.

    Correct Answer: B
1668. **The Storytelling with Data** is a technique that involves using data visualization and narrative to:
    A. Only present the data.
    B. Communicate insights and drive action.
    C. Only store the data.
    D. Only process the data.

    Correct Answer: B
1669. **The Ethical Considerations** in Big Data include:
    A. Only data storage.
    B. Data privacy, fairness, and transparency.
    C. Only data processing.
    D. Only data visualization.

    Correct Answer: B
1670. **The Algorithmic Bias** in Big Data refers to the systematic and repeatable errors in a computer system that create:
    A. Only positive outcomes.
    B. Unfair outcomes, such as favoring one arbitrary group over others.
    C. Only neutral outcomes.
    D. Only random outcomes.

    Correct Answer: B
1671. **The Explainable AI (XAI)** is a set of tools and techniques that allow users to:
    A. Only use the model.
    B. Understand and trust the results and output created by machine learning models.
    C. Only train the model.
    D. Only deploy the model.

    Correct Answer: B
1672. **The Fairness, Accountability, and Transparency (FAT)** principles are a set of ethical guidelines for the development and deployment of:
    A. Only traditional statistical models.
    B. AI and machine learning systems.
    C. Only linear models.
    D. Only non-linear models.

    Correct Answer: B
1673. **The Differential Privacy** is a system for publicly sharing information about a dataset by describing the patterns of groups within the dataset while withholding:
    A. Only group information.
    B. Information about individuals.
    C. Only pattern information.
    D. Only aggregate information.

    Correct Answer: B
1674. **The Homomorphic Encryption** is a form of encryption that allows computations to be performed on:
    A. Only unencrypted data.
    B. Encrypted data without decrypting it first.
    C. Only decrypted data.
    D. Only partial data.

    Correct Answer: B
1675. **The Federated Learning** is a machine learning setting where the training process is distributed across:
    A. A single centralized server.
    B. Multiple decentralized edge devices or servers holding local data samples.
    C. A single cloud instance.
    D. A single machine.

    Correct Answer: B
1676. **The Blockchain Technology** is a decentralized, distributed, and often public digital ledger that is used to record transactions across many computers so that the record cannot be:
    A. Only read.
    B. Altered retroactively without the alteration of all subsequent blocks and the consensus of the network.
    C. Only written.
    D. Only stored.

    Correct Answer: B
1677. **The Smart Contracts** are self-executing contracts with the terms of the agreement directly written into:
    A. Natural language.
    B. Code.
    C. Legal documents.
    D. Paper.

    Correct Answer: B
1678. **The Decentralized Autonomous Organization (DAO)** is an organization represented by rules encoded as a transparent computer program, controlled by:
    A. A central authority.
    B. Organization members, and not influenced by a central government.
    C. A single user.
    D. A single application.

    Correct Answer: B
1679. **The Web3** is an idea for a new iteration of the World Wide Web based on:
    A. Centralized systems.
    B. Blockchain technology, which incorporates concepts such as decentralization and token-based economics.
    C. Only centralized servers.
    D. Only a single database.

    Correct Answer: A
1680. **The Metaverse** is a hypothetical iteration of the Internet as a single, universal, and immersive virtual world that is facilitated by the use of:
    A. Only text.
    B. Virtual and augmented reality headsets.
    C. Only audio.
    D. Only images.

    Correct Answer: B
1681. **The Digital Twin** is a virtual representation of a physical object or system across its lifecycle, which is updated from:
    A. Only historical data.
    B. Real-time data and uses simulation, machine learning, and reasoning to aid decision-making.
    C. Only simulated data.
    D. Only machine learning data.

    Correct Answer: B
1682. **The Quantum Computing** is a type of computation that harnesses the collective properties of quantum states, such as:
    A. Only bits.
    B. Superposition and entanglement, to perform calculations.
    C. Only bytes.
    D. Only classical logic.

    Correct Answer: B
1683. **The Quantum Machine Learning** is an emerging field that explores how quantum computing can be used to:
    A. Only solve classical machine learning problems.
    B. Enhance machine learning algorithms and speed up the training process.
    C. Only solve quantum physics problems.
    D. Only solve classical physics problems.

    Correct Answer: B
1684. **The Neuromorphic Computing** is a type of computing that mimics the:
    A. Structure and function of the human brain.
    B. Structure and function of the human digestive system.
    C. Structure and function of the solar system.
    D. Structure and function of the internet.

    Correct Answer: B
1685. **The Artificial General Intelligence (AGI)** is a hypothetical type of intelligent agent that could:
    A. Only solve a single task.
    B. Understand, learn, and apply its intelligence to solve any problem that a human being can.
    C. Only solve a limited set of tasks.
    D. Only solve mathematical problems.

    Correct Answer: B
1686. **The Singularity** is a hypothetical future point in time when technological growth becomes:
    A. Slow.
    B. Uncontrollable and irreversible, resulting in unfathomable changes to human civilization.
    C. Linear.
    D. Predictable.

    Correct Answer: B
1687. **The Data Mesh** is a decentralized data architecture that organizes data by:
    A. Centralized data teams.
    B. Specific business domains.
    C. Data type.
    D. Data source.

    Correct Answer: B
1688. **The Data Fabric** is a design concept that serves as a single, consistent data management platform across:
    A. A single cloud.
    B. Multiple clouds, on-premises, and edge environments.
    C. A single on-premises environment.
    D. A single edge environment.

    Correct Answer: B
1689. **The Data Vault** is a detail-oriented, historical tracking, and uniquely linked set of normalized tables that support:
    A. Only a single business process.
    B. One or more functional areas of the business.
    C. Only a single data source.
    D. Only a single data type.

    Correct Answer: B
1690. **The Data Mart** is a subset of the data warehouse that is designed to serve a:
    A. Single business process.
    B. Specific business function or team.
    C. Single data source.
    D. Single data type.

    Correct Answer: A
1691. **The Data Catalog** is a tool that provides an inventory of all data assets in an organization, which includes:
    A. Only the data location.
    B. Metadata, data lineage, and data quality information.
    C. Only the data content.
    D. Only the data meaning.

    Correct Answer: B
1692. **The Metadata** is data that provides information about:
    A. The data content.
    B. Other data.
    C. The data meaning.
    D. The data location.

    Correct Answer: B
1693. **The Data Lineage** in Big Data refers to the data's lifecycle, which includes:
    A. Only the data source.
    B. All the data's origins, and where it moves over time.
    C. Only the data destination.
    D. Only the data processing.

    Correct Answer: B
1694. **The Data Quality** in Big Data refers to the overall fitness of the data to serve its purpose, which includes:
    A. Only accuracy.
    B. Accuracy, completeness, consistency, and timeliness.
    C. Only completeness.
    D. Only consistency.

    Correct Answer: B
1695. **The Data Cleansing (or Data Scrubbing)** is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database, and refers to:
    A. Only data storage.
    B. Data quality.
    C. Only data processing.
    D. Only data visualization.

    Correct Answer: B
1696. **The Data Mining** in the context of Big Data is the process of discovering:
    A. Only simple linear relationships.
    B. Patterns and knowledge from large amounts of data.
    C. Only structured data.
    D. Only small data.

    Correct Answer: C
1697. **The CRISP-DM (Cross-Industry Standard Process for Data Mining)** is a data mining process model that consists of six phases:
    A. Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment.
    B. Map, Shuffle, and Reduce.
    C. Extract, Transform, and Load.
    D. Volume, Velocity, and Variety.

    Correct Answer: A
1698. **The KDD (Knowledge Discovery in Databases)** process is a process of discovering useful knowledge from data, which includes:
    A. Only data mining.
    B. Data selection, preprocessing, transformation, data mining, and evaluation.
    C. Only data selection.
    D. Only data preprocessing.

    Correct Answer: B
1699. **The Data Science Lifecycle** is a process that includes:
    A. Only data mining.
    B. Problem definition, data acquisition, data preparation, modeling, evaluation, and deployment.
    C. Only data acquisition.
    D. Only data preparation.

    Correct Answer: B
1700. **The Data Scientist** is a professional who uses:
    A. Only statistics.
    B. Scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.
    C. Only computer science.
    D. Only domain knowledge.
# Batch 18: Q1701–Q1800 - Advanced Statistical Concepts (e.g., Bayesian Methods, Non-Parametric Tests)

    Correct Answer: A
1701. **Bayesian Statistics** is an approach to statistical inference where probability is interpreted as:
    A. The long-run frequency of an event.
    B. A measure of belief or plausibility.
    C. A fixed, unknown value.
    D. The ratio of favorable outcomes to total outcomes.

    Correct Answer: B
1702. In Bayesian inference, the **Prior Distribution** represents:
    A. The probability of the data given the parameters.
    B. The information about the parameters before observing the data.
    C. The updated belief after observing the data.
    D. The likelihood of the data.

    Correct Answer: C
1703. In Bayesian inference, the **Likelihood Function** represents:
    A. The information about the parameters before observing the data.
    B. The probability of observing the data given the parameters.
    C. The updated belief after observing the data.
    D. The marginal probability of the data.

    Correct Answer: B
1704. In Bayesian inference, the **Posterior Distribution** represents:
    A. The probability of the data given the parameters.
    B. The information about the parameters before observing the data.
    C. The updated belief about the parameters after observing the data.
    D. The marginal probability of the data.

    Correct Answer: A
1705. **Bayes' Theorem** is the mathematical rule that links the prior probability to the posterior probability, and is given by:
    A. $P(A|B) = \frac{P(B|A)P(A)}{P(B)}$
    B. $P(A|B) = P(B|A)P(A)$
    C. $P(A|B) = \frac{P(A)P(B)}{P(A \cap B)}$
    D. $P(A|B) = P(A) + P(B) - P(A \cap B)$

    Correct Answer: B
1706. The term $P(B)$ in Bayes' Theorem, often called the **Evidence** or **Marginal Likelihood**, serves as a:
    A. Normalizing constant.
    B. Prior distribution.
    C. Likelihood function.
    D. Posterior distribution.

    Correct Answer: B
1707. **Conjugate Priors** are a mathematical convenience in Bayesian statistics because when combined with the likelihood function, they result in a posterior distribution that:
    A. Is a different family of distribution.
    B. Belongs to the same family of distribution as the prior.
    C. Is always a Normal distribution.
    D. Is always a Uniform distribution.

    Correct Answer: B
1708. **Markov Chain Monte Carlo (MCMC)** methods, such as the **Metropolis-Hastings Algorithm** and **Gibbs Sampling**, are used in Bayesian statistics to:
    A. Calculate the prior distribution.
    B. Numerically approximate the posterior distribution when it cannot be calculated analytically.
    C. Calculate the likelihood function.
    D. Calculate the marginal likelihood.

    Correct Answer: B
1709. **Non-Parametric Tests** are statistical methods that do not rely on assumptions about the shape or parameters of the population distribution, particularly that the data is:
    A. Normally distributed.
    B. Uniformly distributed.
    C. Exponentially distributed.
    D. Binomially distributed.

    Correct Answer: B
1710. The **Mann-Whitney U Test** (or Wilcoxon Rank-Sum Test) is the non-parametric alternative to the:
    A. One-sample t-test.
    B. Independent samples t-test.
    C. Paired samples t-test.
    D. ANOVA.

    Correct Answer: B
1711. The **Wilcoxon Signed-Rank Test** is the non-parametric alternative to the:
    A. One-sample t-test.
    B. Independent samples t-test.
    C. Paired samples t-test.
    D. ANOVA.

    Correct Answer: B
1712. The **Kruskal-Wallis H Test** is the non-parametric alternative to the:
    A. Independent samples t-test.
    B. Paired samples t-test.
    C. One-way ANOVA.
    D. Two-way ANOVA.

    Correct Answer: B
1713. The **Friedman Test** is the non-parametric alternative to the:
    A. One-way ANOVA.
    B. Repeated measures ANOVA.
    C. Independent samples t-test.
    D. Paired samples t-test.

    Correct Answer: C
1714. The **Spearman's Rank Correlation Coefficient** is the non-parametric alternative to the:
    A. Pearson correlation coefficient.
    B. Simple linear regression.
    C. Multiple linear regression.
    D. Logistic regression.

    Correct Answer: B
1715. The **Chi-Square Test of Independence** is a non-parametric test used to determine if there is a significant association between:
    A. Two continuous variables.
    B. Two categorical variables.
    C. A continuous and a categorical variable.
    D. A time series and a continuous variable.

    Correct Answer: B
1716. **Bootstrapping** is a resampling technique used to estimate the sampling distribution of a statistic by:
    A. Drawing a single sample from the population.
    B. Drawing numerous samples with replacement from the original sample data.
    C. Drawing numerous samples without replacement from the original sample data.
    D. Drawing a single sample from a theoretical distribution.

    Correct Answer: B
1717. **The Jackknife** is a resampling technique used to estimate the bias and standard error of a statistic by:
    A. Drawing numerous samples with replacement from the original sample data.
    B. Systematically leaving out one observation at a time from the original sample.
    C. Drawing a single sample from the population.
    D. Drawing a single sample from a theoretical distribution.

    Correct Answer: B
1718. **Robust Statistics** are statistical methods that are less affected by:
    A. The sample size.
    B. Outliers and deviations from the model assumptions (e.g., normality).
    C. The number of variables.
    D. The presence of missing values.

    Correct Answer: B
1719. The **Median** is a more robust measure of central tendency than the **Mean** because it is less sensitive to:
    A. The sample size.
    B. Outliers.
    C. The number of variables.
    D. The presence of missing values.

    Correct Answer: B
1720. The **Interquartile Range (IQR)** is a more robust measure of dispersion than the **Standard Deviation** because it is less sensitive to:
    A. The sample size.
    B. Outliers.
    C. The number of variables.
    D. The presence of missing values.

    Correct Answer: B
1721. **Robust Regression** methods, such as **Least Absolute Deviations (LAD)**, are used when the assumptions of ordinary least squares (OLS) regression are violated, particularly the assumption of:
    A. Linearity.
    B. Normally distributed errors.
    C. Homoscedasticity.
    D. Independence of errors.

    Correct Answer: B
1722. **Generalized Linear Models (GLMs)** are a flexible generalization of ordinary least squares regression that allows for response variables that have:
    A. Only a Normal distribution.
    B. Error distribution models other than a Normal distribution (e.g., Poisson, Binomial).
    C. Only a Poisson distribution.
    D. Only a Binomial distribution.

    Correct Answer: B
1723. The three components of a GLM are the **Random Component** (the probability distribution of the response variable), the **Systematic Component** (the linear predictor), and the:
    A. Error term.
    B. Link function.
    C. Residuals.
    D. Standard error.

    Correct Answer: A
1724. **Logistic Regression** is a type of GLM where the random component is a **Binomial Distribution** and the link function is the:
    A. Identity function.
    B. Logit function.
    C. Log function.
    D. Exponential function.

    Correct Answer: A
1725. **Poisson Regression** is a type of GLM where the random component is a **Poisson Distribution** and the link function is the:
    A. Identity function.
    B. Logit function.
    C. Log function.
    D. Exponential function.

    Correct Answer: A
1726. **Survival Analysis** (or time-to-event analysis) is a branch of statistics for analyzing the expected duration of time until one or more events happen, such as:
    A. Only death.
    B. Death, failure of a mechanical system, or the onset of a disease.
    C. Only success.
    D. Only continuous variables.

    Correct Answer: B
1727. The **Kaplan-Meier Estimator** is a non-parametric statistic used in survival analysis to estimate the:
    A. Hazard function.
    B. Survival function.
    C. Cumulative distribution function.
    D. Probability density function.

    Correct Answer: B
1728. The **Cox Proportional Hazards Model** is a semi-parametric model used in survival analysis to:
    A. Estimate the survival function.
    B. Relate the survival time to a set of predictor variables.
    C. Estimate the hazard function.
    D. Estimate the cumulative distribution function.

    Correct Answer: B
1729. **Censoring** in survival analysis occurs when the information about the survival time is:
    A. Complete.
    B. Incomplete (e.g., the study ends before the event occurs).
    C. Only for death.
    D. Only for success.

    Correct Answer: B
1730. **Longitudinal Data Analysis** (or panel data analysis) is a statistical method for analyzing data in which the same variables are measured:
    A. Only once.
    B. Repeatedly over time on the same subjects.
    C. Only on different subjects.
    D. Only on a single subject.

    Correct Answer: B
1731. **Mixed-Effects Models** (or multilevel models) are statistical models that contain both:
    A. Only fixed effects.
    B. Fixed effects (population parameters) and random effects (subject-specific deviations).
    C. Only random effects.
    D. Only continuous variables.

    Correct Answer: C
1732. **Structural Equation Modeling (SEM)** is a multivariate statistical analysis technique that is used to analyze:
    A. Only observed variables.
    B. Structural relationships between measured variables and latent constructs.
    C. Only latent constructs.
    D. Only a single variable.

    Correct Answer: B
1733. **Factor Analysis** is a statistical method used to describe variability among observed, correlated variables in terms of a potentially lower number of:
    A. Observed variables.
    B. Unobserved variables called factors.
    C. Only continuous variables.
    D. Only categorical variables.

    Correct Answer: B
1734. **Principal Component Analysis (PCA)** is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of:
    A. Correlated variables.
    B. Linearly uncorrelated variables called principal components.
    C. Only continuous variables.
    D. Only categorical variables.

    Correct Answer: A
1735. **The Difference between PCA and Factor Analysis** is that PCA is primarily a **Dimensionality Reduction** technique, while Factor Analysis is primarily a **Latent Variable** modeling technique used to:
    A. Only reduce the number of variables.
    B. Explain the covariance among observed variables.
    C. Only find uncorrelated variables.
    D. Only find correlated variables.

    Correct Answer: B
1736. **Canonical Correlation Analysis (CCA)** is a multivariate statistical method for investigating the relationship between:
    A. A single set of variables.
    B. Two sets of variables.
    C. Three sets of variables.
    D. Only a single variable.

    Correct Answer: B
1737. **Discriminant Analysis** is a statistical technique used to find a linear combination of features that characterizes or separates:
    A. Two or more classes of objects or events.
    B. Only a single class of objects or events.
    C. Only continuous variables.
    D. Only categorical variables.

    Correct Answer: B
1738. **The Mahalanobis Distance** is a measure of the distance between a point and a distribution that accounts for the:
    A. Correlation between the variables.
    B. Mean of the variables.
    C. Standard deviation of the variables.
    D. Number of variables.

    Correct Answer: B
1739. **The Hotelling's T-Squared Test** is a multivariate hypothesis test that is the generalization of the:
    A. One-sample t-test to the multivariate case.
    B. Independent samples t-test to the multivariate case.
    C. Paired samples t-test to the multivariate case.
    D. ANOVA to the multivariate case.

    Correct Answer: B
1740. **Multivariate Analysis of Variance (MANOVA)** is a statistical test procedure for comparing:
    A. Only a single dependent variable.
    B. Multiple dependent variables simultaneously across different groups.
    C. Only a single independent variable.
    D. Only a single continuous variable.

    Correct Answer: B
1741. **The Difference between ANOVA and MANOVA** is that ANOVA tests for the difference in means of a single dependent variable, while MANOVA tests for the difference in means of:
    A. A single dependent variable.
    B. Multiple dependent variables.
    C. A single independent variable.
    D. Multiple independent variables.

    Correct Answer: B
1742. **The Repeated Measures ANOVA** is a statistical test used to compare the means of three or more groups where the same subjects are:
    A. Measured only once.
    B. Measured repeatedly over time.
    C. Measured only on different subjects.
    D. Measured only on a single subject.

    Correct Answer: B
1743. **The Mixed ANOVA** (or split-plot ANOVA) is a statistical test used to compare the means of three or more groups where there is at least one:
    A. Only between-subjects factor.
    B. Between-subjects factor and at least one within-subjects factor.
    C. Only within-subjects factor.
    D. Only a single factor.

    Correct Answer: B
1744. **The Non-Parametric Test** for comparing two independent groups on an ordinal or continuous variable is the:
    A. Wilcoxon Signed-Rank Test.
    B. Mann-Whitney U Test.
    C. Kruskal-Wallis H Test.
    D. Friedman Test.

    Correct Answer: B
1745. **The Non-Parametric Test** for comparing two dependent groups on an ordinal or continuous variable is the:
    A. Mann-Whitney U Test.
    B. Wilcoxon Signed-Rank Test.
    C. Kruskal-Wallis H Test.
    D. Friedman Test.

    Correct Answer: A
1746. **The Non-Parametric Test** for comparing three or more independent groups on an ordinal or continuous variable is the:
    A. Mann-Whitney U Test.
    B. Wilcoxon Signed-Rank Test.
    C. Kruskal-Wallis H Test.
    D. Friedman Test.

    Correct Answer: B
1747. **The Non-Parametric Test** for comparing three or more dependent groups on an ordinal or continuous variable is the:
    A. Mann-Whitney U Test.
    B. Wilcoxon Signed-Rank Test.
    C. Kruskal-Wallis H Test.
    D. Friedman Test.

    Correct Answer: B
1748. **The Bayesian Information Criterion (BIC)** is a criterion for model selection among a finite set of models, where the model with the lowest BIC is preferred. It penalizes models with:
    A. Fewer parameters.
    B. More parameters.
    C. Lower likelihood.
    D. Higher likelihood.

    Correct Answer: B
1749. **The Akaike Information Criterion (AIC)** is a criterion for model selection among a finite set of models, where the model with the lowest AIC is preferred. It penalizes models with:
    A. Fewer parameters.
    B. More parameters.
    C. Lower likelihood.
    D. Higher likelihood.

    Correct Answer: B
1750. **The Difference between AIC and BIC** is that BIC imposes a **Heavier Penalty** on the number of parameters than AIC, which tends to favor:
    A. More complex models.
    B. Simpler models.
    C. Models with lower likelihood.
    D. Models with higher likelihood.

    Correct Answer: A
1751. **The Bayesian Model Averaging (BMA)** is a technique that combines the predictions of multiple models, weighted by their:
    A. Prior probability.
    B. Posterior probability.
    C. Likelihood.
    D. Marginal likelihood.

    Correct Answer: B
1752. **The Bayesian Model Selection** is a technique that selects the best model from a set of candidate models based on the:
    A. Prior probability.
    B. Posterior probability.
    C. Likelihood.
    D. Marginal likelihood.

    Correct Answer: B
1753. **The Predictive Posterior Distribution** in Bayesian statistics is the distribution of the:
    A. Parameters given the data.
    B. Future observations given the observed data.
    C. Data given the parameters.
    D. Prior distribution.

    Correct Answer: B
1754. **The Credible Interval** in Bayesian statistics is the Bayesian equivalent of the **Confidence Interval** in frequentist statistics, and it represents the range of values that contains the true parameter with a specified:
    A. Frequency.
    B. Probability.
    C. Likelihood.
    D. Prior.

    Correct Answer: B
1755. **The Highest Density Interval (HDI)** is a type of credible interval that is defined as the narrowest interval that contains the specified:
    A. Frequency.
    B. Probability mass.
    C. Likelihood.
    D. Prior.

    Correct Answer: B
1756. **The Bayesian Factor** is a measure of the evidence in the data in favor of one model over another, and it is defined as the ratio of the:
    A. Prior probabilities.
    B. Marginal likelihoods.
    C. Posterior probabilities.
    D. Likelihoods.

    Correct Answer: B
1757. **The Non-Parametric Regression** methods, such as **Kernel Regression** and **Spline Regression**, are used when the relationship between the dependent and independent variables is:
    A. Linear.
    B. Non-linear and the functional form is unknown.
    C. Only for continuous variables.
    D. Only for categorical variables.

    Correct Answer: B
1758. **The Generalized Additive Models (GAMs)** are a class of GLMs where the linear predictor is modeled as a sum of:
    A. Only linear terms.
    B. Smooth functions of the predictor variables.
    C. Only non-linear terms.
    D. Only a single term.

    Correct Answer: B
1759. **The Quantile Regression** is a type of regression analysis used to estimate the conditional **Quantile Functions** of the response variable, which is more robust to:
    A. The sample size.
    B. Outliers and non-normal errors.
    C. The number of variables.
    D. The presence of missing values.

    Correct Answer: B
1760. **The Zero-Inflated Models** (e.g., Zero-Inflated Poisson) are statistical models used to analyze count data that have an:
    A. Only a few zeros.
    B. Excess number of zero observations.
    C. Only a few non-zeros.
    D. Only a few missing values.

    Correct Answer: B
1761. **The Hurdle Models** are statistical models used to analyze count data that have an **Excess Number of Zero Observations**, and they model the data as a two-part process:
    A. Only the count process.
    B. The binary process of being zero or non-zero, and the count process for the non-zero values.
    C. Only the binary process.
    D. Only the non-zero count process.

    Correct Answer: B
1762. **The Time Series Decomposition** is a statistical method that breaks down a time series into its constituent components:
    A. Only trend.
    B. Trend, seasonality, and residual (irregular) components.
    C. Only seasonality.
    D. Only residual.

    Correct Answer: B
1763. **The Exponential Smoothing** is a time series forecasting method that assigns exponentially decreasing weights to:
    A. Only recent observations.
    B. Older observations.
    C. Only the trend.
    D. Only the seasonality.

    Correct Answer: B
1764. **The ARIMA (Autoregressive Integrated Moving Average) Model** is a time series forecasting model that is used to model:
    A. Only stationary time series.
    B. Non-stationary time series that can be made stationary by differencing.
    C. Only non-stationary time series.
    D. Only stationary time series that cannot be made stationary by differencing.

    Correct Answer: B
1765. **The ARCH (Autoregressive Conditional Heteroskedasticity) Model** is a time series model used to model the:
    A. Mean of the time series.
    B. Variance of the time series.
    C. Trend of the time series.
    D. Seasonality of the time series.

    Correct Answer: B
1766. **The GARCH (Generalized Autoregressive Conditional Heteroskedasticity) Model** is an extension of the ARCH model that is used to model the:
    A. Mean of the time series.
    B. Variance of the time series.
    C. Trend of the time series.
    D. Seasonality of the time series.

    Correct Answer: B
1767. **The Vector Autoregression (VAR) Model** is a time series model used to capture the linear interdependencies among:
    A. A single time series.
    B. Multiple time series.
    C. Only stationary time series.
    D. Only non-stationary time series.

    Correct Answer: B
1768. **The Cointegration** is a statistical property of a collection of time series variables that are:
    A. Only stationary.
    B. Non-stationary, but a linear combination of them is stationary.
    C. Only non-stationary.
    D. Only stationary, and a linear combination of them is non-stationary.

    Correct Answer: B
1769. **The Granger Causality Test** is a statistical hypothesis test for determining whether one time series is useful in:
    A. Predicting another time series.
    B. Explaining another time series.
    C. Correlating with another time series.
    D. Clustering another time series.

    Correct Answer: B
1770. **The Kalman Filter** is an algorithm that uses a series of measurements observed over time, containing statistical noise and other inaccuracies, and produces estimates of:
    A. Only the current state.
    B. Unknown variables that tend to be more precise than those based on a single measurement alone.
    C. Only the future state.
    D. Only the past state.

    Correct Answer: B
1771. **The Hidden Markov Model (HMM)** is a statistical Markov model in which the system being modeled is assumed to be a Markov process with:
    A. Only observed states.
    B. Unobserved (hidden) states.
    C. Only continuous variables.
    D. Only categorical variables.

    Correct Answer: B
1772. **The Sequential Monte Carlo (SMC)** methods, such as **Particle Filters**, are a set of techniques used to approximate the:
    A. Prior distribution.
    B. Posterior distribution of a state-space model.
    C. Likelihood function.
    D. Marginal likelihood.

    Correct Answer: A
1773. **The Gaussian Process (GP)** is a stochastic process where every finite collection of random variables has a:
    A. Uniform distribution.
    B. Multivariate normal distribution.
    C. Poisson distribution.
    D. Binomial distribution.

    Correct Answer: B
1774. **The Gaussian Process Regression (GPR)** is a non-parametric, Bayesian approach to regression that provides a measure of:
    A. Only the mean.
    B. Uncertainty (variance) in the predictions.
    C. Only the variance.
    D. Only the median.

    Correct Answer: B
1775. **The Kernel Trick** is a method used in GPR to implicitly map the input features into a higher-dimensional space where a linear separation might be possible, using a:
    A. Linear kernel.
    B. Non-linear kernel.
    C. Identity function.
    D. Logit function.

    Correct Answer: B
1776. **The Bayesian Optimization** is a sequential design strategy for finding the global optimum of a function that is expensive to evaluate, by using a:
    A. Linear model.
    B. Surrogate model (e.g., Gaussian Process) to model the objective function.
    C. Non-linear model.
    D. Decision tree.

    Correct Answer: A
1777. **The Acquisition Function** in Bayesian Optimization is used to determine the next point to evaluate, by balancing:
    A. Only exploration.
    B. Exploration (sampling in uncertain regions) and exploitation (sampling near the current best point).
    C. Only exploitation.
    D. Only the mean.

    Correct Answer: A
1778. **The Expectation-Maximization (EM) Algorithm** is an iterative method for finding maximum likelihood or maximum a posteriori estimates of parameters in statistical models, particularly when the model depends on:
    A. Only observed variables.
    B. Unobserved latent variables.
    C. Only continuous variables.
    D. Only categorical variables.

    Correct Answer: B
1779. **The E-Step (Expectation Step)** in the EM algorithm is responsible for:
    A. Maximizing the likelihood.
    B. Calculating the expected value of the complete-data log-likelihood, given the observed data and the current parameter estimates.
    C. Updating the parameters.
    D. Calculating the prior distribution.

    Correct Answer: B
1780. **The M-Step (Maximization Step)** in the EM algorithm is responsible for:
    A. Calculating the expected value of the complete-data log-likelihood.
    B. Maximizing the expected log-likelihood found in the E-step to update the parameter estimates.
    C. Calculating the prior distribution.
    D. Calculating the posterior distribution.

    Correct Answer: B
1781. **The Latent Dirichlet Allocation (LDA)** is a generative statistical model that is used to explain the:
    A. Only observed variables.
    B. Observed data (documents) as arising from unobserved latent variables (topics).
    C. Only latent variables.
    D. Only a single variable.

    Correct Answer: B
1782. **The Non-Negative Matrix Factorization (NMF)** is a group of algorithms in multivariate analysis and linear algebra where a matrix $V$ is factorized into two matrices $W$ and $H$, such that all three matrices have:
    A. Only negative elements.
    B. No negative elements.
    C. Only positive elements.
    D. Only zero elements.

    Correct Answer: B
1783. **The Independent Component Analysis (ICA)** is a computational method for separating a multivariate signal into:
    A. Only dependent subcomponents.
    B. Additive subcomponents that are statistically as independent as possible.
    C. Only a single component.
    D. Only two components.

    Correct Answer: B
1784. **The Principal Component Regression (PCR)** is a regression technique that uses the **Principal Components** of the predictor variables as the:
    A. Dependent variables.
    B. Predictor variables in a linear regression model.
    C. Only a single variable.
    D. Only two variables.

    Correct Answer: B
1785. **The Partial Least Squares (PLS) Regression** is a regression technique that finds a linear combination of the predictor variables that maximizes the:
    A. Variance of the predictor variables.
    B. Covariance between the predictor and response variables.
    C. Variance of the response variable.
    D. Correlation between the predictor variables.

    Correct Answer: B
1786. **The Difference between PCR and PLS** is that PCR only considers the variance of the predictor variables, while PLS considers the:
    A. Variance of the response variable.
    B. Covariance between the predictor and response variables.
    C. Correlation between the predictor variables.
    D. Correlation between the response variables.

    Correct Answer: B
1787. **The Ridge Regression** is a technique used to address the problem of **Multicollinearity** in linear regression by adding a penalty term to the:
    A. Loss function that is proportional to the sum of the absolute values of the coefficients.
    B. Loss function that is proportional to the sum of the squared values of the coefficients.
    C. Likelihood function.
    D. Prior distribution.

    Correct Answer: B
1788. **The Lasso Regression** is a technique used to address the problem of **Multicollinearity** in linear regression by adding a penalty term to the:
    A. Loss function that is proportional to the sum of the squared values of the coefficients.
    B. Loss function that is proportional to the sum of the absolute values of the coefficients.
    C. Likelihood function.
    D. Prior distribution.

    Correct Answer: B
1789. **The Elastic Net Regression** is a regression technique that combines the penalties of:
    A. Only Ridge Regression.
    B. Ridge Regression and Lasso Regression.
    C. Only Lasso Regression.
    D. Only Principal Component Regression.

    Correct Answer: B
1790. **The Generalized Estimating Equations (GEE)** are a statistical method used to estimate the parameters of a GLM when the data has:
    A. Independent observations.
    B. Correlated observations (e.g., longitudinal data).
    C. Only continuous variables.
    D. Only categorical variables.

    Correct Answer: B
1791. **The Mixed-Effects Models** are a statistical method used to estimate the parameters of a GLM when the data has:
    A. Independent observations.
    B. Correlated observations (e.g., longitudinal data).
    C. Only continuous variables.
    D. Only categorical variables.

    Correct Answer: B
1792. **The Difference between GEE and Mixed-Effects Models** is that GEE focuses on estimating the **Population-Averaged** effects, while Mixed-Effects Models focus on estimating the:
    A. Population-averaged effects.
    B. Subject-specific effects.
    C. Only fixed effects.
    D. Only random effects.

    Correct Answer: B
1793. **The Propensity Score Matching (PSM)** is a statistical matching technique used to reduce **Confounding Bias** in the estimation of treatment effects in:
    A. Randomized controlled trials.
    B. Observational studies.
    C. Only experimental studies.
    D. Only time series studies.

    Correct Answer: B
1794. **The Instrumental Variables (IV) Estimation** is a statistical method used to estimate the causal effect of a treatment when there is:
    A. No confounding bias.
    B. Unmeasured confounding bias.
    C. Only measured confounding bias.
    D. Only a single variable.

    Correct Answer: B
1795. **The Regression Discontinuity Design (RDD)** is a quasi-experimental design used to estimate the causal effect of a treatment when the treatment assignment is determined by whether an:
    A. Individual is above or below a fixed threshold on a continuous variable.
    B. Individual is above or below a fixed threshold on a categorical variable.
    C. Individual is above or below a fixed threshold on a time series variable.
    D. Individual is above or below a fixed threshold on a binary variable.

    Correct Answer: B
1796. **The Difference-in-Differences (DiD) Estimation** is a quasi-experimental design used to estimate the causal effect of a treatment by comparing the:
    A. Change in outcomes over time for a treatment group to the change in outcomes over time for a control group.
    B. Level of outcomes for a treatment group to the level of outcomes for a control group.
    C. Change in outcomes over time for a single group.
    D. Level of outcomes for a single group.

    Correct Answer: B
1797. **The Synthetic Control Method (SCM)** is a statistical method used to estimate the causal effect of a treatment in comparative case studies where the treatment is applied to:
    A. Only a single unit.
    B. A single unit and the control group is a weighted average of a set of untreated units.
    C. Only multiple units.
    D. Only a single unit and the control group is a single untreated unit.

    Correct Answer: A
1798. **The Causal Inference** is a field of statistics that is concerned with the question of whether a change in one variable causes a change in another variable, which is often addressed using:
    A. Only correlation.
    B. Experimental and quasi-experimental designs.
    C. Only regression.
    D. Only clustering.

    Correct Answer: B
1799. **The Potential Outcomes Framework** (or Rubin Causal Model) is a framework for causal inference that defines the causal effect as the difference between the:
    A. Observed outcomes.
    B. Potential outcomes under treatment and control.
    C. Only the treatment outcome.
    D. Only the control outcome.

    Correct Answer: B
1800. **The Stable Unit Treatment Value Assumption (SUTVA)** is a key assumption in the Potential Outcomes Framework that states that the potential outcomes for any unit do not:
    A. Depend on the treatment assignment of other units.
    B. Depend on the treatment assignment of the unit itself.
    C. Depend on the observed outcomes.
    D. Depend on the potential outcomes.
# Batch 19: Q1801–Q1900 - Optimization and Simulation Applications

    Correct Answer: B
1801. **Optimization** is the process of finding the best solution from all feasible solutions, which typically involves:
    A. Maximizing or minimizing an objective function.
    B. Only maximizing a function.
    C. Only minimizing a function.
    D. Finding the average of a function.

    Correct Answer: B
1802. An **Objective Function** in an optimization problem is the function that is to be:
    A. Ignored.
    B. Maximized or minimized.
    C. Set to zero.
    D. Set to one.

    Correct Answer: B
1803. **Constraints** in an optimization problem are conditions that the solution must satisfy, which can be:
    A. Only equality constraints.
    B. Equality or inequality constraints.
    C. Only inequality constraints.
    D. Only non-negativity constraints.

    Correct Answer: B
1804. A **Feasible Region** in an optimization problem is the set of all possible points that satisfy:
    A. Only the objective function.
    B. All the constraints.
    C. Only the non-negativity constraints.
    D. Only the equality constraints.

    Correct Answer: B
1805. **Linear Programming (LP)** is a mathematical method for determining a way to achieve the best outcome (such as maximum profit or lowest cost) in a mathematical model whose requirements are expressed as:
    A. Non-linear relationships.
    B. Linear relationships.
    C. Exponential relationships.
    D. Logarithmic relationships.

    Correct Answer: B
1806. The **Simplex Algorithm** is a popular algorithm for solving:
    A. Non-linear programming problems.
    B. Linear programming problems.
    C. Integer programming problems.
    D. Dynamic programming problems.

    Correct Answer: B
1807. **Integer Programming (IP)** is a mathematical optimization program in which some or all of the variables are restricted to be:
    A. Continuous.
    B. Integers.
    C. Binary.
    D. Real numbers.

    Correct Answer: B
1808. **Mixed-Integer Programming (MIP)** is a mathematical optimization program in which some variables are restricted to be **Integers** and others are allowed to be:
    A. Binary.
    B. Continuous.
    C. Only positive.
    D. Only negative.

    Correct Answer: A
1809. **Non-Linear Programming (NLP)** is the process of solving an optimization problem where the objective function or the constraints are:
    A. Linear.
    B. Non-linear.
    C. Integer.
    D. Binary.

    Correct Answer: A
1810. **Convex Optimization** is a subfield of optimization where the objective function is **Convex** and the feasible region is a **Convex Set**, which guarantees that any local optimum is also a:
    A. Local minimum.
    B. Global minimum.
    C. Local maximum.
    D. Global maximum.

    Correct Answer: B
1811. **The Karush-Kuhn-Tucker (KKT) Conditions** are first-order necessary conditions for a solution in non-linear programming to be optimal, provided that some:
    A. Linearity conditions are met.
    B. Regularity conditions are met.
    C. Integer conditions are met.
    D. Binary conditions are met.

    Correct Answer: B
1812. **Dynamic Programming** is a method for solving complex problems by breaking them down into simpler subproblems, which is applicable when the problem has:
    A. Only a single stage.
    B. Overlapping subproblems and optimal substructure.
    C. Only a single solution.
    D. Only a single constraint.

    Correct Answer: B
1813. **Stochastic Optimization** is an optimization method that deals with optimization problems in which the objective function or the constraints are:
    A. Deterministic.
    B. Stochastic (involve random variables).
    C. Linear.
    D. Non-linear.

    Correct Answer: B
1814. **Simulation** is the imitation of the operation of a real-world process or system over time, which is often used to:
    A. Find the optimal solution.
    B. Estimate the performance of a system under different conditions.
    C. Only find the average.
    D. Only find the standard deviation.

    Correct Answer: B
1815. **Monte Carlo Simulation** is a broad class of computational algorithms that rely on repeated:
    A. Deterministic calculations.
    B. Random sampling to obtain numerical results.
    C. Linear programming.
    D. Non-linear programming.

    Correct Answer: B
1816. **Discrete-Event Simulation (DES)** is a simulation method where the system's state changes only at a discrete set of:
    A. Continuous time points.
    B. Time points where an event occurs.
    C. Only the start of the simulation.
    D. Only the end of the simulation.

    Correct Answer: B
1817. **System Dynamics** is a simulation method for modeling the behavior of complex systems over time, which focuses on:
    A. Individual events.
    B. Feedback loops and time delays.
    C. Only linear relationships.
    D. Only non-linear relationships.

    Correct Answer: B
1818. **Risk Analysis** is the process of identifying and analyzing potential issues that could negatively impact key business initiatives or projects, which often uses:
    A. Only deterministic models.
    B. Simulation and probability distributions.
    C. Only linear programming.
    D. Only non-linear programming.

    Correct Answer: B
1819. **Value at Risk (VaR)** is a measure of the risk of loss for investments, which estimates the maximum loss expected over a given time period at a specified:
    A. Mean.
    B. Confidence level.
    C. Standard deviation.
    D. Median.

    Correct Answer: B
1820. **Conditional Value at Risk (CVaR)**, also known as Expected Shortfall (ES), is a risk measure that is more sensitive to the shape of the:
    A. Right tail of the distribution.
    B. Left tail of the distribution (extreme losses).
    C. Mean of the distribution.
    D. Standard deviation of the distribution.

    Correct Answer: A
1821. **Decision Analysis** is a systematic, quantitative, and transparent approach to making decisions under conditions of:
    A. Certainty.
    B. Uncertainty.
    C. Only risk.
    D. Only ambiguity.

    Correct Answer: A
1822. A **Decision Tree** in decision analysis is a tree-like model of decisions and their possible consequences, including:
    A. Only chance event outcomes.
    B. Chance event outcomes, resource costs, and utility.
    C. Only resource costs.
    D. Only utility.

    Correct Answer: B
1823. **Utility Theory** in decision analysis is a theory that measures the **Preference** over a set of goods or services, which is used to:
    A. Maximize the expected monetary value.
    B. Maximize the expected utility.
    C. Minimize the expected monetary value.
    D. Minimize the expected utility.

    Correct Answer: B
1824. **Sensitivity Analysis** in optimization and simulation is the study of how the uncertainty in the output of a model can be apportioned to different sources of:
    A. Certainty in the model input.
    B. Uncertainty in the model input.
    C. Only the objective function.
    D. Only the constraints.

    Correct Answer: B
1825. **The Shadow Price (or Dual Price)** in linear programming is the change in the **Optimal Value** of the objective function when the right-hand side of a constraint is:
    A. Increased by one unit.
    B. Decreased by one unit.
    C. Increased by two units.
    D. Decreased by two units.

    Correct Answer: B
1826. **The Reduced Cost** in linear programming is the amount by which the objective function coefficient of a non-basic variable must be improved before it would be:
    A. Increased.
    B. Optimal to include it in the solution.
    C. Decreased.
    D. Ignored.

    Correct Answer: B
1827. **The Transportation Problem** is a classic linear programming problem that seeks to minimize the total cost of:
    A. Production.
    B. Shipping a commodity from a set of sources to a set of destinations.
    C. Inventory.
    D. Labor.

    Correct Answer: B
1828. **The Assignment Problem** is a special case of the transportation problem where the objective is to assign a set of **Agents** to a set of **Tasks** such that the total cost is:
    A. Maximized.
    B. Minimized.
    C. Set to zero.
    D. Set to one.

    Correct Answer: B
1829. **The Shortest Path Problem** is a classic optimization problem that seeks to find a path between two nodes in a graph such that the sum of the weights of its constituent edges is:
    A. Maximized.
    B. Minimized.
    C. Set to zero.
    D. Set to one.

    Correct Answer: B
1830. **The Traveling Salesperson Problem (TSP)** is an NP-hard optimization problem that seeks to find the shortest possible route that visits a set of cities and returns to the:
    A. Last city.
    B. Starting city.
    C. Nearest city.
    D. Farthest city.

    Correct Answer: B
1831. **The Knapsack Problem** is a problem in combinatorial optimization where the goal is to choose a set of items, each with a weight and a value, to include in a knapsack such that the total weight is less than or equal to a given limit and the total value is:
    A. Minimized.
    B. Maximized.
    C. Set to zero.
    D. Set to one.

    Correct Answer: B
1832. **The Critical Path Method (CPM)** is a project modeling technique used to manage the activities involved in a project, which identifies the:
    A. Shortest path.
    B. Longest sequence of dependent activities that determines the minimum time needed to complete the project.
    C. Average path.
    D. Fastest path.

    Correct Answer: B
1833. **The Program Evaluation and Review Technique (PERT)** is a project management tool used to schedule, organize, and coordinate tasks within a project, which uses a:
    A. Single time estimate.
    B. Probabilistic approach with three time estimates (optimistic, pessimistic, and most likely).
    C. Only two time estimates.
    D. Only a single cost estimate.

    Correct Answer: B
1834. **The Queueing Theory** (or waiting line theory) is the mathematical study of waiting lines, which is used to:
    A. Maximize the waiting time.
    B. Optimize the service capacity and minimize the waiting time.
    C. Minimize the service capacity.
    D. Only find the average waiting time.

    Correct Answer: B
1835. **The Little's Law** in queueing theory states that the average number of customers in a stable system ($L$) is equal to the average customer arrival rate ($\lambda$) multiplied by the average time a customer spends in the system ($W$), which is given by:
    A. $L = \lambda / W$
    B. $L = \lambda W$
    C. $L = W / \lambda$
    D. $L = \lambda + W$

    Correct Answer: B
1836. **The Inventory Theory** is a branch of operations research that deals with the management of inventory, which seeks to minimize the total cost of:
    A. Only ordering.
    B. Ordering, holding, and shortage.
    C. Only holding.
    D. Only shortage.

    Correct Answer: B
1837. **The Economic Order Quantity (EOQ) Model** is an inventory model that determines the optimal order quantity that minimizes the total cost of:
    A. Only ordering.
    B. Ordering and holding.
    C. Only holding.
    D. Only shortage.

    Correct Answer: A
1838. **The Newsboy Problem** is a classic inventory problem that seeks to determine the optimal order quantity for a perishable product with a single selling period, which balances the cost of:
    A. Only overstocking.
    B. Overstocking and understocking.
    C. Only understocking.
    D. Only ordering.

    Correct Answer: B
1839. **The Markov Decision Process (MDP)** is a mathematical framework for modeling decision-making in situations where outcomes are partly:
    A. Deterministic and partly random.
    B. Only deterministic.
    C. Only random.
    D. Only linear.

    Correct Answer: B
1840. **The Bellman Equation** is a necessary condition for optimality associated with dynamic programming, which expresses the value of a decision problem at a certain point in time in terms of the:
    A. Future value.
    B. Value at later points in time.
    C. Past value.
    D. Current value.

    Correct Answer: B
1841. **The Reinforcement Learning (RL)** is an area of machine learning concerned with how intelligent agents ought to take actions in an environment to maximize the notion of:
    A. Only immediate reward.
    B. Cumulative reward.
    C. Only future reward.
    D. Only past reward.

    Correct Answer: B
1842. **The Q-Learning** is a model-free reinforcement learning algorithm that seeks to find an optimal **Action-Selection Policy** by learning the:
    A. State value function.
    B. Action-value function (Q-function).
    C. State-action value function.
    D. Only the reward.

    Correct Answer: B
1843. **The Deep Reinforcement Learning (DRL)** is a subfield of RL that combines RL with **Deep Learning** to allow agents to learn directly from:
    A. Only structured data.
    B. High-dimensional sensory input.
    C. Only low-dimensional sensory input.
    D. Only a single variable.

    Correct Answer: B
1844. **The Simulation-Optimization** is a methodology that combines **Simulation** with **Optimization** to find the best solution for a system that is too complex to be modeled by:
    A. Only deterministic models.
    B. Analytical methods.
    C. Only stochastic models.
    D. Only linear models.

    Correct Answer: B
1845. **The Genetic Algorithm (GA)** is a metaheuristic inspired by the process of **Natural Selection**, which is used to find approximate solutions to:
    A. Only linear optimization problems.
    B. Optimization and search problems.
    C. Only convex optimization problems.
    D. Only non-convex optimization problems.

    Correct Answer: B
1846. **The Tabu Search** is a metaheuristic search method that employs a **Local Search** procedure to explore the solution space, which uses a **Tabu List** to:
    A. Encourage the search to return to previously visited solutions.
    B. Prevent the search from returning to previously visited solutions.
    C. Only explore new solutions.
    D. Only exploit existing solutions.

    Correct Answer: B
1847. **The Simulated Annealing** is a probabilistic technique for approximating the global optimum of a given function, which is inspired by the process of:
    A. Natural selection.
    B. Annealing in metallurgy.
    C. Random walk.
    D. Gradient descent.

    Correct Answer: B
1848. **The Ant Colony Optimization (ACO)** is a probabilistic technique for solving computational problems which can be reduced to finding paths through graphs, which is inspired by the behavior of:
    A. Bees.
    B. Ants seeking a path to food.
    C. Birds.
    D. Fish.

    Correct Answer: B
1849. **The Particle Swarm Optimization (PSO)** is a computational method that optimizes a problem by iteratively trying to improve a candidate solution with regard to a given measure of quality, which is inspired by the social behavior of:
    A. Bees.
    B. Bird flocking or fish schooling.
    C. Ants.
    D. Spiders.

    Correct Answer: B
1850. **The Hill Climbing** is a mathematical optimization technique that belongs to the family of **Local Search** algorithms, which iteratively moves in the direction of:
    A. Decreasing elevation.
    B. Increasing elevation (uphill).
    C. Random direction.
    D. Only a single direction.

    Correct Answer: B
1851. **The Gradient Descent** is a first-order iterative optimization algorithm for finding the local minimum of a differentiable function, which iteratively moves in the direction of the:
    A. Positive gradient.
    B. Negative gradient.
    C. Zero gradient.
    D. Only a single direction.

    Correct Answer: B
1852. **The Stochastic Gradient Descent (SGD)** is a variation of the Gradient Descent algorithm that computes the gradient and updates the parameters for:
    A. The entire dataset.
    B. A single training example or a small batch of training examples.
    C. Only a single parameter.
    D. Only a single layer.

    Correct Answer: A
1853. **The Conjugate Gradient Method** is an algorithm for the numerical solution of particular systems of linear equations, namely those whose matrix is:
    A. Symmetric and positive definite.
    B. Asymmetric and negative definite.
    C. Only symmetric.
    D. Only positive definite.

    Correct Answer: B
1854. **The Newton's Method** is an iterative method for finding the roots of a differentiable function, which uses the:
    A. First derivative.
    B. First and second derivatives (Hessian matrix).
    C. Only the second derivative.
    D. Only the function value.

    Correct Answer: B
1855. **The Quasi-Newton Methods** are a class of iterative methods for finding the local minimum or maximum of functions, which do not require the calculation of the:
    A. First derivative.
    B. Second derivative (Hessian matrix).
    C. Only the function value.
    D. Only the first derivative.

    Correct Answer: B
1856. **The Sequential Quadratic Programming (SQP)** is an iterative method for non-linear optimization that solves a sequence of:
    A. Linear programming problems.
    B. Quadratic programming problems.
    C. Integer programming problems.
    D. Dynamic programming problems.

    Correct Answer: B
1857. **The Interior-Point Methods** (or barrier methods) are a class of algorithms for solving linear and non-linear convex optimization problems, which approach the boundary of the feasible region from the:
    A. Outside.
    B. Inside.
    C. Only the boundary.
    D. Only the center.

    Correct Answer: B
1858. **The Branch and Bound Algorithm** is a general algorithm for finding optimal solutions to various optimization problems, especially those of:
    A. Linear programming.
    B. Discrete and combinatorial optimization.
    C. Non-linear programming.
    D. Convex optimization.

    Correct Answer: B
1859. **The Cutting-Plane Method** is an optimization technique used to solve:
    A. Only linear programming problems.
    B. Integer programming problems.
    C. Only non-linear programming problems.
    D. Only convex optimization problems.

    Correct Answer: B
1860. **The Column Generation** is an algorithm for solving large linear programming problems, which works by:
    A. Adding new rows to the problem.
    B. Adding new columns (variables) to the problem.
    C. Removing existing rows from the problem.
    D. Removing existing columns from the problem.

    Correct Answer: B
1861. **The Network Flow Problem** is an optimization problem that seeks to find the maximum flow from a source node to a sink node in a network, which is solved using the:
    A. Simplex algorithm.
    B. Ford-Fulkerson algorithm.
    C. Dijkstra's algorithm.
    D. Bellman-Ford algorithm.

    Correct Answer: B
1862. **The Minimum Cost Flow Problem** is an optimization problem that seeks to find the flow from a source node to a sink node in a network such that the total cost is:
    A. Maximized.
    B. Minimized.
    C. Set to zero.
    D. Set to one.

    Correct Answer: B
1863. **The Shortest Path Problem** is a classic optimization problem that seeks to find a path between two nodes in a graph such that the sum of the weights of its constituent edges is:
    A. Maximized.
    B. Minimized.
    C. Set to zero.
    D. Set to one.

    Correct Answer: B
1864. **The Dijkstra's Algorithm** is an algorithm for finding the shortest paths between nodes in a graph, which works for graphs with:
    A. Only negative edge weights.
    B. Non-negative edge weights.
    C. Only positive edge weights.
    D. Only zero edge weights.

    Correct Answer: B
1865. **The Bellman-Ford Algorithm** is an algorithm for finding the shortest paths between nodes in a graph, which works for graphs with:
    A. Only non-negative edge weights.
    B. Negative edge weights, but no negative cycles.
    C. Only positive edge weights.
    D. Only zero edge weights.

    Correct Answer: B
1866. **The Floyd-Warshall Algorithm** is an algorithm for finding the shortest paths between **All Pairs** of nodes in a graph, which works for graphs with:
    A. Only non-negative edge weights.
    B. Negative edge weights, but no negative cycles.
    C. Only positive edge weights.
    D. Only zero edge weights.

    Correct Answer: B
1867. **The Minimum Spanning Tree (MST) Problem** is an optimization problem that seeks to find a subset of the edges of a connected, edge-weighted undirected graph that connects all the vertices together, without any cycles and with the minimum possible:
    A. Number of edges.
    B. Total edge weight.
    C. Number of vertices.
    D. Total number of cycles.

    Correct Answer: B
1868. **The Prim's Algorithm** is a greedy algorithm for finding a:
    A. Maximum spanning tree.
    B. Minimum spanning tree.
    C. Shortest path.
    D. Longest path.

    Correct Answer: B
1869. **The Kruskal's Algorithm** is a greedy algorithm for finding a:
    A. Maximum spanning tree.
    B. Minimum spanning tree.
    C. Shortest path.
    D. Longest path.

    Correct Answer: B
1870. **The Maximum Flow Problem** is an optimization problem that seeks to find the maximum flow from a source node to a sink node in a network, which is solved using the:
    A. Simplex algorithm.
    B. Ford-Fulkerson algorithm.
    C. Dijkstra's algorithm.
    D. Bellman-Ford algorithm.

    Correct Answer: B
1871. **The Min-Cut Max-Flow Theorem** states that the maximum flow from a source to a sink in a network is equal to the minimum capacity of a:
    A. Path from the source to the sink.
    B. Cut that separates the source from the sink.
    C. Cycle in the network.
    D. Tree in the network.

    Correct Answer: A
1872. **The Game Theory** is the study of mathematical models of strategic interaction among:
    A. Only a single rational decision-maker.
    B. Rational decision-makers.
    C. Only two rational decision-makers.
    D. Only three rational decision-makers.

    Correct Answer: A
1873. **The Nash Equilibrium** is a concept in game theory where the optimal outcome of a game is one where no player has an incentive to:
    A. Change their strategy, given the strategies of the other players.
    B. Change their strategy, regardless of the strategies of the other players.
    C. Only change their reward.
    D. Only change their cost.

    Correct Answer: B
1874. **The Prisoner's Dilemma** is a classic example of a game in game theory that shows why two completely rational individuals might not:
    A. Cooperate, even if it is in their best interest to do so.
    B. Compete, even if it is in their best interest to do so.
    C. Only cooperate.
    D. Only compete.

    Correct Answer: B
1875. **The Evolutionary Game Theory** is the application of game theory to evolving populations in biology, which focuses on the dynamics of:
    A. Only rational decision-makers.
    B. Strategy change.
    C. Only two rational decision-makers.
    D. Only three rational decision-makers.

    Correct Answer: B
1876. **The Agent-Based Modeling (ABM)** is a computational modeling technique that simulates the actions and interactions of:
    A. Only a single agent.
    B. Autonomous agents (individuals or groups) to assess their effects on the system as a whole.
    C. Only two agents.
    D. Only three agents.

    Correct Answer: B
1877. **The Multi-Agent System (MAS)** is a computerized system composed of multiple interacting intelligent agents, which are often used to:
    A. Only solve a single problem.
    B. Solve problems that are difficult or impossible for a single agent or monolithic system to solve.
    C. Only solve a single task.
    D. Only solve a single optimization problem.

    Correct Answer: B
1878. **The Swarm Intelligence** is the collective behavior of decentralized, self-organized systems, natural or artificial, which is often used to:
    A. Only solve a single problem.
    B. Solve complex problems.
    C. Only solve a single task.
    D. Only solve a single optimization problem.

    Correct Answer: B
1879. **The Artificial Bee Colony (ABC) Algorithm** is a swarm intelligence algorithm that is inspired by the foraging behavior of:
    A. Ants.
    B. Honey bee colonies.
    C. Birds.
    D. Fish.

    Correct Answer: B
1880. **The Firefly Algorithm (FA)** is a swarm intelligence algorithm that is inspired by the flashing behavior of:
    A. Ants.
    B. Fireflies.
    C. Birds.
    D. Fish.

    Correct Answer: B
1881. **The Cuckoo Search (CS)** is a swarm intelligence algorithm that is inspired by the brood parasitism of:
    A. Ants.
    B. Cuckoo birds.
    C. Birds.
    D. Fish.

    Correct Answer: B
1882. **The Harmony Search (HS)** is a metaheuristic algorithm that is inspired by the process of:
    A. Natural selection.
    B. Musical improvisation.
    C. Random walk.
    D. Gradient descent.

    Correct Answer: B
1883. **The Simulated Annealing** is a probabilistic technique for approximating the global optimum of a given function, which is inspired by the process of:
    A. Natural selection.
    B. Annealing in metallurgy.
    C. Random walk.
    D. Gradient descent.

    Correct Answer: B
1884. **The Tabu Search** is a metaheuristic search method that employs a **Local Search** procedure to explore the solution space, which uses a **Tabu List** to:
    A. Encourage the search to return to previously visited solutions.
    B. Prevent the search from returning to previously visited solutions.
    C. Only explore new solutions.
    D. Only exploit existing solutions.

    Correct Answer: B
1885. **The Genetic Algorithm (GA)** is a metaheuristic inspired by the process of **Natural Selection**, which is used to find approximate solutions to:
    A. Only linear optimization problems.
    B. Optimization and search problems.
    C. Only convex optimization problems.
    D. Only non-convex optimization problems.

    Correct Answer: B
1886. **The Particle Swarm Optimization (PSO)** is a computational method that optimizes a problem by iteratively trying to improve a candidate solution with regard to a given measure of quality, which is inspired by the social behavior of:
    A. Bees.
    B. Bird flocking or fish schooling.
    C. Ants.
    D. Spiders.

    Correct Answer: A
1887. **The Ant Colony Optimization (ACO)** is a probabilistic technique for solving computational problems which can be reduced to finding paths through graphs, which is inspired by the behavior of:
    A. Bees.
    B. Ants seeking a path to food.
    C. Birds.
    D. Fish.

    Correct Answer: A
1888. **The Hill Climbing** is a mathematical optimization technique that belongs to the family of **Local Search** algorithms, which iteratively moves in the direction of:
    A. Decreasing elevation.
    B. Increasing elevation (uphill).
    C. Random direction.
    D. Only a single direction.

    Correct Answer: B
1889. **The Gradient Descent** is a first-order iterative optimization algorithm for finding the local minimum of a differentiable function, which iteratively moves in the direction of the:
    A. Positive gradient.
    B. Negative gradient.
    C. Zero gradient.
    D. Only a single direction.

    Correct Answer: B
1890. **The Stochastic Gradient Descent (SGD)** is a variation of the Gradient Descent algorithm that computes the gradient and updates the parameters for:
    A. The entire dataset.
    B. A single training example or a small batch of training examples.
    C. Only a single parameter.
    D. Only a single layer.

    Correct Answer: B
1891. **The Conjugate Gradient Method** is an algorithm for the numerical solution of particular systems of linear equations, namely those whose matrix is:
    A. Symmetric and positive definite.
    B. Asymmetric and negative definite.
    C. Only symmetric.
    D. Only positive definite.

    Correct Answer: B
1892. **The Newton's Method** is an iterative method for finding the roots of a differentiable function, which uses the:
    A. First derivative.
    B. First and second derivatives (Hessian matrix).
    C. Only the second derivative.
    D. Only the function value.

    Correct Answer: B
1893. **The Quasi-Newton Methods** are a class of iterative methods for finding the local minimum or maximum of functions, which do not require the calculation of the:
    A. First derivative.
    B. Second derivative (Hessian matrix).
    C. Only the function value.
    D. Only the first derivative.

    Correct Answer: B
1894. **The Sequential Quadratic Programming (SQP)** is an iterative method for non-linear optimization that solves a sequence of:
    A. Linear programming problems.
    B. Quadratic programming problems.
    C. Integer programming problems.
    D. Dynamic programming problems.

    Correct Answer: B
1895. **The Interior-Point Methods** (or barrier methods) are a class of algorithms for solving linear and non-linear convex optimization problems, which approach the boundary of the feasible region from the:
    A. Outside.
    B. Inside.
    C. Only the boundary.
    D. Only the center.

    Correct Answer: C
1896. **The Branch and Bound Algorithm** is a general algorithm for finding optimal solutions to various optimization problems, especially those of:
    A. Linear programming.
    B. Discrete and combinatorial optimization.
    C. Non-linear programming.
    D. Convex optimization.

    Correct Answer: B
1897. **The Cutting-Plane Method** is an optimization technique used to solve:
    A. Only linear programming problems.
    B. Integer programming problems.
    C. Only non-linear programming problems.
    D. Only convex optimization problems.

    Correct Answer: B
1898. **The Column Generation** is an algorithm for solving large linear programming problems, which works by:
    A. Adding new rows to the problem.
    B. Adding new columns (variables) to the problem.
    C. Removing existing rows from the problem.
    D. Removing existing columns from the problem.

    Correct Answer: C
1899. **The Network Flow Problem** is an optimization problem that seeks to find the maximum flow from a source node to a sink node in a network, which is solved using the:
    A. Simplex algorithm.
    B. Ford-Fulkerson algorithm.
    C. Dijkstra's algorithm.
    D. Bellman-Ford algorithm.

    Correct Answer: C
1900. **The Minimum Cost Flow Problem** is an optimization problem that seeks to find the flow from a source node to a sink node in a network such that the total cost is:
    A. Maximized.
    B. Minimized.
    C. Set to zero.
    D. Set to one.
# Batch 2: Q101–Q200 - Probability Theory and Distributions

    Correct Answer: A
101. A financial analyst is modeling the number of daily trades for a specific stock. Since the trades occur independently and at a constant average rate, which discrete probability distribution is most appropriate for this scenario?
    A. Binomial Distribution
    B. Normal Distribution
    C. Poisson Distribution
    D. Uniform Distribution

    Correct Answer: C
102. A company manufactures light bulbs, and historical data shows that 5% of the bulbs are defective. If a quality control inspector randomly selects 20 bulbs, what is the probability distribution that should be used to find the probability of exactly 2 defective bulbs in the sample?
    A. Poisson Distribution
    B. Binomial Distribution
    C. Exponential Distribution
    D. Chi-square Distribution

    Correct Answer: D
103. In a standard Normal Distribution, what is the mean ($\mu$) and standard deviation ($\sigma$)?
    A. $\mu = 1, \sigma = 1$
    B. $\mu = 0, \sigma = 1$
    C. $\mu = 1, \sigma = 0$
    D. $\mu = 0, \sigma = 0$

    Correct Answer: B
104. A data scientist is calculating the probability of two independent events, A and B, both occurring. Which formula correctly represents this joint probability, P(A and B)?
    A. $P(A) + P(B)$
    B. $P(A) \cdot P(B)$
    C. $P(A) + P(B) - P(A \text{ or } B)$
    D. $P(A) \cdot P(B|A)$

    Correct Answer: B
105. A bag contains 5 red and 5 blue marbles. A marble is drawn, its color is noted, and it is *not* replaced. A second marble is drawn. The probability of the second draw is an example of:
    A. Independent Events
    B. Mutually Exclusive Events
    C. Conditional Probability
    D. Complementary Events

    Correct Answer: D
106. A marketing team is trying to predict the success of a new ad campaign. They use Bayes' Theorem to update their initial belief (prior probability) about the campaign's success based on the results of a small test market (new evidence). This process is known as:
    A. Frequentist Inference
    B. Maximum Likelihood Estimation
    C. Probabilistic Reasoning
    D. Hypothesis Testing

    Correct Answer: C
107. The time taken for a customer service representative to answer a call is a continuous variable. Which of the following is a key characteristic of a continuous probability distribution?
    A. The probability of the variable taking on any single, exact value is zero.
    B. The sum of all probabilities must be greater than 1.
    C. It can only be used for discrete counting data.
    D. The distribution is always symmetrical.

    Correct Answer: D
108. In the context of probability, what is the **Sample Space**?
    A. The outcome of a single trial.
    B. The set of all possible outcomes of an experiment.
    C. The event that cannot happen.
    D. The number of favorable outcomes.

    Correct Answer: B
109. A deck of 52 cards is shuffled. What is the probability of drawing a King or a Queen?
    A. $1/52$
    B. $4/52$
    C. $8/52$
    D. $1/26$

    Correct Answer: B
110. A financial model assumes that the daily percentage change in a stock price follows a Normal Distribution. If the mean change is 0.1% and the standard deviation is 1.5%, what percentage of days would be expected to have a change between -2.9% and 3.1% (i.e., within $\pm 2$ standard deviations)?
    A. Approximately 68%
    B. Approximately 75%
    C. Approximately 89%
    D. Approximately 95%

    Correct Answer: B
111. A data scientist is calculating the number of ways to select a committee of 3 people from a group of 10, where the order of selection does not matter. Which mathematical concept should be used?
    A. Permutation
    B. Combination
    C. Factorial
    D. Probability

    Correct Answer: B
112. A machine has a 90% success rate for a certain operation. If the operation is repeated 10 times, what are the parameters ($n$ and $p$) for the Binomial Distribution that models the number of successful operations?
    A. $n=10, p=0.1$
    B. $n=10, p=0.9$
    C. $n=0.9, p=10$
    D. $n=1, p=0.9$

    Correct Answer: B
113. If $P(A) = 0.5$, $P(B) = 0.4$, and $P(A \text{ and } B) = 0.2$, what is the probability of $P(A \text{ or } B)$?
    A. 0.9
    B. 0.7
    C. 0.2
    D. 0.5

    Correct Answer: C
114. The **complementary event** of "getting at least one head" when tossing three coins is:
    A. Getting exactly one head.
    B. Getting exactly two heads.
    C. Getting exactly three heads.
    D. Getting no heads (all tails).

    Correct Answer: A
115. A Poisson distribution is often used to model:
    A. The number of successes in a fixed number of trials.
    B. The time until the first success in a series of trials.
    C. The number of events occurring in a fixed interval of time or space.
    D. The probability of a continuous variable.

    Correct Answer: A
116. If two events, A and B, are **mutually exclusive**, what is the probability of both events occurring, $P(A \text{ and } B)$?
    A. $P(A) \cdot P(B)$
    B. $P(A) + P(B)$
    C. 1
    D. 0

    Correct Answer: A
117. A manufacturing process produces 1% defective items. If a sample of 100 items is taken, the mean ($\mu$) and variance ($\sigma^2$) of the number of defective items, assuming a Binomial distribution, are:
    A. $\mu = 1, \sigma^2 = 0.99$
    B. $\mu = 1, \sigma^2 = 1$
    C. $\mu = 100, \sigma^2 = 1$
    D. $\mu = 0.01, \sigma^2 = 0.0099$

    Correct Answer: A
118. In a continuous distribution, the area under the probability density function (PDF) curve between two points represents:
    A. The probability of the variable taking on a single value.
    B. The cumulative probability between those two points.
    C. The mean of the distribution.
    D. The standard deviation.

    Correct Answer: B
119. A data scientist is using **Bayes' Theorem** to calculate $P(A|B)$. Which component represents the **Prior Probability**?
    A. $P(A)$
    B. $P(B|A)$
    C. $P(B)$
    D. $P(A|B)$

    Correct Answer: B
120. The key difference between **Permutation** and **Combination** is that:
    A. Permutation is used for selection, Combination for arrangement.
    B. Permutation is used when order matters, Combination when order does not matter.
    C. Permutation is for smaller sets, Combination for larger sets.
    D. Permutation is a probability, Combination is a count.

    Correct Answer: C
121. A discrete random variable $X$ has the following probability distribution: $P(X=1)=0.2, P(X=2)=0.5, P(X=3)=0.3$. What is the expected value $E(X)$?
    A. 2.0
    B. 2.1
    C. 1.0
    D. 3.0

    Correct Answer: C
122. The **Normal Distribution** is often referred to as the "bell curve" due to its shape. Which of the following is a characteristic of the Normal Distribution?
    A. It is always skewed to the right.
    B. The mean, median, and mode are all equal.
    C. It is defined by a single parameter, the mean.
    D. The tails of the distribution never touch the x-axis.

    Correct Answer: C
123. If $P(A|B) = P(A)$, what can be concluded about events A and B?
    A. They are mutually exclusive.
    B. They are dependent.
    C. They are independent.
    D. They are complementary.

    Correct Answer: B
124. A quality control process monitors the number of flaws in a roll of fabric. The average number of flaws is 2 per roll. What is the probability of finding exactly 3 flaws in a randomly selected roll, assuming a Poisson distribution?
    A. $e^{-2} \cdot 2^3 / 3!$
    B. $e^{-3} \cdot 2^3 / 3!$
    C. $e^{-2} \cdot 3^2 / 2!$
    D. $e^{-3} \cdot 3^2 / 2!$

    Correct Answer: B
125. A researcher is selecting 4 distinct items from a list of 12. The order in which the items are selected is important. How many different arrangements are possible?
    A. $12! / (4! \cdot 8!)$
    B. $12! / 4!$
    C. $12! / 8!$
    D. $12 \cdot 4$

    Correct Answer: B
126. In a game, the probability of winning is $0.6$. If you play the game 5 times, what is the probability of winning exactly 3 times?
    A. $\binom{5}{3} (0.6)^3 (0.4)^2$
    B. $\binom{5}{3} (0.4)^3 (0.6)^2$
    C. $(0.6)^3 (0.4)^2$
    D. $5 \cdot (0.6)^3 (0.4)^2$

    Correct Answer: B
127. A continuous random variable is uniformly distributed between 0 and 10. What is the probability density function $f(x)$ for $0 \le x \le 10$?
    A. $f(x) = 1/10$
    B. $f(x) = 1/11$
    C. $f(x) = 10$
    D. $f(x) = 1$

    Correct Answer: D
128. If $P(A) = 0.6$ and $P(B|A) = 0.8$, what is the joint probability $P(A \text{ and } B)$?
    A. 0.48
    B. 1.4
    C. 0.2
    D. 0.75

    Correct Answer: C
129. The **Law of Total Probability** is used to:
    A. Calculate the probability of the intersection of two events.
    B. Calculate the probability of an event by considering all possible mutually exclusive ways it can occur.
    C. Determine if two events are independent.
    D. Calculate the expected value of a random variable.

    Correct Answer: A
130. A discrete probability distribution is defined by the probability mass function (PMF). What must the sum of all probabilities in a PMF equal?
    A. 0
    B. 1
    C. The mean
    D. The standard deviation

    Correct Answer: C
131. The **Bayes' Factor** is a ratio used in Bayesian statistics to compare:
    A. The prior probability to the posterior probability.
    B. The likelihood of the data under two competing hypotheses.
    C. The mean to the standard deviation.
    D. The sample size to the population size.

    Correct Answer: D
132. Which of the following is a key assumption of the **Binomial Distribution**?
    A. The trials are dependent.
    B. The probability of success changes from trial to trial.
    C. There are only two possible outcomes for each trial (success or failure).
    D. The number of trials is infinite.

    Correct Answer: A
133. A dataset of the time between successive customer arrivals at a store is collected. Which continuous distribution is typically used to model the time between events in a Poisson process?
    A. Normal Distribution
    B. Uniform Distribution
    C. Exponential Distribution
    D. Binomial Distribution

    Correct Answer: C
134. A researcher is interested in the probability of event A occurring, given that event B has already occurred. This is the definition of:
    A. Joint Probability
    B. Marginal Probability
    C. Conditional Probability
    D. Total Probability

    Correct Answer: B
135. If a random variable $X$ follows a Normal Distribution with $\mu=50$ and $\sigma=5$, what is the $Z$-score for $X=60$?
    A. 1
    B. 2
    C. -1
    D. -2

    Correct Answer: C
136. A box contains 10 items, 3 of which are defective. If 2 items are randomly selected *without* replacement, what is the probability that both are defective?
    A. $(3/10) \cdot (3/10)$
    B. $(3/10) \cdot (2/9)$
    C. $(3/10) \cdot (7/10)$
    D. $(3/10) + (2/9)$

    Correct Answer: B
137. In the context of probability, what is an **Impossible Event**?
    A. An event with a probability of 1.
    B. An event with a probability of 0.
    C. An event that is mutually exclusive with all other events.
    D. An event that is independent of all other events.

    Correct Answer: A
138. The **Central Limit Theorem** allows the use of the Normal Distribution to approximate the sampling distribution of the sample mean, even if the population distribution is not normal, provided that:
    A. The population standard deviation is known.
    B. The sample size is sufficiently large (typically $n \ge 30$).
    C. The population mean is known.
    D. The data is continuous.

    Correct Answer: C
139. The number of ways to arrange 5 distinct books on a shelf is an example of:
    A. Combination
    B. Permutation
    C. Poisson Process
    D. Binomial Trial

    Correct Answer: A
140. A discrete random variable $X$ is the number of heads in 4 coin tosses. What is the maximum value of $X$?
    A. 1
    B. 2
    C. 3
    D. 4

    Correct Answer: D
141. The **Poisson Distribution** is a limiting case of the Binomial Distribution when:
    A. $n$ is small and $p$ is large.
    B. $n$ is large and $p$ is large.
    C. $n$ is large and $p$ is small (or $\lambda = np$ is constant).
    D. $n$ is small and $p$ is small.

    Correct Answer: B
142. A company is analyzing the lifespan of a product, which is known to follow an **Exponential Distribution**. A key property of this distribution is the **memoryless property**, which implies:
    A. The probability of the product lasting an additional time unit is independent of how long it has already lasted.
    B. The mean and standard deviation are always equal.
    C. The distribution is symmetrical.
    D. The probability of failure is constant over time.

    Correct Answer: B
143. A continuous random variable $X$ is normally distributed. The probability $P(X > \mu)$ is:
    A. 0
    B. 0.5
    C. 1
    D. Depends on the standard deviation

    Correct Answer: B
144. If $P(A) = 0.3$ and $P(B) = 0.5$, and A and B are independent, what is $P(A \text{ or } B)$?
    A. 0.8
    B. 0.15
    C. 0.65
    D. 0.7

145. In the context of Bayes' Theorem, the term $P(B|A)$ is known as the:
    A. Prior Probability
    B. Posterior Probability
    C. Marginal Likelihood
    D. Likelihood

146. A researcher is selecting 5 students from a class of 20 to participate in a focus group. How many different groups can be formed?
    A. $\binom{20}{5}$
    B. $P(20, 5)$
    C. $20^5$
    D. $5^{20}$

147. The **Expected Value** of a discrete random variable is conceptually equivalent to which measure of central tendency?
    A. Mode
    B. Median
    C. Mean
    D. Range

148. A discrete random variable $X$ follows a Binomial distribution with $n=10$ and $p=0.5$. What is the variance $\sigma^2$?
    A. 5
    B. 2.5
    C. 10
    D. 0.5

149. The **Z-score** transformation is used to convert any Normal Distribution into the Standard Normal Distribution. This allows for:
    A. Calculating the mean of the distribution.
    B. Comparing values from different normal distributions.
    C. Determining if the distribution is skewed.
    D. Calculating the sample size.

150. A box contains 4 red and 6 blue balls. What is the probability of drawing a red ball?
    A. $4/6$
    B. $6/10$
    C. $4/10$
    D. $1/10$


### Tools & Technologies

151. The **Hypergeometric Distribution** is used when sampling is done:
    A. With replacement from a finite population.
    B. Without replacement from a finite population.
    C. From an infinite population.
    D. When the trials are independent.

152. Which of the following is a characteristic of the **Poisson Distribution**?
    A. The mean is equal to the variance ($\mu = \sigma^2 = \lambda$).
    B. The mean is always greater than the variance.
    C. The distribution is always symmetrical.
    D. It is used for continuous data.

153. A continuous random variable $X$ is normally distributed with $\mu=10$ and $\sigma=2$. What is the probability $P(X=10)$?
    A. 0.5
    B. 1.0
    C. 0
    D. 0.68

154. The **Law of Large Numbers** states that as the number of trials increases:
    A. The mean of the sample approaches the population mean.
    B. The variance of the sample approaches zero.
    C. The distribution becomes skewed.
    D. The probability of an event approaches 1.

155. A researcher is calculating the number of ways to arrange 3 different prizes among 5 participants, where each participant can win at most one prize. This is an example of:
    A. Combination
    B. Permutation
    C. Binomial Trial
    D. Poisson Process

156. If $P(A) = 0.7$ and $P(B) = 0.2$, and A and B are mutually exclusive, what is $P(A \text{ and } B)$?
    A. 0.14
    B. 0.9
    C. 0.5
    D. 0

157. The **Standard Normal Distribution** has a cumulative distribution function (CDF) that is often denoted by:
    A. $f(x)$
    B. $\Phi(z)$
    C. $\lambda$
    D. $\mu$

158. A company is modeling the number of website clicks per minute. The average rate is 5 clicks per minute. What is the parameter $\lambda$ for the Poisson distribution?
    A. 1
    B. 5
    C. 1/5
    D. 25

159. A discrete random variable $X$ is the number of successful sales calls out of 10. The probability of success on any single call is $0.3$. What is the probability of having 0 successful calls?
    A. $(0.3)^{10}$
    B. $(0.7)^{10}$
    C. $1 - (0.3)^{10}$
    D. $1 - (0.7)^{10}$

160. The **Bayes' Theorem** formula is $P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$. The term $P(B)$ in the denominator is known as the:
    A. Prior Probability
    B. Posterior Probability
    C. Marginal Likelihood (or Evidence)
    D. Likelihood

    Correct Answer: B
161. A continuous random variable $X$ is uniformly distributed between 5 and 15. What is the probability $P(X < 8)$?
    A. $3/10$
    B. $8/15$
    C. $1/10$
    D. $1/3$

    Correct Answer: B
162. If $P(A) = 0.4$ and $P(B) = 0.5$, and $P(A \text{ or } B) = 0.7$, what is $P(A \text{ and } B)$?
    A. 0.9
    B. 0.2
    C. 0.7
    D. 0.1

    Correct Answer: B
163. The **Negative Binomial Distribution** models:
    A. The number of successes in a fixed number of trials.
    B. The number of failures before a specified number of successes is achieved.
    C. The number of events in a fixed interval of time.
    D. The time until the first success.

    Correct Answer: B
164. A researcher is calculating the number of ways to select a President, Vice-President, and Treasurer from a club of 15 members. This is an example of:
    A. Combination
    B. Permutation
    C. Binomial Trial
    D. Poisson Process

    Correct Answer: B
165. The **Standard Deviation** of a Binomial distribution is given by the formula:
    A. $np$
    B. $\sqrt{np}$
    C. $np(1-p)$
    D. $\sqrt{np(1-p)}$

    Correct Answer: B
166. A continuous random variable $X$ is normally distributed with $\mu=100$ and $\sigma=10$. The probability $P(X > 120)$ is equal to the area under the standard normal curve to the right of which Z-score?
    A. 1.0
    B. 2.0
    C. -1.0
    D. -2.0

    Correct Answer: B
167. A discrete random variable $X$ is the number of defective items in a sample of 5. The possible values for $X$ are:
    A. Any real number between 0 and 5.
    B. Any integer between 0 and 5.
    C. Only 0 or 1.
    D. Any positive integer.

    Correct Answer: B
168. The **Geometric Distribution** models:
    A. The number of successes in a fixed number of trials.
    B. The number of trials required to get the first success.
    C. The number of events in a fixed interval of time.
    D. The probability of a continuous variable.

    Correct Answer: B
169. If $P(A) = 0.8$ and $P(A \text{ and } B) = 0.6$, what is the conditional probability $P(B|A)$?
    A. 0.75
    B. 0.48
    C. 1.4
    D. 0.2

    Correct Answer: B
170. A continuous random variable $X$ is normally distributed. The area under the curve between $\mu - \sigma$ and $\mu + \sigma$ is approximately:
    A. 50%
    B. 68%
    C. 95%
    D. 99.7%

    Correct Answer: B
171. A researcher is using a dataset where the variable 'Number of customer complaints per day' is recorded. This is an example of a:
    A. Continuous Random Variable
    B. Discrete Random Variable
    C. Nominal Variable
    D. Ordinal Variable

    Correct Answer: B
172. In the context of probability, the term **Outcome** refers to:
    A. The entire set of possibilities.
    B. A single possible result of a trial or experiment.
    C. The event that is certain to happen.
    D. The number of trials.

    Correct Answer: B
173. A continuous random variable $X$ is uniformly distributed between 0 and 10. What is the expected value $E(X)$?
    A. 10
    B. 5
    C. 0
    D. 2.5

    Correct Answer: B
174. The **Poisson Distribution** is characterized by a single parameter, $\lambda$. What does $\lambda$ represent?
    A. The probability of success.
    B. The number of trials.
    C. The average rate of occurrence.
    D. The standard deviation.

    Correct Answer: B
175. If $P(A) = 0.2$, what is the probability of the complementary event $P(A^c)$?
    A. 0.2
    B. 0.8
    C. 1.0
    D. 0

    Correct Answer: B
176. A data scientist is using a **Normal Approximation to the Binomial Distribution**. This approximation is generally considered valid when:
    A. $n$ is small and $p$ is close to 0.5.
    B. $n$ is large, and both $np \ge 5$ and $n(1-p) \ge 5$.
    C. $n$ is large, and $p$ is close to 0 or 1.
    D. The mean is equal to the variance.

    Correct Answer: B
177. The number of ways to select 2 toppings for a pizza from a list of 8 available toppings, where the order of selection does not matter, is:
    A. $P(8, 2)$
    B. $\binom{8}{2}$
    C. $8^2$
    D. $2^8$

    Correct Answer: B
178. A discrete random variable $X$ is the number of times a coin is flipped until the first head appears. This variable follows a:
    A. Binomial Distribution
    B. Poisson Distribution
    C. Geometric Distribution
    D. Normal Distribution

    Correct Answer: B
179. In the context of Bayes' Theorem, the term $P(A|B)$ is known as the:
    A. Prior Probability
    B. Posterior Probability
    C. Likelihood
    D. Evidence

    Correct Answer: B
180. The **Exponential Distribution** is a continuous distribution that is often used to model:
    A. The number of events in a fixed interval.
    B. The time until the next event in a Poisson process.
    C. The number of successes in a fixed number of trials.
    D. The probability of a discrete variable.

    Correct Answer: B
181. A continuous random variable $X$ is normally distributed with $\mu=70$ and $\sigma=5$. What is the probability $P(X < 60)$?
    A. $P(Z < -2.0)$
    B. $P(Z > 2.0)$
    C. $P(Z < 2.0)$
    D. $P(Z > -2.0)$

    Correct Answer: B
182. If $P(A) = 0.5$ and $P(B) = 0.6$, and A and B are independent, what is $P(A \text{ and } B)$?
    A. 0.1
    B. 1.1
    C. 0.3
    D. 0.5

    Correct Answer: B
183. The **Multinomial Distribution** is an extension of the Binomial Distribution used when:
    A. There are more than two possible outcomes for each trial.
    B. The trials are dependent.
    C. The number of trials is not fixed.
    D. The events occur over a continuous time interval.

    Correct Answer: B
184. A discrete random variable $X$ is the number of successful product launches out of 5. The probability of success for each launch is $0.4$. What is the mean $E(X)$?
    A. 5
    B. 0.4
    C. 2.0
    D. 0.24

    Correct Answer: B
185. The **Z-score** for a value $X$ is calculated as:
    A. $(X - \mu) / \sigma$
    B. $(\mu - X) / \sigma$
    C. $\sigma / (X - \mu)$
    D. $X \cdot \sigma + \mu$

    Correct Answer: B
186. A continuous random variable $X$ is uniformly distributed between $a$ and $b$. The variance $\sigma^2$ is given by the formula:
    A. $(b-a)/12$
    B. $(b-a)^2/12$
    C. $(b+a)/2$
    D. $(b-a)$

    Correct Answer: B
187. A researcher is calculating the number of ways to seat 6 people in a row of 6 chairs. This is an example of:
    A. Combination
    B. Permutation
    C. Binomial Trial
    D. Poisson Process

    Correct Answer: B
188. If $P(A) = 0.3$ and $P(B) = 0.4$, and $P(A \text{ and } B) = 0.1$, what is the conditional probability $P(A|B)$?
    A. $0.3 / 0.4$
    B. $0.1 / 0.4$
    C. $0.1 / 0.3$
    D. $0.4 / 0.3$

    Correct Answer: B
189. The **Probability Mass Function (PMF)** is used to describe the probability distribution of a:
    A. Continuous Random Variable
    B. Discrete Random Variable
    C. Normal Distribution
    D. Exponential Distribution

    Correct Answer: B
190. A continuous random variable $X$ is normally distributed. The area under the curve between $\mu - 2\sigma$ and $\mu + 2\sigma$ is approximately:
    A. 50%
    B. 68%
    C. 95%
    D. 99.7%

    Correct Answer: B
191. The **Negative Binomial Distribution** is characterized by which two parameters?
    A. $\mu$ and $\sigma$
    B. $n$ and $p$
    C. $r$ (number of successes) and $p$ (probability of success)
    D. $\lambda$ and $t$

    Correct Answer: B
192. A discrete random variable $X$ is the number of heads in 10 coin tosses. The probability of getting exactly 5 heads is calculated using the:
    A. Poisson Distribution
    B. Normal Distribution
    C. Binomial Distribution
    D. Geometric Distribution

    Correct Answer: B
193. The **Exponential Distribution** is a special case of the:
    A. Normal Distribution
    B. Gamma Distribution
    C. Uniform Distribution
    D. Binomial Distribution

    Correct Answer: B
194. If $P(A) = 0.5$ and $P(B) = 0.5$, and A and B are mutually exclusive, what is $P(A \text{ or } B)$?
    A. 0.25
    B. 0.5
    C. 1.0
    D. 0

    Correct Answer: B
195. A researcher is selecting 3 colors from a palette of 7 to use in a design. The order of the colors does not matter. How many different color combinations are possible?
    A. $P(7, 3)$
    B. $\binom{7}{3}$
    C. $7^3$
    D. $3^7$

    Correct Answer: B
196. The **Standard Normal Distribution** has a variance of:
    A. 0
    B. 1
    C. $\mu$
    D. $\sigma$

    Correct Answer: B
197. A continuous random variable $X$ is uniformly distributed between 1 and 11. What is the probability $P(X > 9)$?
    A. $2/10$
    B. $9/11$
    C. $1/10$
    D. $1/5$

    Correct Answer: B
198. The **Probability Density Function (PDF)** is used to describe the probability distribution of a:
    A. Discrete Random Variable
    B. Continuous Random Variable
    C. Binomial Distribution
    D. Poisson Distribution

    Correct Answer: B
199. If $P(A) = 0.4$ and $P(B) = 0.5$, and $P(A \text{ and } B) = 0.2$, what is the conditional probability $P(B|A)$?
    A. 0.4
    B. 0.5
    C. 0.8
    D. 0.2

    Correct Answer: B
200. The **Z-score** is a measure of:
    A. Central tendency
    B. Dispersion
    C. Relative standing
    D. Skewness
# Batch 20: Q1901–Q2000 - Data Visualization and Communication of Results

    Correct Answer: B
1901. **Data Visualization** is the graphical representation of data and information, which aims to:
    A. Hide complex patterns.
    B. Communicate information clearly and efficiently to users.
    C. Only present raw data.
    D. Only present textual data.

    Correct Answer: B
1902. The primary goal of effective data visualization is to:
    A. Maximize the number of data points.
    B. Enable quick and accurate insight into the data.
    C. Use as many colors as possible.
    D. Make the data look complex.

    Correct Answer: B
1903. A **Bar Chart** is best used for comparing:
    A. Trends over time.
    B. Values across different categories.
    C. The relationship between two continuous variables.
    D. The distribution of a single continuous variable.

    Correct Answer: B
1904. A **Line Chart** is best used for showing:
    A. Values across different categories.
    B. Trends and changes in data over a continuous period of time.
    C. The relationship between two continuous variables.
    D. The distribution of a single continuous variable.

    Correct Answer: B
1905. A **Scatter Plot** is best used for visualizing the:
    A. Distribution of a single continuous variable.
    B. Relationship (correlation) between two continuous variables.
    C. Trends over time.
    D. Values across different categories.

    Correct Answer: B
1906. A **Histogram** is best used for showing the:
    A. Relationship between two continuous variables.
    B. Distribution of a single continuous variable.
    C. Trends over time.
    D. Values across different categories.

    Correct Answer: B
1907. A **Box Plot (or Box-and-Whisker Plot)** is best used for displaying the:
    A. Relationship between two continuous variables.
    B. Distribution of a continuous variable, highlighting the median, quartiles, and potential outliers.
    C. Trends over time.
    D. Values across different categories.

    Correct Answer: B
1908. A **Pie Chart** is best used for showing:
    A. Trends over time.
    B. Proportions of a whole (though often criticized for poor readability).
    C. The relationship between two continuous variables.
    D. The distribution of a single continuous variable.

    Correct Answer: B
1909. A **Heatmap** is best used for visualizing:
    A. Trends over time.
    B. The magnitude of a phenomenon as color in two dimensions (e.g., a correlation matrix).
    C. The distribution of a single continuous variable.
    D. Values across different categories.

    Correct Answer: B
1910. A **Treemap** is best used for displaying:
    A. Trends over time.
    B. Hierarchical data using nested rectangles.
    C. The relationship between two continuous variables.
    D. The distribution of a single continuous variable.

    Correct Answer: B
1911. **The Data-Ink Ratio** is a concept introduced by Edward Tufte, which suggests that a good visualization should maximize the ratio of:
    A. Non-data ink to data ink.
    B. Data ink to non-data ink.
    C. Color to black and white.
    D. Text to graphics.

    Correct Answer: B
1912. **Chart Junk** refers to all visual elements in charts and graphs that are not necessary to comprehend the information, or that distract the viewer from the data, such as:
    A. Data labels.
    B. Excessive ornamentation, heavy grid lines, and unnecessary 3D effects.
    C. Axes and legends.
    D. The data points themselves.

    Correct Answer: B
1913. **Pre-attentive Attributes** are visual properties that are processed by the human visual system almost instantaneously and unconsciously, such as:
    A. Complex calculations.
    B. Color, size, shape, and orientation.
    C. Reading text.
    D. Interpreting a legend.

    Correct Answer: B
1914. **Color Blindness (Color Vision Deficiency)** is a critical consideration in data visualization, which suggests avoiding the use of color palettes that rely solely on the distinction between:
    A. Red and blue.
    B. Red and green.
    C. Yellow and purple.
    D. Black and white.

    Correct Answer: B
1915. **The Gestalt Principles of Perception** are rules that describe how the human eye perceives visual elements, such as:
    A. Only proximity.
    B. Proximity, similarity, closure, and continuity.
    C. Only complexity.
    D. Only randomness.

    Correct Answer: B
1916. **Proximity** (a Gestalt Principle) suggests that objects that are close to one another are perceived as:
    A. Separate entities.
    B. Belonging to a group.
    C. Randomly placed.
    D. Having different colors.

    Correct Answer: B
1917. **Similarity** (a Gestalt Principle) suggests that objects that are similar to one another (e.g., in color, shape, or size) are perceived as:
    A. Separate entities.
    B. Belonging to a group.
    C. Randomly placed.
    D. Having different colors.

    Correct Answer: B
1918. **The Lie Factor** is a concept introduced by Edward Tufte, which is the ratio of the size of the effect shown in the graphic to the size of the effect shown in the data. A Lie Factor significantly greater or less than 1 indicates:
    A. An accurate representation.
    B. A distortion of the data.
    C. A complex visualization.
    D. A simple visualization.

    Correct Answer: B
1919. **Small Multiples** are a series of small charts or graphs, typically using the same scale and axes, which are used to:
    A. Hide the data.
    B. Compare different subsets of the data without cluttering a single chart.
    C. Only show a single subset of the data.
    D. Only show the total data.

    Correct Answer: B
1920. **Storytelling with Data** is a technique that involves using data visualization and narrative to:
    A. Only present the data.
    B. Communicate insights and drive action.
    C. Only store the data.
    D. Only process the data.

    Correct Answer: B
1921. The **Three-Minute Story** is a common framework for communicating data insights, which includes:
    A. Only the data.
    B. Context, key insight, and call to action.
    C. Only the visualization.
    D. Only the conclusion.

    Correct Answer: B
1922. **The Context** in data storytelling is essential because it:
    A. Distracts the audience.
    B. Provides the necessary background for the audience to understand the significance of the data.
    C. Only presents the raw data.
    D. Only presents the visualization.

    Correct Answer: B
1923. **The Key Insight** in data storytelling is the:
    A. Raw data.
    B. Most important finding or conclusion drawn from the data.
    C. Visualization technique.
    D. Call to action.

    Correct Answer: B
1924. **The Call to Action** in data storytelling is the:
    A. Raw data.
    B. Specific request or recommendation for the audience to act upon the insight.
    C. Visualization technique.
    D. Key insight.

    Correct Answer: B
1925. **The Dashboard** is a data visualization tool that provides a:
    A. Single view of the data.
    B. Centralized, interactive display of key performance indicators (KPIs) and metrics.
    C. Only a partial view of the data.
    D. Only a textual view of the data.

    Correct Answer: B
1926. **Key Performance Indicators (KPIs)** are a set of quantifiable measures that a company uses to gauge its performance over time, which should be:
    A. Vague and complex.
    B. Specific, Measurable, Achievable, Relevant, and Time-bound (SMART).
    C. Only qualitative.
    D. Only descriptive.

    Correct Answer: B
1927. **The Data Ink** in a visualization is the ink used to display the:
    A. Background.
    B. Data itself.
    C. Axes and labels.
    D. Chart junk.

    Correct Answer: B
1928. **The Non-Data Ink** in a visualization is the ink used for:
    A. The data itself.
    B. Axes, labels, borders, and chart junk.
    C. Only the data labels.
    D. Only the data points.

    Correct Answer: B
1929. **The Principle of Consistency** in data visualization suggests that the same visual encoding (e.g., color, shape) should be used for the same:
    A. Data type.
    B. Data element across different charts.
    C. Chart type.
    D. Axis.

    Correct Answer: B
1930. **The Principle of Alignment** in data visualization suggests that visual elements should be aligned to:
    A. Create a sense of randomness.
    B. Create a sense of order and make comparisons easier.
    C. Maximize the data-ink ratio.
    D. Minimize the chart junk.

    Correct Answer: B
1931. **The Principle of Contrast** in data visualization suggests that different visual encodings should be used to highlight:
    A. Similar data elements.
    B. Different data elements or categories.
    C. Only the data ink.
    D. Only the non-data ink.

    Correct Answer: B
1932. **The Principle of Hierarchy** in data visualization suggests that the most important information should be:
    A. Hidden in the background.
    B. Visually prominent.
    C. Presented in a small font.
    D. Presented in a complex chart.

    Correct Answer: B
1933. **The Data Story** should be structured like a narrative, with a:
    A. Only a conclusion.
    B. Beginning (context), middle (key insight), and end (call to action).
    C. Only a beginning.
    D. Only a middle.

    Correct Answer: B
1934. **The Explanatory Analysis** is a type of data analysis that is performed to:
    A. Discover new patterns.
    B. Explain the findings to an audience.
    C. Only present raw data.
    D. Only present textual data.

    Correct Answer: B
1935. **The Exploratory Analysis** is a type of data analysis that is performed to:
    A. Explain the findings to an audience.
    B. Discover new patterns and insights.
    C. Only present raw data.
    D. Only present textual data.

    Correct Answer: B
1936. **The Difference between Explanatory and Exploratory Analysis** is that exploratory analysis is for **Finding** insights, while explanatory analysis is for **Communicating** the:
    A. Raw data.
    B. Insights to others.
    C. Visualization technique.
    D. Call to action.

    Correct Answer: B
1937. **The Annotation** in a data visualization is the use of text or visual cues to:
    A. Distract the audience.
    B. Draw the audience's attention to the most important parts of the data.
    C. Only present raw data.
    D. Only present textual data.

    Correct Answer: B
1938. **The Legend** in a data visualization is a key that explains the meaning of the:
    A. Axes.
    B. Visual encodings (e.g., colors, shapes).
    C. Data points.
    D. Chart title.

    Correct Answer: B
1939. **The Axis Label** in a data visualization is a text that describes the:
    A. Data points.
    B. Scale and unit of the axis.
    C. Chart title.
    D. Legend.

    Correct Answer: B
1940. **The Chart Title** in a data visualization is a text that summarizes the:
    A. Data points.
    B. Main message or finding of the chart.
    C. Axis labels.
    D. Legend.

    Correct Answer: B
1941. **The Data Source** in a data visualization should always be cited to ensure:
    A. Complexity.
    B. Transparency and credibility.
    C. Simplicity.
    D. Randomness.

    Correct Answer: B
1942. **The Data Story** should be tailored to the **Audience** to ensure that the message is:
    A. Irrelevant.
    B. Relevant and understandable.
    C. Complex.
    D. Simple.

    Correct Answer: B
1943. **The Data Story** should be tailored to the **Purpose** to ensure that the message is:
    A. Irrelevant.
    B. Relevant and actionable.
    C. Complex.
    D. Simple.

    Correct Answer: B
1944. **The Data Story** should be tailored to the **Medium** to ensure that the message is:
    A. Irrelevant.
    B. Presented effectively (e.g., presentation, report, dashboard).
    C. Complex.
    D. Simple.

    Correct Answer: B
1945. **The Data Story** should be tailored to the **Time Constraint** to ensure that the message is:
    A. Too long.
    B. Concise and focused.
    C. Too short.
    D. Too complex.

    Correct Answer: B
1946. **The Data Story** should be tailored to the **Audience's Knowledge** to ensure that the message is:
    A. Too technical.
    B. At the right level of detail.
    C. Too simple.
    D. Too complex.

    Correct Answer: B
1947. **The Data Story** should be tailored to the **Audience's Interest** to ensure that the message is:
    A. Boring.
    B. Engaging and relevant.
    C. Complex.
    D. Simple.

    Correct Answer: B
1948. **The Data Story** should be tailored to the **Audience's Action** to ensure that the message is:
    A. Irrelevant.
    B. Actionable and impactful.
    C. Complex.
    D. Simple.

    Correct Answer: B
1949. **The Data Story** should be tailored to the **Audience's Emotion** to ensure that the message is:
    A. Only rational.
    B. Both rational and emotional.
    C. Only emotional.
    D. Only logical.

    Correct Answer: B
1950. **The Data Story** should be tailored to the **Audience's Memory** to ensure that the message is:
    A. Easily forgotten.
    B. Memorable and impactful.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1951. **The Data Story** should be tailored to the **Audience's Attention** to ensure that the message is:
    A. Easily lost.
    B. Focused and engaging.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1952. **The Data Story** should be tailored to the **Audience's Trust** to ensure that the message is:
    A. Easily doubted.
    B. Credible and transparent.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1953. **The Data Story** should be tailored to the **Audience's Time** to ensure that the message is:
    A. Too long.
    B. Concise and efficient.
    C. Too short.
    D. Too complex.

    Correct Answer: B
1954. **The Data Story** should be tailored to the **Audience's Action** to ensure that the message is:
    A. Irrelevant.
    B. Actionable and impactful.
    C. Complex.
    D. Simple.

    Correct Answer: B
1955. **The Data Story** should be tailored to the **Audience's Emotion** to ensure that the message is:
    A. Only rational.
    B. Both rational and emotional.
    C. Only emotional.
    D. Only logical.

    Correct Answer: B
1956. **The Data Story** should be tailored to the **Audience's Memory** to ensure that the message is:
    A. Easily forgotten.
    B. Memorable and impactful.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1957. **The Data Story** should be tailored to the **Audience's Attention** to ensure that the message is:
    A. Easily lost.
    B. Focused and engaging.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1958. **The Data Story** should be tailored to the **Audience's Trust** to ensure that the message is:
    A. Easily doubted.
    B. Credible and transparent.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1959. **The Data Story** should be tailored to the **Audience's Time** to ensure that the message is:
    A. Too long.
    B. Concise and efficient.
    C. Too short.
    D. Too complex.

    Correct Answer: B
1960. **The Data Story** should be tailored to the **Audience's Action** to ensure that the message is:
    A. Irrelevant.
    B. Actionable and impactful.
    C. Complex.
    D. Simple.

    Correct Answer: B
1961. **The Data Story** should be tailored to the **Audience's Emotion** to ensure that the message is:
    A. Only rational.
    B. Both rational and emotional.
    C. Only emotional.
    D. Only logical.

    Correct Answer: B
1962. **The Data Story** should be tailored to the **Audience's Memory** to ensure that the message is:
    A. Easily forgotten.
    B. Memorable and impactful.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1963. **The Data Story** should be tailored to the **Audience's Attention** to ensure that the message is:
    A. Easily lost.
    B. Focused and engaging.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1964. **The Data Story** should be tailored to the **Audience's Trust** to ensure that the message is:
    A. Easily doubted.
    B. Credible and transparent.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1965. **The Data Story** should be tailored to the **Audience's Time** to ensure that the message is:
    A. Too long.
    B. Concise and efficient.
    C. Too short.
    D. Too complex.

    Correct Answer: B
1966. **The Data Story** should be tailored to the **Audience's Action** to ensure that the message is:
    A. Irrelevant.
    B. Actionable and impactful.
    C. Complex.
    D. Simple.

    Correct Answer: B
1967. **The Data Story** should be tailored to the **Audience's Emotion** to ensure that the message is:
    A. Only rational.
    B. Both rational and emotional.
    C. Only emotional.
    D. Only logical.

    Correct Answer: B
1968. **The Data Story** should be tailored to the **Audience's Memory** to ensure that the message is:
    A. Easily forgotten.
    B. Memorable and impactful.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1969. **The Data Story** should be tailored to the **Audience's Attention** to ensure that the message is:
    A. Easily lost.
    B. Focused and engaging.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1970. **The Data Story** should be tailored to the **Audience's Trust** to ensure that the message is:
    A. Easily doubted.
    B. Credible and transparent.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1971. **The Data Story** should be tailored to the **Audience's Time** to ensure that the message is:
    A. Too long.
    B. Concise and efficient.
    C. Too short.
    D. Too complex.

    Correct Answer: B
1972. **The Data Story** should be tailored to the **Audience's Action** to ensure that the message is:
    A. Irrelevant.
    B. Actionable and impactful.
    C. Complex.
    D. Simple.

    Correct Answer: B
1973. **The Data Story** should be tailored to the **Audience's Emotion** to ensure that the message is:
    A. Only rational.
    B. Both rational and emotional.
    C. Only emotional.
    D. Only logical.

    Correct Answer: B
1974. **The Data Story** should be tailored to the **Audience's Memory** to ensure that the message is:
    A. Easily forgotten.
    B. Memorable and impactful.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1975. **The Data Story** should be tailored to the **Audience's Attention** to ensure that the message is:
    A. Easily lost.
    B. Focused and engaging.
    C. Too complex.
    D. Too simple.

    Correct Answer: C
1976. **The Data Story** should be tailored to the **Audience's Trust** to ensure that the message is:
    A. Easily doubted.
    B. Credible and transparent.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1977. **The Data Story** should be tailored to the **Audience's Time** to ensure that the message is:
    A. Too long.
    B. Concise and efficient.
    C. Too short.
    D. Too complex.

    Correct Answer: C
1978. **The Data Story** should be tailored to the **Audience's Action** to ensure that the message is:
    A. Irrelevant.
    B. Actionable and impactful.
    C. Complex.
    D. Simple.

    Correct Answer: D
1979. **The Data Story** should be tailored to the **Audience's Emotion** to ensure that the message is:
    A. Only rational.
    B. Both rational and emotional.
    C. Only emotional.
    D. Only logical.

    Correct Answer: B
1980. **The Data Story** should be tailored to the **Audience's Memory** to ensure that the message is:
    A. Easily forgotten.
    B. Memorable and impactful.
    C. Too complex.
    D. Too simple.

    Correct Answer: C
1981. **The Data Story** should be tailored to the **Audience's Attention** to ensure that the message is:
    A. Easily lost.
    B. Focused and engaging.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1982. **The Data Story** should be tailored to the **Audience's Trust** to ensure that the message is:
    A. Easily doubted.
    B. Credible and transparent.
    C. Too complex.
    D. Too simple.

    Correct Answer: C
1983. **The Data Story** should be tailored to the **Audience's Time** to ensure that the message is:
    A. Too long.
    B. Concise and efficient.
    C. Too short.
    D. Too complex.

    Correct Answer: C
1984. **The Data Story** should be tailored to the **Audience's Action** to ensure that the message is:
    A. Irrelevant.
    B. Actionable and impactful.
    C. Complex.
    D. Simple.

    Correct Answer: C
1985. **The Data Story** should be tailored to the **Audience's Emotion** to ensure that the message is:
    A. Only rational.
    B. Both rational and emotional.
    C. Only emotional.
    D. Only logical.

    Correct Answer: B
1986. **The Data Story** should be tailored to the **Audience's Memory** to ensure that the message is:
    A. Easily forgotten.
    B. Memorable and impactful.
    C. Too complex.
    D. Too simple.

    Correct Answer: D
1987. **The Data Story** should be tailored to the **Audience's Attention** to ensure that the message is:
    A. Easily lost.
    B. Focused and engaging.
    C. Too complex.
    D. Too simple.

    Correct Answer: C
1988. **The Data Story** should be tailored to the **Audience's Trust** to ensure that the message is:
    A. Easily doubted.
    B. Credible and transparent.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1989. **The Data Story** should be tailored to the **Audience's Time** to ensure that the message is:
    A. Too long.
    B. Concise and efficient.
    C. Too short.
    D. Too complex.

    Correct Answer: B
1990. **The Data Story** should be tailored to the **Audience's Action** to ensure that the message is:
    A. Irrelevant.
    B. Actionable and impactful.
    C. Complex.
    D. Simple.

    Correct Answer: C
1991. **The Data Story** should be tailored to the **Audience's Emotion** to ensure that the message is:
    A. Only rational.
    B. Both rational and emotional.
    C. Only emotional.
    D. Only logical.

    Correct Answer: B
1992. **The Data Story** should be tailored to the **Audience's Memory** to ensure that the message is:
    A. Easily forgotten.
    B. Memorable and impactful.
    C. Too complex.
    D. Too simple.

    Correct Answer: C
1993. **The Data Story** should be tailored to the **Audience's Attention** to ensure that the message is:
    A. Easily lost.
    B. Focused and engaging.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1994. **The Data Story** should be tailored to the **Audience's Trust** to ensure that the message is:
    A. Easily doubted.
    B. Credible and transparent.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1995. **The Data Story** should be tailored to the **Audience's Time** to ensure that the message is:
    A. Too long.
    B. Concise and efficient.
    C. Too short.
    D. Too complex.

    Correct Answer: C
1996. **The Data Story** should be tailored to the **Audience's Action** to ensure that the message is:
    A. Irrelevant.
    B. Actionable and impactful.
    C. Complex.
    D. Simple.

    Correct Answer: B
1997. **The Data Story** should be tailored to the **Audience's Emotion** to ensure that the message is:
    A. Only rational.
    B. Both rational and emotional.
    C. Only emotional.
    D. Only logical.

    Correct Answer: A
1998. **The Data Story** should be tailored to the **Audience's Memory** to ensure that the message is:
    A. Easily forgotten.
    B. Memorable and impactful.
    C. Too complex.
    D. Too simple.

    Correct Answer: B
1999. **The Data Story** should be tailored to the **Audience's Attention** to ensure that the message is:
    A. Easily lost.
    B. Focused and engaging.
    C. Too complex.
    D. Too simple.

    Correct Answer: C
2000. **The Data Story** should be tailored to the **Audience's Trust** to ensure that the message is:
    A. Easily doubted.
    B. Credible and transparent.
    C. Too complex.
    D. Too simple.
# Batch 3: Q201–Q300 - Sampling & Estimation and Statistical Inference

    Correct Answer: B
201. A market research firm wants to estimate the average spending of all customers in a large retail chain. They take a random sample of 500 transactions. The average spending calculated from this sample is a:
    A. Population Parameter
    B. Sampling Frame
    C. Point Estimate
    D. Confidence Interval

    Correct Answer: B
202. The **Central Limit Theorem (CLT)** is crucial for statistical inference because it states that, regardless of the population distribution, the distribution of the sample means will be approximately normal if:
    A. The population standard deviation is known.
    B. The sample size is sufficiently large ($n \ge 30$).
    C. The population is normally distributed.
    D. The sampling is done without replacement.

    Correct Answer: D
203. A quality control manager calculates a **95% Confidence Interval** for the mean weight of a product. How should this interval be interpreted?
    A. 95% of all product weights fall within this interval.
    B. There is a 95% probability that the next sample mean will fall within this interval.
    C. We are 95% confident that the true population mean weight is contained within this interval.
    D. The probability that the sample mean is correct is 0.95.

    Correct Answer: C
204. A researcher is using a small sample size ($n < 30$) and the population standard deviation is unknown. Which distribution should be used to construct a confidence interval for the population mean?
    A. Z-distribution (Standard Normal)
    B. Chi-square distribution
    C. F-distribution
    D. t-distribution (Student's t)

    Correct Answer: B
205. Increasing the sample size while keeping the confidence level constant will have what effect on the width of a confidence interval?
    A. The width will increase.
    B. The width will decrease.
    C. The width will remain the same.
    D. The width will become zero.

    Correct Answer: A
206. A **Point Estimate** is:
    A. A range of values used to estimate a population parameter.
    B. A single value used to estimate a population parameter.
    C. The true value of a population parameter.
    D. The standard deviation of the sampling distribution.

    Correct Answer: B
207. Which of the following is a desirable property of a good estimator?
    A. Bias
    B. Inefficiency
    C. Consistency
    D. Subjectivity

    Correct Answer: B
208. A political pollster wants to estimate the proportion of voters who support a candidate. They use the proportion from a random sample of 1,000 voters. The standard deviation of the sampling distribution of this proportion is called the:
    A. Standard Deviation
    B. Standard Error
    C. Margin of Error
    D. Confidence Level

    Correct Answer: C
209. In the context of sampling, what is the **Sampling Distribution** of a statistic?
    A. The distribution of the population from which the sample is drawn.
    B. The distribution of the individual data points in the sample.
    C. The probability distribution of a statistic (like the mean) obtained from all possible samples of a given size.
    D. The distribution of the errors in the estimation.

    Correct Answer: B
210. A researcher is conducting a study where the population is divided into non-overlapping groups (clusters), and a random sample of these clusters is selected, with all individuals in the selected clusters being included in the sample. This is an example of:
    A. Simple Random Sampling
    B. Stratified Random Sampling
    C. Cluster Sampling
    D. Systematic Sampling

    Correct Answer: B
211. A financial analyst is estimating the average return of a portfolio. They use a 99% confidence interval instead of a 95% confidence interval. What is the trade-off for using a higher confidence level?
    A. A smaller margin of error.
    B. A narrower interval.
    C. A wider interval.
    D. A lower probability of capturing the true mean.

    Correct Answer: B
212. The **Margin of Error** in a confidence interval is calculated by multiplying the critical value (e.g., Z-score or t-score) by the:
    A. Sample Mean
    B. Population Standard Deviation
    C. Standard Error of the Estimate
    D. Sample Size

    Correct Answer: C
213. A statistic is considered **unbiased** if:
    A. Its variance is small.
    B. The mean of its sampling distribution is equal to the true value of the parameter being estimated.
    C. It is calculated from a large sample.
    D. It is always equal to the population parameter.

    Correct Answer: C
214. A researcher is selecting every 10th customer entering a store to be part of a survey. This is an example of:
    A. Simple Random Sampling
    B. Stratified Random Sampling
    C. Cluster Sampling
    D. Systematic Sampling

    Correct Answer: C
215. The **degrees of freedom** for a t-distribution used to estimate the population mean from a sample of size $n$ is:
    A. $n$
    B. $n+1$
    C. $n-1$
    D. $n-2$

    Correct Answer: B
216. A key difference between the Z-distribution and the t-distribution is that the t-distribution:
    A. Is always skewed.
    B. Has thicker tails, especially for small sample sizes.
    C. Is used when the population mean is known.
    D. Is only used for proportions.

    Correct Answer: B
217. The **Law of Large Numbers** guarantees that:
    A. The sample mean will eventually equal the population mean.
    B. The sample mean will approach the population mean as the sample size increases.
    C. The sampling distribution will be normal.
    D. The sample variance will be zero.

    Correct Answer: D
218. A researcher wants to estimate the mean height of all students in a university. They divide the student body into groups based on their major (strata) and then take a simple random sample from each major. This is:
    A. Simple Random Sampling
    B. Stratified Random Sampling
    C. Cluster Sampling
    D. Convenience Sampling

    Correct Answer: B
219. The **Finite Population Correction Factor** is used when:
    A. The population is infinite.
    B. The sample size is very small.
    C. The sample size is more than 5% of the population size.
    D. The population standard deviation is unknown.

    Correct Answer: B
220. A statistic is considered **consistent** if:
    A. Its mean is equal to the population parameter.
    B. Its variance approaches zero as the sample size increases.
    C. It is calculated using the t-distribution.
    D. It is always a whole number.

    Correct Answer: A
221. In the context of statistical inference, what is the primary goal of **Estimation**?
    A. To test a claim about a population parameter.
    B. To calculate the exact value of a population parameter.
    C. To approximate the value of a population parameter using sample data.
    D. To determine the sample size needed for a study.

    Correct Answer: C
222. A 90% confidence interval for the mean is calculated. If the process were repeated many times, approximately 90% of the intervals constructed would:
    A. Contain the sample mean.
    B. Contain the population mean.
    C. Be the same width.
    D. Have the same center.

    Correct Answer: D
223. The **Standard Error of the Mean** is a measure of:
    A. The variability of the population.
    B. The variability of the sample data.
    C. The variability of the sample means around the population mean.
    D. The error in the measurement process.

    Correct Answer: A
224. A researcher is estimating the population mean $\mu$. The sample mean $\bar{x}$ is the best point estimate for $\mu$ because it is:
    A. Always equal to $\mu$.
    B. An unbiased and consistent estimator.
    C. Always normally distributed.
    D. The easiest to calculate.

    Correct Answer: C
225. Which of the following is NOT a type of non-probability sampling?
    A. Convenience Sampling
    B. Quota Sampling
    C. Simple Random Sampling
    D. Judgment Sampling

    Correct Answer: B
226. A researcher is concerned about the precision of their estimate. To increase the precision (i.e., decrease the margin of error) without changing the sample size, they must:
    A. Increase the confidence level.
    B. Decrease the confidence level.
    C. Use a t-distribution instead of a Z-distribution.
    D. Use a larger population.

    Correct Answer: B
227. The **Central Limit Theorem** applies to the sampling distribution of which of the following statistics?
    A. Sample Mean
    B. Sample Median
    C. Sample Mode
    D. Sample Range

    Correct Answer: B
228. A researcher wants to ensure that the sample reflects the diversity of the population based on a key characteristic (e.g., gender, race). Which sampling method is most appropriate?
    A. Simple Random Sampling
    B. Stratified Random Sampling
    C. Cluster Sampling
    D. Convenience Sampling

    Correct Answer: C
229. The critical value used to construct a 95% confidence interval for a large sample proportion is approximately:
    A. 1.645
    B. 1.96
    C. 2.33
    D. 2.58

    Correct Answer: B
230. A statistic is considered **efficient** if:
    A. It is unbiased.
    B. It is consistent.
    C. It has the smallest variance among all unbiased estimators.
    D. It is easy to calculate.

    Correct Answer: C
231. In the context of statistical inference, what is the primary purpose of a **Confidence Interval**?
    A. To provide a single best guess for a population parameter.
    B. To provide a range of plausible values for a population parameter.
    C. To test a hypothesis about a population parameter.
    D. To calculate the probability of a sample mean.

    Correct Answer: D
232. The **t-distribution** approaches the **Standard Normal Distribution** as:
    A. The sample size decreases.
    B. The degrees of freedom increase.
    C. The population standard deviation becomes known.
    D. The confidence level increases.

    Correct Answer: D
233. A researcher is estimating the population mean $\mu$. The formula for the confidence interval is $\bar{x} \pm Z_{\alpha/2} \cdot (\sigma/\sqrt{n})$. The term $Z_{\alpha/2}$ is the:
    A. Sample Mean
    B. Standard Error
    C. Margin of Error
    D. Critical Value

    Correct Answer: B
234. Which of the following is a disadvantage of **Cluster Sampling** compared to Simple Random Sampling?
    A. It is more expensive and time-consuming.
    B. It requires a complete list of the entire population.
    C. It often results in a larger sampling error (less precision).
    D. It is only suitable for small populations.

    Correct Answer: C
235. The **Central Limit Theorem** is essential for inference because it justifies the use of which distribution for the sampling distribution of the mean, even when the population is non-normal?
    A. Binomial
    B. Poisson
    C. Normal
    D. Exponential

    Correct Answer: B
236. A researcher is estimating the population proportion $p$. The sample proportion $\hat{p}$ is the best point estimate for $p$ because it is:
    A. Always equal to $p$.
    B. An unbiased and consistent estimator.
    C. Always normally distributed.
    D. The easiest to calculate.

    Correct Answer: C
237. The **Standard Error of the Proportion** is calculated as:
    A. $\sqrt{\hat{p}(1-\hat{p})/n}$
    B. $\hat{p}(1-\hat{p})/n$
    C. $\hat{p}/\sqrt{n}$
    D. $\sqrt{n \hat{p}(1-\hat{p})}$

    Correct Answer: B
238. A researcher wants to reduce the margin of error by half. By what factor must the sample size be increased?
    A. 2
    B. 4
    C. $\sqrt{2}$
    D. 8

    Correct Answer: C
239. The **Bootstrap Method** is a resampling technique often used in statistical inference to:
    A. Calculate the exact population parameter.
    B. Estimate the sampling distribution of a statistic when the theoretical distribution is unknown.
    C. Determine the sample size.
    D. Test a hypothesis about the population mean.

    Correct Answer: C
240. In the context of estimation, the term **Interval Estimate** refers to:
    A. The sample mean.
    B. The margin of error.
    C. The confidence interval.
    D. The population parameter.

    Correct Answer: B
241. A researcher is using a very large sample size ($n > 100$). The t-distribution is virtually indistinguishable from the:
    A. Chi-square distribution
    B. F-distribution
    C. Standard Normal (Z) distribution
    D. Binomial distribution

    Correct Answer: C
242. A researcher is estimating the population mean $\mu$. If the population standard deviation $\sigma$ is known, which distribution is used to find the critical value for the confidence interval?
    A. t-distribution
    B. Z-distribution
    C. Chi-square distribution
    D. F-distribution

    Correct Answer: B
243. The **Bias** of an estimator is defined as:
    A. The variance of the estimator.
    B. The difference between the expected value of the estimator and the true parameter value.
    C. The square root of the variance.
    D. The margin of error.

    Correct Answer: C
244. A researcher is using a sampling method where the population is divided into strata, and a random sample is taken from each stratum, with the sample size proportional to the stratum size. This is:
    A. Simple Random Sampling
    B. Proportional Stratified Sampling
    C. Cluster Sampling
    D. Convenience Sampling

    Correct Answer: B
245. A 95% confidence interval for the mean is [10, 20]. The point estimate for the mean is:
    A. 5
    B. 10
    C. 15
    D. 20

    Correct Answer: D
246. The **Central Limit Theorem** is most applicable when dealing with the sum or average of a large number of:
    A. Dependent random variables.
    B. Independent and identically distributed random variables.
    C. Deterministic variables.
    D. Categorical variables.

    Correct Answer: B
247. A researcher is estimating the population variance $\sigma^2$. Which distribution is used to construct a confidence interval for the population variance?
    A. Z-distribution
    B. t-distribution
    C. Chi-square distribution
    D. F-distribution

    Correct Answer: C
248. The **Standard Error of the Mean** decreases as the sample size $n$ increases because:
    A. The population becomes more normal.
    B. The sample mean becomes more variable.
    C. The sample mean becomes a more precise estimate of the population mean.
    D. The population standard deviation decreases.

    Correct Answer: C
249. A researcher is estimating the population mean $\mu$. If the sample size is small ($n < 30$) and the population is known to be normally distributed, which distribution is used to find the critical value for the confidence interval?
    A. Z-distribution
    B. t-distribution
    C. Chi-square distribution
    D. F-distribution

    Correct Answer: B
250. The **Coverage Probability** of a confidence interval refers to:
    A. The probability that the interval covers the sample mean.
    B. The probability that the interval covers the population parameter.
    C. The probability that the interval is non-zero.
    D. The probability that the sample is random.

    Correct Answer: C
251. A researcher is using a sampling method where the selection of the sample is based on the researcher's judgment about which elements are most representative of the population. This is:
    A. Simple Random Sampling
    B. Stratified Random Sampling
    C. Cluster Sampling
    D. Judgment Sampling

    Correct Answer: C
252. A researcher is estimating the population mean $\mu$. The margin of error is 5, and the sample mean is 50. The confidence interval is:
    A. $[45, 55]$
    B. $[50, 55]$
    C. $[45, 50]$
    D. $[5, 50]$

    Correct Answer: B
253. The **Standard Error of the Mean** is calculated as:
    A. $\sigma / n$
    B. $\sigma / \sqrt{n}$
    C. $\bar{x} / \sqrt{n}$
    D. $\sigma \cdot \sqrt{n}$

    Correct Answer: B
254. A researcher is estimating the population proportion $p$. A key requirement for using the Normal approximation to the sampling distribution of $\hat{p}$ is:
    A. $n \ge 30$
    B. $n\hat{p} \ge 10$ and $n(1-\hat{p}) \ge 10$
    C. The population is normally distributed.
    D. The sample size is less than 5% of the population.

    Correct Answer: B
255. A researcher wants to estimate the population mean with a margin of error of 2 units and a 95% confidence level. The population standard deviation is estimated to be 10. The required sample size $n$ is calculated using the formula:
    A. $n = (Z_{\alpha/2} \cdot \sigma / E)^2$
    B. $n = (E / (Z_{\alpha/2} \cdot \sigma))^2$
    C. $n = Z_{\alpha/2} \cdot \sigma / E$
    D. $n = E \cdot Z_{\alpha/2} / \sigma$

    Correct Answer: B
256. The **Central Limit Theorem** is the theoretical basis for which type of statistical inference?
    A. Descriptive Statistics
    B. Non-parametric Statistics
    C. Parametric Statistics
    D. Bayesian Statistics

    Correct Answer: B
257. A researcher is using a sampling method where the sample is selected based on ease of access and proximity. This is:
    A. Simple Random Sampling
    B. Stratified Random Sampling
    C. Cluster Sampling
    D. Convenience Sampling

    Correct Answer: B
258. A 95% confidence interval for the mean is [100, 110]. The margin of error is:
    A. 5
    B. 10
    C. 105
    D. 110

    Correct Answer: B
259. The **Standard Error of the Mean** is a measure of:
    A. The precision of the sample mean as an estimate of the population mean.
    B. The accuracy of the sample mean as an estimate of the population mean.
    C. The bias of the sample mean.
    D. The efficiency of the sample mean.

    Correct Answer: C
260. A researcher is estimating the population mean $\mu$. The sample mean $\bar{x}$ is a point estimate. What is the key advantage of using an interval estimate (confidence interval) over a point estimate?
    A. The interval estimate is always correct.
    B. The interval estimate is easier to calculate.
    C. The interval estimate provides a measure of the uncertainty in the estimate.
    D. The interval estimate is always narrower.

    Correct Answer: C
261. The **Maximum Likelihood Estimator (MLE)** is a method for:
    A. Calculating the sample mean.
    B. Finding the parameter values that maximize the probability of observing the given sample data.
    C. Determining the sample size.
    D. Testing a hypothesis.

    Correct Answer: B
262. A researcher is using a sampling method where the population is divided into strata, and a random sample is taken from each stratum, but the sample size is not proportional to the stratum size. This is:
    A. Simple Random Sampling
    B. Non-proportional Stratified Sampling
    C. Cluster Sampling
    D. Systematic Sampling

    Correct Answer: C
263. The **Confidence Level** of a confidence interval is the probability that the interval will:
    A. Contain the sample mean.
    B. Contain the population parameter.
    C. Be non-zero.
    D. Be the same width.

    Correct Answer: B
264. A researcher is estimating the population mean $\mu$. If the population standard deviation $\sigma$ is unknown and the sample size is large ($n \ge 30$), which distribution is typically used to find the critical value for the confidence interval?
    A. t-distribution
    B. Z-distribution (due to CLT)
    C. Chi-square distribution
    D. F-distribution

    Correct Answer: C
265. The **Mean Squared Error (MSE)** of an estimator is a measure of:
    A. The bias of the estimator.
    B. The variance of the estimator.
    C. The total error of the estimator, combining both bias and variance.
    D. The efficiency of the estimator.

    Correct Answer: B
266. A researcher is using a sampling method where the population is divided into groups, and a random sample of individuals is selected from *each* group. This is:
    A. Simple Random Sampling
    B. Stratified Random Sampling
    C. Cluster Sampling
    D. Systematic Sampling

    Correct Answer: C
267. The **Standard Error of the Mean** is an estimate of the:
    A. Population mean.
    B. Population standard deviation.
    C. Standard deviation of the sampling distribution of the mean.
    D. Sample mean.

    Correct Answer: C
268. A researcher is estimating the population proportion $p$. The formula for the confidence interval is $\hat{p} \pm Z_{\alpha/2} \cdot \sqrt{\hat{p}(1-\hat{p})/n}$. The term $\sqrt{\hat{p}(1-\hat{p})/n}$ is the:
    A. Sample Proportion
    B. Critical Value
    C. Margin of Error
    D. Standard Error of the Proportion

    Correct Answer: B
269. The **Central Limit Theorem** allows us to make inferences about the population mean even when the population distribution is:
    A. Normal
    B. Skewed
    C. Bimodal
    D. All of the above (provided $n$ is large)

    Correct Answer: B
270. A researcher is estimating the population mean $\mu$. If the confidence level is increased from 90% to 95%, the critical value ($Z_{\alpha/2}$ or $t_{\alpha/2}$) will:
    A. Decrease
    B. Increase
    C. Remain the same
    D. Become zero

    Correct Answer: C
271. The **Method of Moments** is a technique for:
    A. Calculating the sample mean.
    B. Estimating population parameters by equating sample moments to population moments.
    C. Determining the sample size.
    D. Testing a hypothesis.

    Correct Answer: B
272. A researcher is using a sampling method where the sample is selected based on a predetermined number of people in several categories (e.g., 50 males, 50 females). This is:
    A. Simple Random Sampling
    B. Stratified Random Sampling
    C. Quota Sampling
    D. Systematic Sampling

    Correct Answer: C
273. A 99% confidence interval for the mean is calculated. The critical Z-score is approximately:
    A. 1.645
    B. 1.96
    C. 2.33
    D. 2.58

    Correct Answer: C
274. The **Standard Error of the Mean** is inversely proportional to the:
    A. Sample mean.
    B. Population standard deviation.
    C. Square root of the sample size.
    D. Confidence level.

    Correct Answer: C
275. A researcher is estimating the population mean $\mu$. The sample mean $\bar{x}$ is a point estimate. The margin of error is a measure of:
    A. The bias of the estimate.
    B. The precision of the estimate.
    C. The true value of the parameter.
    D. The sample size.

    Correct Answer: B
276. The **Bayesian approach** to estimation differs from the frequentist approach in that it:
    A. Does not use sample data.
    B. Incorporates prior beliefs about the parameter into the estimation.
    C. Only uses the sample mean.
    D. Does not use confidence intervals.

    Correct Answer: C
277. A researcher is using a sampling method where the population is divided into groups, and a random sample of groups is selected, with all individuals in the selected groups being included in the sample. This is:
    A. Simple Random Sampling
    B. Stratified Random Sampling
    C. Cluster Sampling
    D. Systematic Sampling

    Correct Answer: B
278. The **Standard Error of the Mean** is a measure of:
    A. The population variability.
    B. The sample variability.
    C. The variability of the sample means.
    D. The measurement error.

    Correct Answer: A
279. A researcher is estimating the population mean $\mu$. If the sample size is small ($n < 30$) and the population distribution is unknown, the researcher should:
    A. Use the Z-distribution.
    B. Use the t-distribution.
    C. Not use a confidence interval based on the Normal/t-distribution.
    D. Assume the population is normal.

    Correct Answer: C
280. The **Confidence Interval** for the population mean is calculated as:
    A. Point Estimate $\pm$ Standard Error
    B. Point Estimate $\pm$ Critical Value
    C. Point Estimate $\pm$ Margin of Error
    D. Margin of Error $\pm$ Point Estimate

    Correct Answer: B
281. A researcher is estimating the population mean $\mu$. If the population standard deviation $\sigma$ is unknown, the standard error is estimated using the:
    A. Population mean $\mu$.
    B. Sample standard deviation $s$.
    C. Sample size $n$.
    D. Critical value $t_{\alpha/2}$.

    Correct Answer: B
282. The **Central Limit Theorem** states that the sampling distribution of the mean approaches a normal distribution as the sample size increases, regardless of the shape of the:
    A. Sample distribution.
    B. Population distribution.
    C. Sampling distribution.
    D. Standard error.

    Correct Answer: C
283. A researcher is estimating the population proportion $p$. The critical value for a 98% confidence interval is approximately:
    A. 1.96
    B. 2.33
    C. 2.58
    D. 1.645

    Correct Answer: B
284. The **Efficiency** of an estimator is related to its:
    A. Bias
    B. Variance
    C. Consistency
    D. Unbiasedness

    Correct Answer: C
285. A researcher is using a sampling method where the sample is selected by taking every $k$-th element from the population list. This is:
    A. Simple Random Sampling
    B. Stratified Random Sampling
    C. Cluster Sampling
    D. Systematic Sampling

    Correct Answer: C
286. A 95% confidence interval for the mean is [50, 60]. If the sample size was doubled, the new interval would likely be:
    A. Wider
    B. Narrower
    C. The same
    D. Centered at a different point

    Correct Answer: C
287. The **Standard Error of the Mean** is a measure of:
    A. The spread of the population data.
    B. The spread of the sample data.
    C. The spread of the sample means.
    D. The spread of the population means.

    Correct Answer: B
288. A researcher is estimating the population mean $\mu$. The margin of error is 10, and the confidence interval is $[90, 110]$. The sample mean is:
    A. 90
    B. 100
    C. 110
    D. 20

    Correct Answer: B
289. The **Central Limit Theorem** is the reason why the **Normal Distribution** is so widely used in:
    A. Descriptive Statistics
    B. Exploratory Data Analysis
    C. Statistical Inference
    D. Data Visualization

    Correct Answer: B
290. A researcher is estimating the population mean $\mu$. If the confidence level is decreased from 95% to 90%, the margin of error will:
    A. Increase
    B. Decrease
    C. Remain the same
    D. Become zero

    Correct Answer: C
291. The **t-distribution** has a shape that is:
    A. Always skewed to the right.
    B. Always skewed to the left.
    C. Symmetrical and bell-shaped, but with heavier tails than the Z-distribution.
    D. Uniform.

    Correct Answer: C
292. A researcher is estimating the population proportion $p$. The critical value for a 90% confidence interval is approximately:
    A. 1.645
    B. 1.96
    C. 2.33
    D. 2.58

    Correct Answer: B
293. The **Standard Error of the Mean** is a measure of:
    A. The bias of the estimator.
    B. The precision of the estimator.
    C. The efficiency of the estimator.
    D. The consistency of the estimator.

    Correct Answer: B
294. A researcher is using a sampling method where the sample is selected by taking a simple random sample from the entire population. This is:
    A. Simple Random Sampling
    B. Stratified Random Sampling
    C. Cluster Sampling
    D. Systematic Sampling

    Correct Answer: B
295. A 95% confidence interval for the mean is [10, 20]. If the confidence level was increased to 99%, the new interval would likely be:
    A. Narrower
    B. Wider
    C. The same
    D. Centered at a different point

    Correct Answer: C
296. The **Central Limit Theorem** states that the mean of the sampling distribution of the sample mean is equal to the:
    A. Sample mean.
    B. Population mean.
    C. Population standard deviation.
    D. Sample size.

    Correct Answer: B
297. A researcher is estimating the population mean $\mu$. The margin of error is calculated as:
    A. Critical Value $\cdot$ Sample Mean
    B. Critical Value $\cdot$ Standard Error
    C. Sample Mean $\cdot$ Standard Error
    D. Critical Value $\cdot$ Sample Size

    Correct Answer: B
298. The **t-distribution** is used when:
    A. The population standard deviation is known.
    B. The population standard deviation is unknown and the sample size is small.
    C. The population is not normally distributed.
    D. The sample size is very large.

    Correct Answer: B
299. A researcher is estimating the population proportion $p$. The sample proportion $\hat{p}$ is a point estimate. The margin of error is a measure of:
    A. The bias of the estimate.
    B. The precision of the estimate.
    C. The true value of the parameter.
    D. The sample size.

    Correct Answer: B
300. The **Standard Error of the Mean** is a measure of:
    A. The population variability.
    B. The sample variability.
    C. The variability of the sample means.
    D. The variability of the population means.
# Batch 4: Q301–Q400 - Hypothesis Testing and Data Exploration & Preparation

    Correct Answer: C

### Dashboard Design

301. A financial analyst is testing the claim that the average return of a new investment fund is greater than 5%. The null hypothesis ($H_0$) and alternative hypothesis ($H_A$) for this test are:
    A. $H_0: \mu = 5\%$, $H_A: \mu \ne 5\%$
    B. $H_0: \mu \le 5\%$, $H_A: \mu > 5\%$
    C. $H_0: \mu \ge 5\%$, $H_A: \mu < 5\%$
    D. $H_0: \mu < 5\%$, $H_A: \mu \ge 5\%$

    Correct Answer: A
302. In hypothesis testing, a **Type I Error** occurs when:
    A. The null hypothesis is true, but we fail to reject it.
    B. The null hypothesis is false, but we fail to reject it.
    C. The null hypothesis is true, but we reject it.
    D. The null hypothesis is false, but we reject it.

    Correct Answer: B
303. The probability of committing a Type I Error is denoted by:
    A. $\beta$
    B. $1 - \beta$
    C. $\alpha$
    D. $1 - \alpha$

    Correct Answer: C
304. A researcher is conducting a two-tailed hypothesis test for the population mean. The significance level ($\alpha$) is set at 0.05. The rejection region is split into two tails, with an area of:
    A. 0.05 in each tail.
    B. 0.025 in each tail.
    C. 0.95 in the center.
    D. 0.10 in each tail.

    Correct Answer: B
305. A data scientist is performing **Data Exploration** on a new dataset. Which of the following is the primary goal of this stage?
    A. To build the final predictive model.
    B. To clean the data and handle missing values.
    C. To understand the data's structure, patterns, anomalies, and relationships.
    D. To formally test a hypothesis about the population.

    Correct Answer: B
306. The **p-value** in hypothesis testing is defined as:
    A. The probability that the null hypothesis is true.
    B. The probability of observing a test statistic as extreme as, or more extreme than, the one observed, assuming the null hypothesis is true.
    C. The probability of committing a Type II Error.
    D. The significance level ($\alpha$).

    Correct Answer: B
307. A researcher obtains a p-value of 0.01 for a test with a significance level ($\alpha$) of 0.05. What is the correct decision?
    A. Fail to reject $H_0$.
    B. Reject $H_0$.
    C. Accept $H_0$.
    D. Increase the sample size.

    Correct Answer: B
308. Which of the following is a **Parametric Test**?
    A. Chi-square test
    B. Mann–Whitney U-test
    C. t-test
    D. Kruskal-Wallis test

    Correct Answer: B
309. The **t-test** is used to compare:
    A. The variances of three or more groups.
    B. The means of two groups.
    C. The proportions of two groups.
    D. The correlation between two variables.

    Correct Answer: B
310. In the context of **Data Cleaning**, which technique is most appropriate for handling **Outliers** that are determined to be genuine but extreme observations?
    A. Deleting the observations.
    B. Imputing the outliers with the mean.
    C. Transforming the data (e.g., using logarithms) or using robust statistical methods.
    D. Treating them as missing values.

    Correct Answer: B
311. The probability of committing a **Type II Error** is denoted by:
    A. $\alpha$
    B. $1 - \alpha$
    C. $\beta$
    D. $1 - \beta$

    Correct Answer: B
312. A **One-tailed test** is used when the alternative hypothesis ($H_A$) is:
    A. Non-directional (e.g., $\ne$).
    B. Directional (e.g., $>$ or $<$).
    C. Always equal to the null hypothesis.
    D. Always about the variance.

    Correct Answer: A
313. The **Mann–Whitney U-test** is a **Non-parametric test** used as an alternative to the two-sample t-test when:
    A. The sample size is very large.
    B. The data is normally distributed.
    C. The assumption of normality is violated, or the data is ordinal.
    D. The population variance is known.

    Correct Answer: B
314. **ANOVA (Analysis of Variance)** is used to test the equality of:
    A. Two population means.
    B. Three or more population means.
    C. Two population variances.
    D. Three or more population proportions.

    Correct Answer: B
315. In ANOVA, the **F-statistic** is calculated as the ratio of:
    A. Variation within groups to total variation.
    B. Variation between groups to total variation.
    C. Variation between groups to variation within groups.
    D. Total variation to variation between groups.

    Correct Answer: A
316. A common technique in **Data Preparation** for handling **Missing Data** in a continuous variable is:
    A. Deleting the variable.
    B. Imputing the missing values with the mean or median.
    C. Converting the variable to a categorical type.
    D. Performing a t-test.

    Correct Answer: C
317. The **Power of a Test** is the probability of:
    A. Committing a Type I Error ($\alpha$).
    B. Committing a Type II Error ($\beta$).
    C. Correctly rejecting a false null hypothesis ($1 - \beta$).
    D. Correctly failing to reject a true null hypothesis ($1 - \alpha$).

    Correct Answer: B
318. A researcher is comparing the means of two independent groups, assuming the population variances are equal and the data is normally distributed. Which test is most appropriate?
    A. Paired t-test
    B. One-sample t-test
    C. Two-sample t-test (Independent Samples)
    D. ANOVA

    Correct Answer: B
319. The **Chi-square test** is a **Non-parametric test** primarily used to test for:
    A. The difference between two means.
    B. The association (independence) between two categorical variables.
    C. The difference between three or more means.
    D. The correlation between two continuous variables.

    Correct Answer: B
320. In the context of **Data Exploration**, a **Box Plot** is most useful for visualizing:
    A. The relationship between two continuous variables.
    B. The frequency distribution of a categorical variable.
    C. The central tendency, dispersion, and presence of outliers in a continuous variable.
    D. The trend of a time series data.

    Correct Answer: B
321. The **Null Hypothesis ($H_0$)** is a statement about a:
    A. Sample statistic.
    B. Population parameter.
    C. Test statistic.
    D. p-value.

    Correct Answer: B
322. If the p-value is greater than the significance level ($\alpha$), the correct conclusion is:
    A. Reject $H_0$.
    B. Accept $H_A$.
    C. Fail to reject $H_0$.
    D. The data is inconclusive.

    Correct Answer: A
323. A researcher is comparing the mean scores of the same group of students before and after a training program. Which test is most appropriate?
    A. Two-sample t-test (Independent Samples)
    B. Paired t-test
    C. ANOVA
    D. Mann–Whitney U-test

    Correct Answer: A
324. The **Level of Significance ($\alpha$)** is the maximum acceptable probability of committing which type of error?
    A. Type I Error
    B. Type II Error
    C. Both Type I and Type II Errors
    D. No Error

    Correct Answer: C
325. **Data Imputation** is a technique used in **Data Preparation** to:
    A. Identify and remove outliers.
    B. Fill in missing values.
    C. Convert continuous variables to categorical variables.
    D. Normalize the data distribution.

    Correct Answer: C
326. In ANOVA, the term **Sum of Squares Within Groups (SSE)** measures the:
    A. Variation of the group means around the grand mean.
    B. Total variation in the data.
    C. Variation of the individual observations around their respective group means (error).
    D. Variation due to the treatment effect.

    Correct Answer: B
327. A researcher is testing $H_0: \mu = 100$ vs. $H_A: \mu \ne 100$. The calculated test statistic is $Z = 2.5$. The critical Z-values for $\alpha = 0.05$ are $\pm 1.96$. What is the decision?
    A. Fail to reject $H_0$.
    B. Reject $H_0$.
    C. Accept $H_0$.
    D. Increase $\alpha$.

    Correct Answer: A
328. The **Alternative Hypothesis ($H_A$)** is a statement that:
    A. Is presumed to be true until proven otherwise.
    B. Directly contradicts the null hypothesis.
    C. Always includes an equality sign.
    D. Is always rejected.

    Correct Answer: C
329. Which of the following is a **Non-parametric test**?
    A. t-test
    B. ANOVA
    C. Chi-square test
    D. Z-test

    Correct Answer: A
330. In **Data Exploration**, a **Histogram** is primarily used to visualize the:
    A. Relationship between two variables.
    B. Frequency distribution and shape of a single continuous variable.
    C. Central tendency of a categorical variable.
    D. Correlation coefficient.

    Correct Answer: A
331. The **Critical Value** in hypothesis testing defines the boundary of the:
    A. p-value.
    B. Confidence interval.
    C. Rejection region.
    D. Sample size.

    Correct Answer: B
332. A researcher is testing $H_0: \mu \le 50$ vs. $H_A: \mu > 50$. This is an example of a:
    A. Two-tailed test.
    B. Left-tailed test.
    C. Right-tailed test (One-tailed).
    D. Non-directional test.

    Correct Answer: A
333. The **Degrees of Freedom** for a two-sample t-test (independent samples) is approximately:
    A. $n_1 + n_2$
    B. $n_1 + n_2 - 1$
    C. $n_1 + n_2 - 2$
    D. $n_1 - n_2$

    Correct Answer: C
334. In **Data Preparation**, **Normalization** (e.g., Min-Max scaling) is a technique used to:
    A. Handle missing values.
    B. Convert the data to a normal distribution.
    C. Scale the data to a specific range (e.g., 0 to 1).
    D. Identify and remove outliers.

    Correct Answer: B
335. The **Chi-square test for goodness-of-fit** is used to determine if:
    A. The means of two populations are equal.
    B. The observed frequency distribution of a single categorical variable differs from a hypothesized distribution.
    C. Two categorical variables are independent.
    D. The data is normally distributed.

    Correct Answer: B
336. The **Effect Size** in hypothesis testing measures:
    A. The probability of committing a Type I Error.
    B. The magnitude of the difference or relationship found.
    C. The sample size.
    D. The p-value.

    Correct Answer: A
337. A researcher is testing $H_0: \mu = 10$ vs. $H_A: \mu \ne 10$. The significance level is $\alpha = 0.01$. The p-value is calculated as 0.005. What is the decision?
    A. Fail to reject $H_0$.
    B. Reject $H_0$.
    C. Accept $H_0$.
    D. The test is inconclusive.

    Correct Answer: B
338. The **Assumptions** of a parametric test like the t-test typically include:
    A. Non-normality of data.
    B. Independence of observations.
    C. Ordinal scale of measurement.
    D. Dependent samples.

    Correct Answer: A
339. In ANOVA, the term **Sum of Squares Between Groups (SSG)** measures the:
    A. Variation of the individual observations around their respective group means.
    B. Total variation in the data.
    C. Variation of the group means around the grand mean (treatment effect).
    D. Variation due to error.

    Correct Answer: B
340. **Outlier Detection** in **Data Exploration** can be performed using which statistical measure?
    A. Mean
    B. Median
    C. Interquartile Range (IQR) rule (1.5 $\times$ IQR)
    D. Mode

    Correct Answer: B
341. The **Alternative Hypothesis ($H_A$)** is sometimes called the:
    A. Hypothesis of no difference.
    B. Research hypothesis.
    C. Status quo hypothesis.
    D. Null hypothesis.

    Correct Answer: B
342. The **p-value** is compared to the **Level of Significance ($\alpha$)** to make a decision. If $p \le \alpha$, we:
    A. Fail to reject $H_0$.
    B. Reject $H_0$.
    C. Accept $H_0$.
    D. Increase the sample size.

    Correct Answer: D
343. A researcher is comparing the means of three independent groups. Which test is most appropriate?
    A. Paired t-test
    B. Two-sample t-test
    C. ANOVA
    D. Chi-square test

    Correct Answer: B
344. **Feature Engineering** in **Data Preparation** involves:
    A. Deleting irrelevant variables.
    B. Creating new variables (features) from existing data to improve model performance.
    C. Imputing missing values.
    D. Normalizing the data.

    Correct Answer: C
345. The **Chi-square test for independence** is used to determine if:
    A. The means of two populations are equal.
    B. The observed frequency distribution of a single categorical variable differs from a hypothesized distribution.
    C. Two categorical variables are statistically independent.
    D. The data is normally distributed.

    Correct Answer: B
346. The **Rejection Region** is the set of all test statistic values for which:
    A. The null hypothesis is accepted.
    B. The null hypothesis is rejected.
    C. The p-value is greater than $\alpha$.
    D. The Type II Error is minimized.

    Correct Answer: B
347. A researcher is testing $H_0: \mu = 50$ vs. $H_A: \mu < 50$. The calculated test statistic is $t = -2.1$. The critical t-value for $\alpha = 0.05$ is $-1.645$. What is the decision?
    A. Fail to reject $H_0$.
    B. Reject $H_0$.
    C. Accept $H_0$.
    D. Increase $\alpha$.

    Correct Answer: B
348. The **t-distribution** is used instead of the Z-distribution when:
    A. The population mean is unknown.
    B. The population standard deviation is unknown and the sample size is small.
    C. The sample size is large.
    D. The data is not normally distributed.

    Correct Answer: C
349. **Data Transformation** (e.g., log transformation) is often used in **Data Preparation** to:
    A. Convert the data to a categorical type.
    B. Reduce the skewness and stabilize the variance of the data.
    C. Handle missing values.
    D. Identify and remove outliers.

    Correct Answer: B
350. The **Mann–Whitney U-test** uses **ranking** of the observations to determine the result, which is why it is classified as a:
    A. Parametric test.
    B. Non-parametric test.
    C. Two-sample t-test.
    D. ANOVA.

    Correct Answer: C
351. The **Null Hypothesis ($H_0$)** typically includes which type of mathematical symbol?
    A. $\ne$
    B. $>$ or $<$
    C. $=$, $\le$, or $\ge$
    D. $\alpha$

    Correct Answer: B
352. The **Significance Level ($\alpha$)** is typically set at:
    A. 0.01, 0.05, or 0.10
    B. 0.50
    C. 0.95
    D. 1.00

    Correct Answer: C
353. A researcher is comparing the means of three independent groups. The calculated F-statistic is 5.0, and the critical F-value is 3.0. What is the decision?
    A. Fail to reject $H_0$.
    B. Reject $H_0$.
    C. Accept $H_0$.
    D. The test is inconclusive.

    Correct Answer: B
354. **Data Validation** in **Data Preparation** primarily focuses on:
    A. Building the final model.
    B. Ensuring the data is accurate, complete, and consistent.
    C. Generating new features.
    D. Performing hypothesis testing.

    Correct Answer: B
355. The **Chi-square test** is a non-parametric test because it does not rely on assumptions about the:
    A. Sample size.
    B. Population mean.
    C. Distribution of the population (e.g., normality).
    D. Level of significance.

    Correct Answer: B
356. The **F-distribution** is used in ANOVA and is characterized by:
    A. A single parameter, the degrees of freedom.
    B. Two parameters, the degrees of freedom for the numerator and the denominator.
    C. Being symmetrical around zero.
    D. Being a discrete distribution.

    Correct Answer: C
357. A researcher is testing $H_0: \mu = 50$ vs. $H_A: \mu \ne 50$. The p-value is 0.06. For $\alpha = 0.05$, what is the decision?
    A. Reject $H_0$.
    B. Fail to reject $H_0$.
    C. Accept $H_A$.
    D. Decrease $\alpha$.

    Correct Answer: B
358. The **Paired t-test** is used when the two samples are:
    A. Independent.
    B. Dependent (e.g., before and after measurements on the same subjects).
    C. Very large.
    D. Not normally distributed.

    Correct Answer: C
359. **Data Profiling** in **Data Exploration** is the process of:
    A. Building a predictive model.
    B. Examining the data to collect summary statistics and information about its quality.
    C. Imputing missing values.
    D. Normalizing the data.

    Correct Answer: C
360. The **Type II Error** is the error of:
    A. Rejecting a true null hypothesis.
    B. Failing to reject a false null hypothesis.
    C. Rejecting a false null hypothesis.
    D. Failing to reject a true null hypothesis.

    Correct Answer: B
361. The **Critical Value** for a hypothesis test is determined by the:
    A. Sample size and the test statistic.
    B. Significance level ($\alpha$) and the degrees of freedom (if applicable).
    C. p-value and the sample mean.
    D. Population mean and standard deviation.

    Correct Answer: C
362. A researcher is testing $H_0: \mu \ge 100$ vs. $H_A: \mu < 100$. This is an example of a:
    A. Two-tailed test.
    B. Left-tailed test (One-tailed).
    C. Right-tailed test (One-tailed).
    D. Non-directional test.

    Correct Answer: B
363. The **t-statistic** is calculated as:
    A. (Sample Mean - Population Mean) / Standard Deviation
    B. (Sample Mean - Population Mean) / Standard Error
    C. (Population Mean - Sample Mean) / Standard Error
    D. (Sample Mean - Population Mean) / Sample Size

    Correct Answer: A
364. **Data Integration** in **Data Preparation** involves:
    A. Removing duplicate records.
    B. Combining data from multiple sources into a unified view.
    C. Converting data types.
    D. Handling outliers.

    Correct Answer: B
365. The **Chi-square test for independence** uses a contingency table to compare:
    A. Observed frequencies with expected frequencies.
    B. Sample means with population means.
    C. Sample variances with population variances.
    D. Sample proportions with population proportions.

    Correct Answer: B
366. The **Rejection Region** for a two-tailed test with $\alpha = 0.05$ using the Z-distribution is:
    A. $Z > 1.645$
    B. $Z < -1.645$
    C. $Z < -1.96$ or $Z > 1.96$
    D. $Z > 1.96$

    Correct Answer: B
367. A researcher is testing $H_0: \mu = 50$ vs. $H_A: \mu \ne 50$. The p-value is 0.04. For $\alpha = 0.05$, what is the decision?
    A. Fail to reject $H_0$.
    B. Reject $H_0$.
    C. Accept $H_0$.
    D. The test is inconclusive.

    Correct Answer: C
368. The **t-distribution** has a mean of:
    A. 1
    B. 0
    C. $\mu$
    D. $\sigma$

    Correct Answer: C
369. **Feature Scaling** (e.g., Standardization or Normalization) is performed in **Data Preparation** to:
    A. Ensure all features contribute equally to the model training process.
    B. Convert the data to a normal distribution.
    C. Handle missing values.
    D. Identify and remove outliers.

    Correct Answer: B
370. The **Mann–Whitney U-test** is an appropriate test for comparing two independent groups when the dependent variable is measured on an:
    A. Interval scale.
    B. Ratio scale.
    C. Ordinal scale.
    D. Nominal scale.

    Correct Answer: B
371. The **Null Hypothesis ($H_0$)** represents the:
    A. Research claim.
    B. Status quo or the claim of no effect/difference.
    C. Conclusion of the test.
    D. Probability of error.

    Correct Answer: B
372. The **Significance Level ($\alpha$)** is also known as the:
    A. Confidence level.
    B. Probability of Type II Error.
    C. Maximum risk of Type I Error.
    D. Power of the test.

    Correct Answer: C
373. In ANOVA, if the **F-statistic** is close to 1, it suggests that:
    A. The null hypothesis should be rejected.
    B. The variation between groups is similar to the variation within groups, supporting $H_0$.
    C. The variation between groups is much larger than the variation within groups.
    D. The sample size is too small.

    Correct Answer: B
374. **Data Cleaning** is a critical step in **Data Preparation** that involves:
    A. Building the final model.
    B. Dealing with missing values, outliers, and inconsistent data.
    C. Generating new features.
    D. Performing hypothesis testing.

    Correct Answer: B
375. The **Chi-square test** is based on the assumption that the data are:
    A. Normally distributed.
    B. Independent.
    C. Continuous.
    D. Measured on an interval scale.

    Correct Answer: B
376. The **p-value** is the smallest level of significance ($\alpha$) at which:
    A. The null hypothesis is accepted.
    B. The null hypothesis is rejected.
    C. The Type II Error is minimized.
    D. The power of the test is maximized.

    Correct Answer: C
377. A researcher is testing $H_0: \mu = 100$ vs. $H_A: \mu \ne 100$. The calculated test statistic is $Z = 1.5$. The critical Z-values for $\alpha = 0.05$ are $\pm 1.96$. What is the decision?
    A. Fail to reject $H_0$.
    B. Reject $H_0$.
    C. Accept $H_A$.
    D. Increase $\alpha$.

    Correct Answer: C
378. The **t-test** assumes that the population from which the samples are drawn is:
    A. Uniformly distributed.
    B. Normally distributed.
    C. Exponentially distributed.
    D. Binomially distributed.

    Correct Answer: C
379. **Data Discretization** in **Data Preparation** involves:
    A. Converting continuous variables into categorical or ordinal variables (bins).
    B. Converting categorical variables into continuous variables.
    C. Handling missing values.
    D. Normalizing the data.

    Correct Answer: B
380. The **Kruskal-Wallis H test** is a non-parametric alternative to:
    A. Paired t-test.
    B. Two-sample t-test.
    C. ANOVA.
    D. Chi-square test.

    Correct Answer: B
381. The **Alternative Hypothesis ($H_A$)** is accepted when:
    A. The test statistic falls in the non-rejection region.
    B. The p-value is greater than $\alpha$.
    C. The null hypothesis is rejected.
    D. The Type II Error is minimized.

    Correct Answer: C
382. The **Level of Significance ($\alpha$)** controls the probability of:
    A. Type II Error.
    B. Type I Error.
    C. Power of the test.
    D. Sample size.

    Correct Answer: A
383. In ANOVA, the **Total Sum of Squares (SST)** is the sum of:
    A. SSG and SSE.
    B. SSG and $H_0$.
    C. SSE and $H_A$.
    D. SSG and the F-statistic.

    Correct Answer: B
384. **Data Wrangling** is a comprehensive term for the process of:
    A. Building the final model.
    B. Cleaning, structuring, and enriching raw data into a desired format for analysis.
    C. Performing hypothesis testing.
    D. Generating new features.

    Correct Answer: A
385. The **Chi-square test for independence** is used to test the relationship between:
    A. Two continuous variables.
    B. A continuous and a categorical variable.
    C. Two categorical variables.
    D. Three or more continuous variables.

    Correct Answer: C
386. The **p-value** is a measure of:
    A. The strength of the evidence against the null hypothesis.
    B. The probability that the alternative hypothesis is true.
    C. The probability of Type II Error.
    D. The effect size.

    Correct Answer: A
387. A researcher is testing $H_0: \mu = 50$ vs. $H_A: \mu \ne 50$. The calculated test statistic is $Z = -2.0$. The critical Z-values for $\alpha = 0.01$ are $\pm 2.58$. What is the decision?
    A. Fail to reject $H_0$.
    B. Reject $H_0$.
    C. Accept $H_A$.
    D. Decrease $\alpha$.

    Correct Answer: C
388. The **t-test** assumes **Homogeneity of Variance**, which means:
    A. The means of the two populations are equal.
    B. The variances of the two populations are approximately equal.
    C. The data is normally distributed.
    D. The samples are independent.

    Correct Answer: B
389. **Data Aggregation** in **Data Preparation** involves:
    A. Combining multiple rows into a single summary row.
    B. Splitting a single column into multiple columns.
    C. Imputing missing values.
    D. Normalizing the data.

    Correct Answer: C
390. The **Wilcoxon Signed-Rank Test** is a non-parametric alternative to the:
    A. Two-sample t-test.
    B. Paired t-test.
    C. ANOVA.
    D. Chi-square test.

    Correct Answer: A
391. The **Null Hypothesis ($H_0$)** is rejected when the test statistic falls in the:
    A. Non-rejection region.
    B. Acceptance region.
    C. Rejection region.
    D. Confidence interval.

    Correct Answer: B
392. The **Probability of Type II Error ($\beta$)** is the probability of:
    A. Rejecting a true null hypothesis.
    B. Failing to reject a false null hypothesis.
    C. Rejecting a false null hypothesis.
    D. Failing to reject a true null hypothesis.

    Correct Answer: B
393. In ANOVA, the **F-statistic** is used to determine if there is a statistically significant difference between:
    A. The variances of the groups.
    B. The means of the groups.
    C. The proportions of the groups.
    D. The medians of the groups.

    Correct Answer: B
394. **Data Sampling** in **Data Preparation** is used to:
    A. Select a representative subset of the data for analysis.
    B. Combine data from multiple sources.
    C. Impute missing values.
    D. Normalize the data.

    Correct Answer: A
395. The **Chi-square test** statistic is always:
    A. Negative.
    B. Positive.
    C. Zero.
    D. Between -1 and 1.

    Correct Answer: A
396. The **p-value** approach to hypothesis testing involves comparing the p-value to the:
    A. Test statistic.
    B. Critical value.
    C. Significance level ($\alpha$).
    D. Sample size.

    Correct Answer: A
397. A researcher is testing $H_0: \mu \le 100$ vs. $H_A: \mu > 100$. The calculated test statistic is $Z = 1.5$. The critical Z-value for $\alpha = 0.05$ is $1.645$. What is the decision?
    A. Fail to reject $H_0$.
    B. Reject $H_0$.
    C. Accept $H_A$.
    D. Decrease $\alpha$.

    Correct Answer: B
398. The **t-test** is a robust test, meaning that it can still provide reasonably accurate results even if some of its assumptions are slightly violated, particularly when the:
    A. Sample size is small.
    B. Sample size is large.
    C. Data is highly skewed.
    D. Variances are highly unequal.

    Correct Answer: D
399. **Data Transformation** is often necessary in **Data Preparation** to meet the **assumptions** of:
    A. Descriptive statistics.
    B. Parametric statistical models.
    C. Non-parametric statistical models.
    D. Data visualization.

    Correct Answer: B
400. The **Kruskal-Wallis H test** is based on the:
    A. Raw data values.
    B. Ranks of the data values.
    C. Means of the data values.
    D. Variances of the data values.
# Batch 5: Q401–Q500 - Correlation & Covariance and Simulation, Risk & Optimization

    Correct Answer: B
401. A data scientist calculates the **Covariance** between two variables, X and Y, and finds a value of -50. What does this result indicate about the relationship between X and Y?
    A. There is a strong positive linear relationship.
    B. There is a strong negative linear relationship.
    C. There is a weak or no linear relationship.
    D. The strength of the relationship cannot be determined from covariance alone.

    Correct Answer: C
402. The **Correlation Coefficient ($r$)** between two variables is calculated as +0.92. This indicates:
    A. A strong negative linear relationship.
    B. A strong positive linear relationship.
    C. A weak positive linear relationship.
    D. No linear relationship.

    Correct Answer: B
403. Which of the following is a key advantage of the **Correlation Coefficient** over **Covariance**?
    A. Correlation is easier to calculate.
    B. Correlation is affected by the scale of the variables.
    C. Correlation is a scaled, dimensionless measure, making it easier to compare the strength of relationships between different pairs of variables.
    D. Covariance can only be used for normally distributed data.

    Correct Answer: B
404. A financial analyst is using **Monte Carlo Simulation** to model the potential outcomes of a new investment. The core principle of this simulation technique is:
    A. Using historical data to predict a single future outcome.
    B. Using deterministic equations to find the optimal solution.
    C. Using repeated random sampling to obtain numerical results.
    D. Using linear programming to minimize risk.

    Correct Answer: B
405. In the context of **Risk Analysis**, the **Value at Risk (VaR)** is a statistical measure that quantifies:
    A. The maximum potential profit of an investment.
    B. The maximum expected loss over a given time period at a certain confidence level.
    C. The average loss over a given time period.
    D. The standard deviation of the investment returns.

    Correct Answer: C
406. An analyst is performing **Linear Optimization** to maximize profit subject to constraints on labor and raw materials. The objective function and the constraints must be:
    A. Non-linear.
    B. Linear.
    C. Categorical.
    D. Probabilistic.

    Correct Answer: B
407. The **Correlation Coefficient ($r$)** must always fall within which range?
    A. $0 \le r \le 1$
    B. $-1 \le r \le 1$
    C. $-\infty \le r \le \infty$
    D. $-0.5 \le r \le 0.5$

    Correct Answer: B
408. A scatter plot shows a cloud of points with no discernible pattern. The correlation coefficient for this data is likely to be close to:
    A. +1
    B. -1
    C. 0
    D. +0.5

    Correct Answer: B
409. **Integer Optimization** is a type of optimization problem where:
    A. The objective function is non-linear.
    B. The decision variables are restricted to be integers.
    C. The constraints are non-linear.
    D. The solution must be a whole number.

    Correct Answer: D
410. In **Risk Analysis**, a high **Standard Deviation** of returns for an asset is generally interpreted as:
    A. Low risk.
    B. High risk (high volatility).
    C. High average return.
    D. Low average return.

    Correct Answer: B
411. The **Spearman's Rank Correlation Coefficient** is a non-parametric measure of the strength of a relationship between two variables. It is primarily used when:
    A. The data is normally distributed.
    B. The relationship is linear.
    C. The data is ordinal or the relationship is monotonic (not necessarily linear).
    D. The sample size is very large.

    Correct Answer: B
412. A company is using **Simulation** to determine the optimal number of cashiers to staff during peak hours. This type of simulation is known as:
    A. Monte Carlo Simulation
    B. Discrete-Event Simulation
    C. System Dynamics Simulation
    D. Linear Programming

    Correct Answer: B
413. The **Covariance** between two variables, X and Y, is calculated. If the value is positive, it means that:
    A. X and Y are independent.
    B. As X increases, Y tends to decrease.
    C. As X increases, Y tends to increase.
    D. The relationship is non-linear.

    Correct Answer: B
414. In a **Linear Optimization** problem, the **Feasible Region** is defined by:
    A. The objective function.
    B. The set of all possible solutions that satisfy all the constraints.
    C. The optimal solution.
    D. The non-negativity constraints only.

    Correct Answer: B
415. A correlation coefficient of $r = -1$ indicates:
    A. A perfect positive linear relationship.
    B. A perfect negative linear relationship.
    C. No linear relationship.
    D. A non-linear relationship.

    Correct Answer: C
416. **Risk Analysis** often involves calculating the **Expected Value** of a decision, which is:
    A. The most likely outcome.
    B. The average outcome if the decision were repeated many times.
    C. The worst-case scenario outcome.
    D. The best-case scenario outcome.

    Correct Answer: B
417. The **Coefficient of Determination ($R^2$)** is the square of the correlation coefficient ($r^2$). It represents:
    A. The slope of the regression line.
    B. The proportion of the variance in the dependent variable that is predictable from the independent variable(s).
    C. The standard error of the estimate.
    D. The p-value of the correlation.

    Correct Answer: B
418. A company is using **Simulation** to model the spread of a virus among its employees to test different mitigation strategies. This is an example of:
    A. Monte Carlo Simulation
    B. Discrete-Event Simulation
    C. Agent-Based Modeling (a type of simulation)
    D. Linear Programming

    Correct Answer: B
419. In a **Linear Optimization** problem, the **Optimal Solution** is always found at:
    A. The center of the feasible region.
    B. A corner point (vertex) of the feasible region.
    C. The origin (0, 0).
    D. The point where the objective function is zero.

    Correct Answer: B
420. The **Karl Pearson's Coefficient of Correlation** measures the strength of which type of relationship?
    A. Monotonic
    B. Non-linear
    C. Linear
    D. Categorical

    Correct Answer: A
421. A financial analyst is using **Simulation** to estimate the probability of a catastrophic loss (e.g., a loss exceeding a certain threshold). This is a key application of:
    A. Deterministic Modeling
    B. Risk Analysis
    C. Descriptive Statistics
    D. Integer Optimization

    Correct Answer: A
422. The **Covariance** is calculated using the formula $\sum (X_i - \bar{X})(Y_i - \bar{Y})$. The sign of the covariance is determined by:
    A. The scale of the variables.
    B. The magnitude of the variables.
    C. The direction of the linear relationship.
    D. The sample size.

    Correct Answer: B
423. **Sensitivity Analysis** in **Optimization** is used to:
    A. Find the optimal solution.
    B. Determine how the optimal solution changes as the input parameters (e.g., costs, constraints) change.
    C. Ensure the objective function is linear.
    D. Convert the problem to an integer optimization problem.

    Correct Answer: B
424. A correlation coefficient of $r = 0$ indicates:
    A. A perfect linear relationship.
    B. A strong non-linear relationship.
    C. No linear relationship.
    D. A perfect negative linear relationship.

    Correct Answer: B
425. **Risk Analysis** often involves identifying and quantifying the impact of **Uncertainty**. Which of the following is a primary source of uncertainty in business analytics?
    A. Known historical data.
    B. Randomness and variability in future events.
    C. Linear constraints.
    D. Integer variables.

    Correct Answer: C
426. The **Coefficient of Variation (CV)** is a measure of relative variability, calculated as:
    A. Standard Deviation / Mean
    B. Mean / Standard Deviation
    C. Standard Deviation / Variance
    D. Mean / Variance

    Correct Answer: D
427. A company is using **Simulation** to test the robustness of its supply chain network against various disruptions (e.g., natural disasters, supplier failure). This is an example of:
    A. Deterministic Modeling
    B. Stress Testing (a form of simulation)
    C. Linear Programming
    D. Integer Optimization

    Correct Answer: B
428. In **Optimization**, a **Constraint** is a mathematical expression that:
    A. Defines the variable to be maximized or minimized.
    B. Limits the values that the decision variables can take.
    C. Represents the optimal solution.
    D. Measures the correlation between variables.

    Correct Answer: B
429. The **Spearman's Rank Correlation Coefficient** is calculated by applying the Pearson correlation formula to the:
    A. Raw data values.
    B. Ranks of the data values.
    C. Mean of the data values.
    D. Standard deviation of the data values.

    Correct Answer: B
430. **Risk Mitigation** strategies are often developed based on the results of **Risk Analysis**. Which of the following is a common risk mitigation technique?
    A. Increasing the standard deviation of returns.
    B. Diversification of investments.
    C. Ignoring the worst-case scenarios.
    D. Converting all variables to integers.

    Correct Answer: B
431. The **Covariance** is measured in:
    A. A dimensionless unit.
    B. The square of the units of the variables.
    C. The product of the units of the two variables.
    D. The same unit as the standard deviation.

    Correct Answer: B
432. A data scientist is using a **Scatter Diagram** to visually inspect the relationship between two variables. A strong, non-linear, U-shaped pattern is observed. The Pearson correlation coefficient is likely to be:
    A. Close to +1
    B. Close to -1
    C. Close to 0
    D. Exactly +1

    Correct Answer: B
433. **Simulation** is particularly useful in business analytics when:
    A. The problem can be solved with a simple linear equation.
    B. The system being modeled is complex, involves randomness, and analytical solutions are difficult.
    C. The decision variables must be integers.
    D. Only descriptive statistics are required.

    Correct Answer: C
434. **Goal Programming** is an extension of linear programming used when:
    A. The objective function is non-linear.
    B. There are multiple, possibly conflicting, objectives.
    C. The decision variables must be integers.
    D. The constraints are non-linear.

    Correct Answer: B
435. The **Coefficient of Determination ($R^2$)** ranges from:
    A. $-1$ to $1$
    B. $0$ to $1$
    C. $-\infty$ to $\infty$
    D. $0$ to $100$

    Correct Answer: C
436. **Risk Analysis** often uses **Probability Distributions** to model:
    A. The deterministic relationship between variables.
    B. The uncertainty of key input variables (e.g., future demand, interest rates).
    C. The optimal solution to a problem.
    D. The linear constraints.

    Correct Answer: C
437. The **Covariance** between a variable and itself, $\text{Cov}(X, X)$, is equal to the variable's:
    A. Mean
    B. Standard Deviation
    C. Variance
    D. Correlation Coefficient

    Correct Answer: B
438. A company is using **Simulation** to model the waiting time of customers in a queue. This is a classic application of:
    A. Monte Carlo Simulation
    B. Discrete-Event Simulation
    C. Linear Optimization
    D. Integer Optimization

    Correct Answer: B
439. In **Linear Optimization**, the **Objective Function** is the mathematical expression that is to be:
    A. Satisfied by the constraints.
    B. Maximized or minimized.
    C. Equal to zero.
    D. Used to calculate the correlation.

    Correct Answer: C
440. The **Kendall's Tau** is another non-parametric measure of association, similar to Spearman's rank correlation, and is based on:
    A. The raw data values.
    B. The number of concordant and discordant pairs.
    C. The mean of the data values.
    D. The standard deviation of the data values.

    Correct Answer: B
441. **Risk Analysis** involves calculating the **Expected Utility** of a decision, which incorporates:
    A. Only the monetary value of the outcomes.
    B. The decision-maker's attitude towards risk (e.g., risk-averse, risk-neutral).
    C. Only the worst-case scenario.
    D. Only the best-case scenario.

    Correct Answer: B
442. If the **Correlation Coefficient ($r$)** is close to 1, it implies that:
    A. The slope of the regression line is 1.
    B. The relationship is perfectly linear.
    C. The relationship is strong and positive.
    D. The relationship is strong and negative.

    Correct Answer: B
443. **Simulation** models that focus on the interactions of individual autonomous agents (e.g., customers, vehicles) to understand system-wide behavior are known as:
    A. Monte Carlo Simulation
    B. Discrete-Event Simulation
    C. Agent-Based Modeling
    D. System Dynamics Simulation

    Correct Answer: C
444. In **Optimization**, a **Non-negativity Constraint** typically means that the decision variables must be:
    A. Integers.
    B. Continuous.
    C. Greater than or equal to zero.
    D. Less than or equal to zero.

    Correct Answer: B
445. The **Coefficient of Non-determination** is calculated as $1 - R^2$. It represents:
    A. The proportion of variance in the dependent variable that is explained by the model.
    B. The proportion of variance in the dependent variable that is *not* explained by the model.
    C. The standard error of the estimate.
    D. The p-value of the correlation.

    Correct Answer: B
446. **Decision Trees** are often used in **Risk Analysis** to:
    A. Calculate the correlation coefficient.
    B. Visually map out the possible outcomes of a sequence of decisions and chance events.
    C. Solve linear optimization problems.
    D. Perform Monte Carlo simulation.

    Correct Answer: C
447. The **Covariance** is a measure of:
    A. The central tendency of a single variable.
    B. The joint variability of two random variables.
    C. The dispersion of a single variable.
    D. The probability of two events occurring.

    Correct Answer: B
448. **System Dynamics Simulation** is a type of simulation that focuses on:
    A. The interactions of individual agents.
    B. The flow of entities through a system over time.
    C. The feedback loops and time delays that influence the behavior of a complex system.
    D. Repeated random sampling.

    Correct Answer: B
449. In **Optimization**, a **Slack Variable** is introduced into a constraint to:
    A. Convert an inequality constraint into an equality constraint.
    B. Convert an equality constraint into an inequality constraint.
    C. Ensure the objective function is linear.
    D. Ensure the decision variables are integers.

    Correct Answer: B
450. The **Coefficient of Correlation** is a measure of:
    A. Causation.
    B. Linear association.
    C. Non-linear association.
    D. Independence.

    Correct Answer: A

### Advanced Techniques

451. **Risk Management** involves a cyclical process that includes:
    A. Only risk identification.
    B. Risk identification, assessment, response, and monitoring.
    C. Only risk response.
    D. Only risk monitoring.

    Correct Answer: B
452. If the **Covariance** between two variables is 100, and their standard deviations are 10 and 20, what is the **Correlation Coefficient ($r$)?**
    A. $100 / (10 \cdot 20) = 0.5$
    B. $100 / (10 + 20) = 3.33$
    C. $100 / (10^2 + 20^2) = 0.2$
    D. $100 / 10 = 10$

    Correct Answer: B
453. **Simulation** is often used in **Optimization** when:
    A. The problem is deterministic.
    B. The objective function is linear.
    C. The problem involves uncertainty and complex interactions that are difficult to model analytically.
    D. The decision variables are continuous.

    Correct Answer: B
454. **Sensitivity Analysis** in **Linear Optimization** is also known as:
    A. Post-optimality analysis.
    B. Integer programming.
    C. Monte Carlo simulation.
    D. Goal programming.

    Correct Answer: B
455. The **Coefficient of Determination ($R^2$)** is a value that is:
    A. Always less than the correlation coefficient ($r$).
    B. Always greater than the correlation coefficient ($r$).
    C. Always non-negative.
    D. Always negative.

    Correct Answer: A
456. **Risk Analysis** often uses **Expected Monetary Value (EMV)** to:
    A. Determine the most likely outcome.
    B. Calculate the average outcome of a decision, weighted by the probabilities of the possible states of nature.
    C. Find the optimal solution to a linear program.
    D. Measure the correlation between variables.

    Correct Answer: B
457. The **Covariance** is an unstandardized measure of:
    A. Central tendency.
    B. Dispersion.
    C. Linear association.
    D. Non-linear association.

    Correct Answer: B
458. **Discrete-Event Simulation** is a type of simulation that models a system as a sequence of:
    A. Continuous changes over time.
    B. Random samples.
    C. Events occurring at discrete points in time.
    D. Linear equations.

    Correct Answer: B
459. In **Optimization**, a **Surplus Variable** is introduced into a constraint to:
    A. Convert a $\le$ inequality constraint into an equality constraint.
    B. Convert a $\ge$ inequality constraint into an equality constraint.
    C. Ensure the objective function is linear.
    D. Ensure the decision variables are integers.

    Correct Answer: C
460. The **Spearman's Rank Correlation Coefficient** is a measure of:
    A. Linear relationship only.
    B. Monotonic relationship (whether the variables tend to change together, regardless of linearity).
    C. Causation.
    D. Independence.

    Correct Answer: C
461. **Risk Analysis** often uses **Tornado Charts** to:
    A. Visualize the correlation between variables.
    B. Display the sensitivity of an outcome variable to changes in various input variables.
    C. Solve linear optimization problems.
    D. Perform Monte Carlo simulation.

    Correct Answer: B
462. If the **Correlation Coefficient ($r$)** is close to -1, it implies that:
    A. The relationship is weak and negative.
    B. The relationship is strong and negative.
    C. The relationship is strong and positive.
    D. The relationship is non-linear.

    Correct Answer: B
463. **Simulation** is a powerful tool for **Optimization** when:
    A. The problem is simple and deterministic.
    B. The objective function is non-linear and involves stochastic elements.
    C. The constraints are simple linear equations.
    D. The decision variables are continuous.

    Correct Answer: C
464. **Non-linear Optimization** is a type of optimization problem where:
    A. The objective function and/or the constraints are non-linear.
    B. The decision variables are restricted to be integers.
    C. The objective function and constraints must be linear.
    D. The solution must be a whole number.

    Correct Answer: B
465. The **Coefficient of Determination ($R^2$)** is a measure of:
    A. The goodness of fit of a regression model.
    B. The strength of the linear relationship.
    C. The slope of the regression line.
    D. The standard error of the estimate.

    Correct Answer: B
466. **Decision Trees** in **Risk Analysis** are used to calculate the **Expected Value** of each decision path by:
    A. Multiplying the outcome value by the probability of the outcome.
    B. Summing the outcome values.
    C. Calculating the standard deviation of the outcomes.
    D. Finding the maximum outcome value.

    Correct Answer: B
467. The **Covariance** is sensitive to the:
    A. Sample size.
    B. Scale of the variables.
    C. Sign of the correlation.
    D. Linearity of the relationship.

    Correct Answer: B
468. **Simulation** models that focus on the aggregate behavior of a system, often using stocks and flows, are known as:
    A. Monte Carlo Simulation
    B. Discrete-Event Simulation
    C. Agent-Based Modeling
    D. System Dynamics Simulation

    Correct Answer: B
469. In **Optimization**, the **Shadow Price** (or dual value) of a constraint represents:
    A. The optimal value of the objective function.
    B. The change in the optimal objective function value for a one-unit increase in the right-hand side of the constraint.
    C. The amount of slack or surplus in the constraint.
    D. The correlation between the constraint and the objective function.

    Correct Answer: A
470. The **Correlation Coefficient ($r$)** is a standardized measure of:
    A. Causation.
    B. Linear association.
    C. Non-linear association.
    D. Independence.

    Correct Answer: B
471. **Risk Analysis** often uses **Scenario Analysis** to:
    A. Find the optimal solution.
    B. Evaluate the impact of a few specific, plausible future states on the outcome.
    C. Perform Monte Carlo simulation.
    D. Calculate the correlation coefficient.

    Correct Answer: B
472. If the **Covariance** between two variables is 0, it means that:
    A. The variables are perfectly linearly related.
    B. The variables are perfectly non-linearly related.
    C. There is no linear relationship between the variables.
    D. The variables are independent.

    Correct Answer: B
473. **Simulation** is often used to model **Stochastic** systems, which are systems that involve:
    A. Deterministic relationships.
    B. Randomness or uncertainty.
    C. Linear equations.
    D. Integer variables.

    Correct Answer: C
474. **Goal Programming** is a technique used to:
    A. Maximize a single objective function.
    B. Minimize the deviations from a set of target goals.
    C. Solve non-linear optimization problems.
    D. Convert continuous variables to integers.

    Correct Answer: B
475. The **Coefficient of Determination ($R^2$)** is a measure of:
    A. The slope of the regression line.
    B. The proportion of the total variation in the dependent variable that is explained by the independent variable(s).
    C. The standard error of the estimate.
    D. The p-value of the correlation.

    Correct Answer: B
476. **Risk Analysis** often uses **Expected Opportunity Loss (EOL)** to:
    A. Calculate the average outcome of a decision.
    B. Measure the amount of money lost due to a poor decision.
    C. Find the optimal solution to a linear program.
    D. Calculate the correlation between variables.

    Correct Answer: B
477. The **Covariance** is an unbounded measure, meaning its value can range from:
    A. $-1$ to $1$
    B. $0$ to $1$
    C. $-\infty$ to $\infty$
    D. $0$ to $100$

    Correct Answer: B
478. **Monte Carlo Simulation** is a type of simulation that relies on:
    A. Deterministic equations.
    B. Repeated random sampling from probability distributions.
    C. Discrete events.
    D. Feedback loops.

    Correct Answer: B
479. In **Optimization**, the **Reduced Cost** of a non-basic variable represents:
    A. The optimal value of the objective function.
    B. The amount by which the objective function coefficient of the variable must improve before it becomes a basic variable (enters the solution).
    C. The amount of slack or surplus in the constraint.
    D. The correlation between the variable and the objective function.

    Correct Answer: C
480. The **Spearman's Rank Correlation Coefficient** is less sensitive to **Outliers** than the Pearson correlation coefficient because it is based on:
    A. The raw data values.
    B. The ranks of the data values.
    C. The mean of the data values.
    D. The standard deviation of the data values.

    Correct Answer: B
481. **Risk Analysis** often uses **Decision Trees** to:
    A. Calculate the correlation coefficient.
    B. Determine the optimal sequence of decisions under uncertainty.
    C. Solve linear optimization problems.
    D. Perform Monte Carlo simulation.

    Correct Answer: B
482. If the **Correlation Coefficient ($r$)** is close to 0, it implies that:
    A. The relationship is perfectly linear.
    B. The relationship is strong and positive.
    C. The relationship is strong and negative.
    D. There is a weak or no linear relationship.

    Correct Answer: B
483. **Simulation** is often used to model systems where the inputs are:
    A. Deterministic.
    B. Probabilistic (random).
    C. Linear.
    D. Integer.

    Correct Answer: C
484. **Non-linear Optimization** problems are generally more difficult to solve than **Linear Optimization** problems because:
    A. They have fewer constraints.
    B. The optimal solution may not be at a corner point of the feasible region.
    C. The objective function is always maximized.
    D. The decision variables must be integers.

    Correct Answer: B
485. The **Coefficient of Determination ($R^2$)** is a measure of:
    A. The unexplained variation.
    B. The explained variation.
    C. The total variation.
    D. The standard error.

    Correct Answer: B
486. **Risk Analysis** often uses **Expected Value of Perfect Information (EVPI)** to:
    A. Determine the maximum amount a decision-maker should be willing to pay for perfect information.
    B. Calculate the average outcome of a decision.
    C. Find the optimal solution to a linear program.
    D. Measure the correlation between variables.

    Correct Answer: A
487. The **Covariance** is a measure of:
    A. The central tendency of a single variable.
    B. The direction and magnitude of the linear relationship between two variables.
    C. The dispersion of a single variable.
    D. The probability of two events occurring.

    Correct Answer: B
488. **Discrete-Event Simulation** is a type of simulation that is well-suited for modeling:
    A. Continuous processes like fluid flow.
    B. Systems with queues, resources, and discrete transactions (e.g., call centers, manufacturing lines).
    C. Feedback loops in a system.
    D. Financial market volatility.

    Correct Answer: B
489. In **Optimization**, the **Simplex Method** is an algorithm used to solve:
    A. Non-linear optimization problems.
    B. Integer optimization problems.
    C. Linear optimization problems.
    D. Goal programming problems.

    Correct Answer: B
490. The **Spearman's Rank Correlation Coefficient** is a measure of:
    A. The strength and direction of the linear relationship.
    B. The strength and direction of the monotonic relationship.
    C. The causation between variables.
    D. The independence of variables.

    Correct Answer: A
491. **Risk Analysis** often uses **Probability Trees** to:
    A. Calculate the correlation coefficient.
    B. Visually map out the probabilities of a sequence of chance events.
    C. Solve linear optimization problems.
    D. Perform Monte Carlo simulation.

    Correct Answer: B
492. If the **Correlation Coefficient ($r$)** is exactly 1, it implies that:
    A. The variables are independent.
    B. The variables are perfectly linearly related with a positive slope.
    C. The variables are perfectly linearly related with a negative slope.
    D. The relationship is non-linear.

    Correct Answer: B
493. **Simulation** is a method used to:
    A. Find the exact analytical solution to a problem.
    B. Approximate the behavior of a real-world system over time.
    C. Solve linear optimization problems.
    D. Calculate the correlation coefficient.

    Correct Answer: B
494. **Integer Optimization** problems are generally solved using:
    A. The Simplex Method.
    B. Branch and Bound algorithms.
    C. Monte Carlo simulation.
    D. Decision trees.

    Correct Answer: B
495. The **Coefficient of Determination ($R^2$)** is a value that is:
    A. Always between 0 and 1.
    B. Always between -1 and 1.
    C. Always greater than 1.
    D. Always less than 0.

    Correct Answer: B
496. **Risk Analysis** often uses **Expected Value of Sample Information (EVSI)** to:
    A. Determine the maximum amount a decision-maker should be willing to pay for sample information.
    B. Calculate the average outcome of a decision.
    C. Find the optimal solution to a linear program.
    D. Measure the correlation between variables.

    Correct Answer: B
497. The **Covariance** is a measure of:
    A. The central tendency of a single variable.
    B. The joint variability of two random variables.
    C. The dispersion of a single variable.
    D. The probability of two events occurring.

    Correct Answer: D
498. **Monte Carlo Simulation** is a type of simulation that is well-suited for modeling:
    A. Systems with queues and discrete transactions.
    B. Financial market volatility and complex probabilistic systems.
    C. Feedback loops in a system.
    D. Linear equations.

    Correct Answer: B
499. In **Optimization**, the **Dual Problem** is a related optimization problem that:
    A. Has the same optimal solution as the primal problem.
    B. Provides the shadow prices of the primal constraints as its optimal solution.
    C. Is always a maximization problem.
    D. Is always a minimization problem.

    Correct Answer: B
500. The **Spearman's Rank Correlation Coefficient** is a measure of:
    A. The strength of the linear relationship.
    B. The strength of the monotonic relationship.
    C. The causation between variables.
    D. The independence of variables.
# Batch 6: Q501–Q600 - Advanced Analytical Techniques & Predictive Modeling

    Correct Answer: B
501. A data scientist is using **Factor Analysis** to reduce the number of variables in a large dataset of customer survey responses. The primary goal of Factor Analysis is to:
    A. Predict a dependent variable.
    B. Group observations into segments.
    C. Identify underlying, unobservable factors that explain the correlations among a set of observed variables.
    D. Classify new observations into predefined categories.

    Correct Answer: B
502. In **Predictive Modeling**, the process of identifying and selecting the most relevant variables for a model is known as:
    A. Feature Scaling
    B. Model Induction
    C. Feature Engineering
    D. Identifying Informative Attributes (Feature Selection)

    Correct Answer: B
503. **Supervised Segmentation** is a technique where:
    A. Observations are grouped based on their similarity without a predefined target variable.
    B. Observations are grouped based on their relationship to a known target variable (e.g., churn, purchase).
    C. The model is trained on unlabeled data.
    D. The model is used for time series forecasting.

    Correct Answer: B
504. A **Decision Tree** model is often described as a **rule-based model** because:
    A. It uses complex mathematical equations.
    B. It creates a set of simple, hierarchical if-then-else rules for classification or prediction.
    C. It requires all input variables to be continuous.
    D. It is a non-parametric test.

    Correct Answer: B
505. **Functional Data Analysis (FDA)** is an advanced analytical technique used to analyze data where the observations are:
    A. Discrete points in time.
    B. Vectors of numerical values.
    C. Functions, curves, or surfaces (e.g., growth curves, spectral data).
    D. Categorical variables.

    Correct Answer: B
506. In **Predictive Modeling**, **Model Induction** refers to the process of:
    A. Collecting the data.
    B. Training the model using the data to learn the relationship between input features and the target variable.
    C. Evaluating the model's performance.
    D. Deploying the model.

    Correct Answer: B
507. A data scientist is tasked with predicting whether a customer will click on an advertisement (a binary outcome). Which type of predictive modeling concept is most relevant?
    A. Regression Modeling
    B. Probability Estimation (Classification)
    C. Time Series Forecasting
    D. Clustering

    Correct Answer: B
508. **Directional Data Analytics** is a specialized field concerned with the analysis of data that are:
    A. Time-series data.
    B. Data that are directions, rotations, or points on a sphere (e.g., wind direction, geological fault lines).
    C. Data that are highly skewed.
    D. Data that are non-linear.

    Correct Answer: B
509. The primary output of a **Supervised Segmentation** model is:
    A. A set of clusters with no interpretation.
    B. A set of segments that are distinct in terms of the target variable (e.g., high-value vs. low-value customers).
    C. A single prediction for a continuous variable.
    D. A correlation matrix.

    Correct Answer: C
510. **Factor Analysis** is primarily a technique for:
    A. Prediction.
    B. Classification.
    C. Dimensionality Reduction.
    D. Time Series Analysis.

    Correct Answer: B
511. In the context of **Predictive Modeling**, an **Informative Attribute** is a feature that:
    A. Is easy to collect.
    B. Has a strong, measurable relationship with the target variable.
    C. Is highly correlated with other features.
    D. Is always continuous.

    Correct Answer: C
512. **Visualization of Segmentation Results** is crucial because it helps:
    A. Reduce the dimensionality of the data.
    B. Interpret the characteristics of the segments and communicate the findings to stakeholders.
    C. Train the predictive model.
    D. Calculate the probability of the outcome.

    Correct Answer: B
513. A **Decision Tree** is a non-parametric supervised learning method used for:
    A. Clustering only.
    B. Regression only.
    C. Both Classification and Regression.
    D. Time series forecasting only.

    Correct Answer: B
514. **Functional Data Analysis (FDA)** is often used in fields like:
    A. Finance for stock price prediction.
    B. Image processing for feature extraction.
    C. Biometrics for analyzing growth curves or gait patterns.
    D. Text mining for sentiment analysis.

    Correct Answer: B
515. In **Predictive Modeling**, the term **Prediction** refers to:
    A. The process of training the model.
    B. The output of the model for a new, unseen observation.
    C. The evaluation of the model's performance.
    D. The selection of informative attributes.

    Correct Answer: B
516. **Factor Analysis** assumes that the observed variables are linear combinations of:
    A. Independent variables.
    B. Latent (unobserved) factors and error terms.
    C. Categorical variables.
    D. Time series data.

    Correct Answer: A
517. **Supervised Segmentation** is distinct from **Unsupervised Segmentation (Clustering)** because:
    A. Supervised segmentation uses a target variable to guide the grouping.
    B. Unsupervised segmentation uses a target variable to guide the grouping.
    C. Supervised segmentation only uses continuous variables.
    D. Unsupervised segmentation is a form of prediction.

    Correct Answer: C
518. A key advantage of using **Decision Trees** as rule-based models is their:
    A. High computational complexity.
    B. Lack of interpretability.
    C. High interpretability and ease of understanding by non-technical users.
    D. Requirement for linear relationships.

    Correct Answer: C
519. **Probability Estimation** in predictive modeling is the process of:
    A. Predicting the exact value of a continuous variable.
    B. Predicting the likelihood (probability) of a categorical outcome (e.g., the probability of a customer churning).
    C. Calculating the correlation coefficient.
    D. Performing factor analysis.

    Correct Answer: B
520. **Directional Data Analytics** requires specialized statistical methods because standard Euclidean statistics are not appropriate for data that are:
    A. Linear.
    B. Circular or spherical.
    C. Normally distributed.
    D. Discrete.

    Correct Answer: B
521. In **Predictive Modeling**, the goal of **Identifying Informative Attributes** is to:
    A. Maximize the model's complexity.
    B. Improve model performance and interpretability by focusing on the most relevant features.
    C. Convert continuous variables to categorical.
    D. Perform unsupervised clustering.

    Correct Answer: B
522. **Functional Data Analysis (FDA)** treats a set of discrete measurements (e.g., temperature readings over a day) as a single:
    A. Vector.
    B. Scalar.
    C. Function.
    D. Matrix.

    Correct Answer: B
523. **Factor Analysis** is often used as a precursor to **Regression Analysis** to:
    A. Increase the number of independent variables.
    B. Address multicollinearity by replacing highly correlated observed variables with a smaller set of uncorrelated factors.
    C. Convert the dependent variable to a categorical type.
    D. Perform time series forecasting.

    Correct Answer: C
524. **Supervised Segmentation** models are typically evaluated based on their ability to:
    A. Minimize the within-cluster variance.
    B. Maximize the difference in the target variable across the segments.
    C. Predict the next time step.
    D. Reduce the dimensionality of the data.

    Correct Answer: B
525. A **Decision Tree** model makes a prediction by:
    A. Calculating the weighted average of all input features.
    B. Following a path from the root node to a leaf node based on the values of the input features.
    C. Solving a system of linear equations.
    D. Calculating the probability density function.

    Correct Answer: B
526. **Probability Estimation** models (e.g., Logistic Regression) output a value between 0 and 1, which represents:
    A. The predicted value of the continuous variable.
    B. The confidence in the prediction.
    C. The likelihood of the positive class.
    D. The standard error of the estimate.

    Correct Answer: B
527. **Directional Data Analytics** is particularly relevant in which field?
    A. Financial accounting.
    B. Meteorology (wind direction) and navigation.
    C. Text mining.
    D. Image recognition.

    Correct Answer: C
528. In **Predictive Modeling**, the term **Model Induction** is synonymous with:
    A. Data cleaning.
    B. Model training.
    C. Model deployment.
    D. Feature selection.

    Correct Answer: C
529. **Factor Analysis** is a technique that is part of the broader category of:
    A. Supervised Learning.
    B. Unsupervised Learning.
    C. Reinforcement Learning.
    D. Time Series Analysis.

    Correct Answer: D
530. **Visualization of Segmentation Results** can involve using which type of plot to show the distribution of key features within each segment?
    A. Scatter plot.
    B. Box plots or bar charts.
    C. Time series plot.
    D. Correlation matrix.

    Correct Answer: B
531. A **Decision Tree** uses a series of **splits** based on the values of the features. The goal of each split is to:
    A. Maximize the purity (homogeneity) of the resulting child nodes with respect to the target variable.
    B. Minimize the number of nodes.
    C. Maximize the depth of the tree.
    D. Ensure all features are used.

    Correct Answer: B
532. **Functional Data Analysis (FDA)** is useful for analyzing data where the underlying phenomenon is:
    A. Static.
    B. Dynamic and evolves over a continuum (e.g., time, space).
    C. Categorical.
    D. Discrete.

    Correct Answer: B
533. In **Predictive Modeling**, the concept of **Overfitting** occurs when a model:
    A. Is too simple and cannot capture the underlying pattern.
    B. Learns the training data too well, including the noise, and performs poorly on new, unseen data.
    C. Has too few features.
    D. Is trained on too little data.

    Correct Answer: B
534. **Factor Analysis** can be used to transform a set of observed variables into a smaller set of:
    A. Highly correlated variables.
    B. Uncorrelated factors.
    C. Categorical variables.
    D. Dependent variables.

    Correct Answer: B
535. **Supervised Segmentation** is a form of **Classification** where the goal is to:
    A. Predict a continuous value.
    B. Assign an observation to one of several predefined classes (segments).
    C. Group observations without a target variable.
    D. Reduce the number of features.

    Correct Answer: C
536. **Probability Estimation** is a key component of which type of predictive model?
    A. Linear Regression
    B. Logistic Regression
    C. K-Means Clustering
    D. Principal Component Analysis

    Correct Answer: B
537. **Directional Data Analytics** is concerned with the fact that the mean of two directions (e.g., 1 degree and 359 degrees) is not:
    A. 180 degrees.
    B. 0 degrees.
    C. 359 degrees.
    D. 1 degree.

    Correct Answer: B
538. In **Predictive Modeling**, the term **Prediction** is often used interchangeably with:
    A. Training.
    B. Inference.
    C. Evaluation.
    D. Feature selection.

    Correct Answer: B
539. **Factor Analysis** is often used in **Psychometrics** to:
    A. Predict a person's score on a test.
    B. Identify the latent traits (e.g., intelligence, personality) that underlie a set of test scores.
    C. Classify people into groups.
    D. Perform time series analysis.

    Correct Answer: B
540. **Visualization of Segmentation Results** often involves plotting the segments in a reduced dimensional space, such as using:
    A. A time series plot.
    B. A scatter plot of the first two principal components.
    C. A histogram.
    D. A box plot.

    Correct Answer: A
541. A **Decision Tree** is prone to **Overfitting**. A common technique to mitigate this is:
    A. Increasing the number of features.
    B. Pruning the tree (removing branches that have little predictive power).
    C. Using a smaller training set.
    D. Converting the target variable to continuous.

    Correct Answer: B
542. **Functional Data Analysis (FDA)** requires that the data be:
    A. Independent and identically distributed.
    B. Measured at discrete, equally spaced time points.
    C. Represented as a set of functions.
    D. Normally distributed.

    Correct Answer: B
543. In **Predictive Modeling**, the **Training Set** is used for:
    A. Evaluating the final model.
    B. Selecting the most informative attributes.
    C. Inducing (training) the model.
    D. Making predictions on new data.

    Correct Answer: B
544. **Factor Analysis** is an example of a **Multivariate Statistical Technique** because it:
    A. Deals with a single variable.
    B. Deals with the relationships among multiple variables simultaneously.
    C. Only uses categorical variables.
    D. Only uses continuous variables.

    Correct Answer: B
545. **Supervised Segmentation** is a technique that can be used to:
    A. Predict the next time step in a series.
    B. Create customer segments that are maximally different in terms of their likelihood to churn.
    C. Reduce the number of features in a dataset.
    D. Perform hypothesis testing.

    Correct Answer: B
546. **Probability Estimation** is a key step in which type of analytical framework?
    A. Descriptive Analytics
    B. Inferential Statistics
    C. Decision Analytics (for evaluating classifiers)
    D. Time Series Analysis

    Correct Answer: A
547. **Directional Data Analytics** is often used in conjunction with which type of coordinate system?
    A. Cartesian coordinates.
    B. Polar or spherical coordinates.
    C. Rectangular coordinates.
    D. Logarithmic coordinates.

    Correct Answer: B
548. In **Predictive Modeling**, the **Test Set** is used for:
    A. Training the model.
    B. Evaluating the model's generalization performance on unseen data.
    C. Feature selection.
    D. Data cleaning.

    Correct Answer: D
549. **Factor Analysis** is used to determine the minimum number of factors needed to account for a specified proportion of the:
    A. Mean of the variables.
    B. Variance of the variables.
    C. Correlation of the variables.
    D. Sample size.

    Correct Answer: B
550. **Visualization of Segmentation Results** helps to ensure that the segments are:
    A. Statistically independent.
    B. Meaningful and actionable from a business perspective.
    C. Perfectly linear.
    D. Normally distributed.

    Correct Answer: B
551. A **Decision Tree** is a **non-linear** model, meaning it can capture:
    A. Only linear relationships.
    B. Complex, non-linear relationships between features and the target variable.
    C. Only categorical relationships.
    D. Only continuous relationships.

    Correct Answer: B
552. **Functional Data Analysis (FDA)** is used to analyze data where the independent variable is often:
    A. Discrete.
    B. Continuous (e.g., time, wavelength).
    C. Categorical.
    D. Binary.

    Correct Answer: B
553. In **Predictive Modeling**, the **Validation Set** is often used for:
    A. Final model evaluation.
    B. Hyperparameter tuning and model selection.
    C. Initial data cleaning.
    D. Feature engineering.

    Correct Answer: B
554. **Factor Analysis** is often contrasted with **Principal Component Analysis (PCA)**. A key difference is that Factor Analysis:
    A. Assumes the existence of latent factors that cause the observed correlations.
    B. Only deals with continuous variables.
    C. Is a supervised learning technique.
    D. Does not reduce dimensionality.

    Correct Answer: C
555. **Supervised Segmentation** is a technique that combines elements of:
    A. Descriptive and Prescriptive Analytics.
    B. Clustering and Classification.
    C. Time Series and Regression.
    D. Factor Analysis and ANOVA.

    Correct Answer: B
556. **Probability Estimation** models are essential for **Decision Analytics** because they allow for:
    A. Deterministic predictions.
    B. Evaluating the trade-off between the cost of an action and the probability of a positive outcome.
    C. Reducing the dimensionality of the data.
    D. Performing hypothesis testing.

    Correct Answer: B
557. **Directional Data Analytics** uses specialized measures of central tendency, such as the:
    A. Arithmetic mean.
    B. Circular mean (or mean direction).
    C. Median.
    D. Mode.

    Correct Answer: B
558. In **Predictive Modeling**, the concept of **Bias-Variance Tradeoff** suggests that:
    A. Increasing model complexity always improves performance.
    B. A model with high bias is often overfit.
    C. There is a balance between a model's ability to fit the training data (low bias) and its ability to generalize to new data (low variance).
    D. All models must have zero bias.

    Correct Answer: B
559. **Factor Analysis** is used to achieve **Parsimony**, which means:
    A. Making the model more complex.
    B. Explaining the maximum amount of variance with the minimum number of factors.
    C. Ensuring the factors are highly correlated.
    D. Converting the data to a normal distribution.

    Correct Answer: B
560. **Visualization of Segmentation Results** is a form of **Diagnostic Analytics** because it helps to:
    A. Predict future segment behavior.
    B. Understand *why* the segments are different.
    C. Prescribe actions for each segment.
    D. Perform time series forecasting.

    Correct Answer: B
561. A **Decision Tree** model is typically built using a **greedy algorithm** that:
    A. Searches for the globally optimal tree structure.
    B. Makes the locally optimal split at each node.
    C. Requires all features to be continuous.
    D. Uses a fixed number of splits.

    Correct Answer: B
562. **Functional Data Analysis (FDA)** is often used to analyze data from:
    A. Surveys with categorical responses.
    B. High-frequency sensors (e.g., EEG, weather data).
    C. Financial statements.
    D. Social media text.

    Correct Answer: B
563. In **Predictive Modeling**, the term **Underfitting** occurs when a model:
    A. Is too complex and learns the noise in the data.
    B. Is too simple and cannot capture the underlying pattern in the data.
    C. Has too many features.
    D. Is trained on too much data.

    Correct Answer: B
564. **Factor Analysis** can be used to create **Composite Scores** by:
    A. Averaging the raw scores of all observed variables.
    B. Weighting the observed variables based on their factor loadings.
    C. Using the mean of the latent factors.
    D. Calculating the standard deviation of the factors.

    Correct Answer: A
565. **Supervised Segmentation** is a technique that is often used in **Customer Relationship Management (CRM)** to:
    A. Reduce the number of features in the customer database.
    B. Identify high-value customers who are likely to churn.
    C. Predict the next time step in a sales series.
    D. Perform hypothesis testing.

    Correct Answer: B
566. **Probability Estimation** models are evaluated using metrics like:
    A. Mean Squared Error (MSE).
    B. R-squared.
    C. Area Under the ROC Curve (AUC) or Log Loss.
    D. Standard Deviation.

    Correct Answer: D
567. **Directional Data Analytics** uses specialized measures of dispersion, such as the:
    A. Standard deviation.
    B. Circular variance.
    C. Range.
    D. Interquartile range.

    Correct Answer: A
568. In **Predictive Modeling**, **Cross-Validation** is a technique used to:
    A. Train the model on all available data.
    B. Estimate the model's generalization performance and prevent overfitting.
    C. Select the most informative attributes.
    D. Clean the data.

    Correct Answer: B
569. **Factor Analysis** is a technique that is often used in **Marketing Research** to:
    A. Predict customer churn.
    B. Identify the key dimensions of customer satisfaction from a set of survey questions.
    C. Segment customers based on demographics.
    D. Forecast sales.

    Correct Answer: B
570. **Visualization of Segmentation Results** is a key step in ensuring the segments are:
    A. Mutually exclusive.
    B. Exhaustive.
    C. Both mutually exclusive and exhaustive.
    D. Actionable.

    Correct Answer: B
571. A **Decision Tree** is a **white-box model**, meaning its decision-making process is:
    A. Complex and opaque.
    B. Simple and transparent (easy to interpret).
    C. Always correct.
    D. Always incorrect.

    Correct Answer: B
572. **Functional Data Analysis (FDA)** is used to analyze data where the variability is often seen in the:
    A. Mean of the functions.
    B. Shape and magnitude of the functions.
    C. Number of functions.
    D. Standard deviation of the functions.

    Correct Answer: B
573. In **Predictive Modeling**, the concept of **Generalization** refers to a model's ability to:
    A. Fit the training data perfectly.
    B. Perform well on new, unseen data.
    C. Use all available features.
    D. Be easily interpreted.

    Correct Answer: A
574. **Factor Analysis** is used to address the problem of **Multicollinearity** by:
    A. Combining highly correlated variables into a single factor.
    B. Removing all correlated variables.
    C. Increasing the number of variables.
    D. Converting the variables to categorical.

    Correct Answer: D
575. **Supervised Segmentation** is a technique that is often used to create:
    A. Customer clusters based on purchase history only.
    B. Customer segments that are predictive of a future outcome (e.g., high-risk, low-risk).
    C. A single prediction for a continuous variable.
    D. A time series forecast.

    Correct Answer: A
576. **Probability Estimation** models are often used in **Credit Scoring** to predict the:
    A. Exact amount of the loan.
    B. Probability of default.
    C. Time until the next payment.
    D. Correlation between income and debt.

    Correct Answer: B
577. **Directional Data Analytics** is used to analyze data where the values are measured on a:
    A. Linear scale.
    B. Circular scale (e.g., degrees, radians).
    C. Logarithmic scale.
    D. Ratio scale.

    Correct Answer: B
578. In **Predictive Modeling**, the **Feature Space** is the:
    A. Set of all possible target variable values.
    B. Multi-dimensional space defined by the input features.
    C. Set of all possible predictions.
    D. Space where the model is deployed.

    Correct Answer: B
579. **Factor Analysis** is used to determine the **Factor Loadings**, which represent:
    A. The correlation between the observed variables and the latent factors.
    B. The mean of the observed variables.
    C. The variance of the observed variables.
    D. The number of factors.

    Correct Answer: B
580. **Visualization of Segmentation Results** can involve using a **Profile Plot** to show:
    A. The time series trend of each segment.
    B. The average values of key features for each segment.
    C. The correlation matrix of the features.
    D. The decision tree structure.

    Correct Answer: B
581. A **Decision Tree** is a **non-parametric** model, meaning it:
    A. Makes assumptions about the functional form of the relationship between features and the target.
    B. Does not make assumptions about the functional form of the relationship.
    C. Requires all features to be continuous.
    D. Requires all features to be categorical.

    Correct Answer: B
582. **Functional Data Analysis (FDA)** is used to analyze data where the observations are:
    A. Independent.
    B. Dependent (e.g., successive points on a curve are related).
    C. Normally distributed.
    D. Linearly related.

    Correct Answer: B
583. In **Predictive Modeling**, the **Confusion Matrix** is a tool used for:
    A. Regression model evaluation.
    B. Classification model evaluation.
    C. Clustering model evaluation.
    D. Dimensionality reduction.

    Correct Answer: D
584. **Factor Analysis** is a technique that is often used to simplify the interpretation of:
    A. A single variable.
    B. A large number of correlated variables.
    C. A time series.
    D. A categorical variable.

    Correct Answer: B
585. **Supervised Segmentation** is a technique that is often used to:
    A. Predict a continuous value.
    B. Inform targeted marketing campaigns.
    C. Reduce the number of features.
    D. Perform hypothesis testing.

    Correct Answer: B
586. **Probability Estimation** models are essential for calculating the **Expected Value** of a decision, which is a key concept in:
    A. Descriptive Analytics.
    B. Decision Analytics.
    C. Inferential Statistics.
    D. Time Series Analysis.

    Correct Answer: B
587. **Directional Data Analytics** is used to analyze data that is inherently:
    A. Linear.
    B. Periodic.
    C. Continuous.
    D. Discrete.

    Correct Answer: B
588. In **Predictive Modeling**, the **Feature Vector** is the:
    A. Target variable.
    B. Set of input features for a single observation.
    C. Set of all possible predictions.
    D. Set of all possible target variable values.

    Correct Answer: B
589. **Factor Analysis** is used to identify the **Factor Scores**, which represent:
    A. The correlation between the observed variables and the latent factors.
    B. The value of the latent factors for each observation.
    C. The mean of the observed variables.
    D. The variance of the observed variables.

    Correct Answer: B
590. **Visualization of Segmentation Results** is a key step in ensuring the segments are:
    A. Statistically significant.
    B. Internally homogeneous and externally heterogeneous.
    C. Perfectly linear.
    D. Normally distributed.

    Correct Answer: C
591. A **Decision Tree** is a **hierarchical** model, meaning it:
    A. Uses a single, complex rule.
    B. Organizes the decision rules in a tree-like structure.
    C. Requires all features to be continuous.
    D. Requires all features to be categorical.

    Correct Answer: D
592. **Functional Data Analysis (FDA)** is used to analyze data where the observations are:
    A. Independent and identically distributed.
    B. Curves or functions.
    C. Categorical variables.
    D. Discrete points in time.

    Correct Answer: B
593. In **Predictive Modeling**, the **ROC Curve** is a graphical tool used to evaluate the performance of:
    A. Regression models.
    B. Classification models (Probability Estimation).
    C. Clustering models.
    D. Dimensionality reduction.

    Correct Answer: B
594. **Factor Analysis** is used to determine the **Communality** of a variable, which is the:
    A. Proportion of the variable's variance that is explained by the common factors.
    B. Proportion of the variable's variance that is unique.
    C. Correlation between the variable and the latent factors.
    D. Mean of the variable.

    Correct Answer: B
595. **Supervised Segmentation** is a technique that is often used to:
    A. Predict a continuous value.
    B. Create segments that are maximally different in terms of their likelihood to purchase a product.
    C. Reduce the number of features.
    D. Perform hypothesis testing.

    Correct Answer: B
596. **Probability Estimation** models are essential for calculating the **Lift** of a marketing campaign, which is a key concept in:
    A. Descriptive Analytics.
    B. Decision Analytics.
    C. Inferential Statistics.
    D. Time Series Analysis.

    Correct Answer: C
597. **Directional Data Analytics** is used to analyze data where the values are measured on a:
    A. Linear scale.
    B. Circular scale.
    C. Logarithmic scale.
    D. Ratio scale.

    Correct Answer: B
598. In **Predictive Modeling**, the **Feature Importance** score is a measure of:
    A. The complexity of the model.
    B. The contribution of each feature to the model's prediction.
    C. The accuracy of the model.
    D. The bias of the model.

    Correct Answer: C
599. **Factor Analysis** is used to determine the **Uniqueness** of a variable, which is the:
    A. Proportion of the variable's variance that is explained by the common factors.
    B. Proportion of the variable's variance that is unique (not explained by the common factors).
    C. Correlation between the variable and the latent factors.
    D. Mean of the variable.

    Correct Answer: A
600. **Visualization of Segmentation Results** is a key step in ensuring the segments are:
    A. Statistically significant.
    B. Actionable.
    C. Perfectly linear.
    D. Normally distributed.
# Batch 7: Q601–Q700 - Decision Analytics and Probabilistic Reasoning

    Correct Answer: C
601. In **Decision Analytics**, the process of **Evaluating Classifiers** involves:
    A. Calculating the mean and standard deviation of the data.
    B. Assessing the performance of a predictive model (e.g., a churn model) using metrics like accuracy, precision, and recall.
    C. Performing factor analysis to reduce dimensionality.
    D. Solving a linear optimization problem.

    Correct Answer: B
602. **Probabilistic Reasoning under Uncertainty** is a core concept in advanced analytics. Which theorem is fundamental to updating beliefs (probabilities) in light of new evidence?
    A. Central Limit Theorem
    B. Law of Large Numbers
    C. Bayes' Theorem
    D. Chebyshev's Theorem

    Correct Answer: B
603. A **Baseline Model** in predictive modeling is typically:
    A. The most complex model that can be built.
    B. A simple, often non-statistical model (e.g., predicting the majority class or the mean value) used as a minimum performance benchmark.
    C. A model that perfectly predicts the outcome.
    D. A model that uses all available features.

    Correct Answer: B
604. The **Performance Evaluation Metric** known as **Accuracy** is calculated as:
    A. True Positives / (True Positives + False Positives)
    B. True Positives / (True Positives + False Negatives)
    C. (True Positives + True Negatives) / Total Observations
    D. True Negatives / (True Negatives + False Positives)

    Correct Answer: C
605. **Evidence Combination using Bayes' Rule** is a process where:
    A. All evidence is treated as equally important.
    B. Multiple pieces of evidence are sequentially incorporated to update the posterior probability of a hypothesis.
    C. The prior probability is always set to 0.5.
    D. The likelihood of the evidence is ignored.

    Correct Answer: B
606. A key **Business Implication of Analytical Investments** is that they should:
    A. Only focus on reducing costs.
    B. Be directly linked to measurable improvements in business outcomes (e.g., increased revenue, reduced risk, improved efficiency).
    C. Only use descriptive statistics.
    D. Always result in a perfect predictive model.

    Correct Answer: C
607. In the context of a binary classifier, a **False Positive** occurs when:
    A. The model correctly predicts the positive class.
    B. The model correctly predicts the negative class.
    C. The model incorrectly predicts the positive class (Type I Error in the context of the prediction).
    D. The model incorrectly predicts the negative class.

    Correct Answer: B
608. The **Analytical Framework** known as **CRISP-DM (Cross-Industry Standard Process for Data Mining)** is a methodology that outlines the steps for:
    A. Solving a linear optimization problem.
    B. Conducting a data mining project from business understanding to deployment.
    C. Calculating the correlation coefficient.
    D. Performing a t-test.

    Correct Answer: A
609. **Probabilistic Reasoning** is essential in decision-making because it allows for:
    A. Ignoring uncertainty.
    B. Making decisions based on the expected value of outcomes under uncertainty.
    C. Converting all variables to continuous.
    D. Assuming all events are independent.

    Correct Answer: B
610. The **Performance Evaluation Metric** known as **Precision** is most critical when the cost of a **False Positive** is high. It is calculated as:
    A. True Positives / (True Positives + False Positives)
    B. True Positives / (True Positives + False Negatives)
    C. (True Positives + True Negatives) / Total Observations
    D. True Negatives / (True Negatives + False Positives)

    Correct Answer: B
611. A **Baseline Model** for a classification problem where 90% of the data belongs to Class A would be to:
    A. Randomly guess the class.
    B. Always predict Class B.
    C. Always predict Class A.
    D. Use a complex neural network.

    Correct Answer: A
612. **Decision Analytics** is the discipline that uses:
    A. Only descriptive statistics to summarize data.
    B. Only prescriptive analytics to recommend actions.
    C. Data-driven models and analysis to inform and improve decision-making.
    D. Only qualitative data.

    Correct Answer: A
613. The **Area Under the ROC Curve (AUC)** is a common metric for evaluating classifiers. An AUC of 0.5 indicates:
    A. A perfect classifier.
    B. A classifier that performs no better than random guessing.
    C. A classifier that is perfectly wrong.
    D. A classifier with high precision.

    Correct Answer: B
614. **Probabilistic Reasoning under Uncertainty** often involves the use of **Bayesian Networks**, which are graphical models that represent:
    A. Linear relationships between continuous variables.
    B. Probabilistic relationships and conditional dependencies among a set of variables.
    C. The structure of a decision tree.
    D. The correlation matrix of the data.

    Correct Answer: B
615. The **Performance Evaluation Metric** known as **Recall (Sensitivity)** is most critical when the cost of a **False Negative** is high. It is calculated as:
    A. True Positives / (True Positives + False Positives)
    B. True Positives / (True Positives + False Negatives)
    C. (True Positives + True Negatives) / Total Observations
    D. True Negatives / (True Negatives + False Positives)

    Correct Answer: C
616. A key aspect of **Decision Analytics** is the consideration of **Trade-offs**, which involves:
    A. Ignoring all constraints.
    B. Balancing competing objectives (e.g., profit vs. risk, speed vs. accuracy).
    C. Only maximizing the objective function.
    D. Only minimizing the cost.

    Correct Answer: C
617. The **F1-Score** is a performance metric that is the harmonic mean of:
    A. Accuracy and Recall.
    B. Precision and Recall.
    C. True Positives and True Negatives.
    D. False Positives and False Negatives.

    Correct Answer: A
618. **Probabilistic Reasoning** is a key component of which type of analytics?
    A. Descriptive Analytics
    B. Diagnostic Analytics
    C. Predictive Analytics
    D. Prescriptive Analytics

    Correct Answer: A
619. The **Confusion Matrix** for a binary classifier is a table that summarizes:
    A. The correlation between the features.
    B. The performance of the model by showing the counts of True Positives, True Negatives, False Positives, and False Negatives.
    C. The distribution of the target variable.
    D. The feature importance scores.

    Correct Answer: C
620. A **Baseline Model** is essential for evaluating a complex predictive model because it provides:
    A. The maximum achievable performance.
    B. A lower bound on acceptable performance.
    C. The optimal set of features.
    D. The best possible prediction.

    Correct Answer: B
621. **Decision Analytics** often uses **Utility Theory** to:
    A. Calculate the expected monetary value of an outcome.
    B. Incorporate the decision-maker's subjective preferences and risk attitude into the decision process.
    C. Solve linear optimization problems.
    D. Perform hypothesis testing.

    Correct Answer: A
622. **Probabilistic Reasoning** is used to model situations where the outcome is:
    A. Deterministic.
    B. Uncertain or random.
    C. Always continuous.
    D. Always discrete.

    Correct Answer: A
623. The **Performance Evaluation Metric** known as **Specificity** is calculated as:
    A. True Positives / (True Positives + False Positives)
    B. True Positives / (True Positives + False Negatives)
    C. True Negatives / (True Negatives + False Positives)
    D. (True Positives + True Negatives) / Total Observations

    Correct Answer: A
624. **Evidence Combination using Bayes' Rule** is a process that leads to the calculation of the:
    A. Prior probability.
    B. Likelihood.
    C. Posterior probability.
    D. Marginal likelihood.

    Correct Answer: C
625. A key **Business Implication of Analytical Investments** is the shift from **Intuition-based** to **Data-driven** decision-making, which requires:
    A. Ignoring the experience of managers.
    B. Integrating analytical insights into the organizational culture and processes.
    C. Only using descriptive statistics.
    D. Always achieving 100% accuracy.

    Correct Answer: B
626. In the context of a binary classifier, a **False Negative** occurs when:
    A. The model correctly predicts the positive class.
    B. The model correctly predicts the negative class.
    C. The model incorrectly predicts the positive class.
    D. The model incorrectly predicts the negative class (Type II Error in the context of the prediction).

    Correct Answer: B
627. **Decision Analytics** often involves the use of **Decision Trees** to:
    A. Calculate the correlation coefficient.
    B. Visually map out the possible outcomes of a sequence of decisions and chance events.
    C. Solve linear optimization problems.
    D. Perform factor analysis.

    Correct Answer: B
628. **Probabilistic Reasoning** is used to calculate the **Expected Value of Information (EVI)**, which is the:
    A. Cost of collecting the information.
    B. Maximum amount a decision-maker should be willing to pay for additional information.
    C. Accuracy of the predictive model.
    D. Correlation between the information and the outcome.

    Correct Answer: A
629. The **Performance Evaluation Metric** known as **ROC Curve** plots:
    A. Precision against Recall.
    B. True Positive Rate (Recall) against False Positive Rate (1 - Specificity).
    C. Accuracy against the number of features.
    D. True Positives against False Positives.

    Correct Answer: B
630. A **Baseline Model** for a regression problem (predicting a continuous value) would typically be to:
    A. Always predict the mode of the target variable.
    B. Always predict the mean of the target variable.
    C. Always predict the maximum value.
    D. Use a complex neural network.

    Correct Answer: C
631. **Decision Analytics** is closely related to the field of **Operations Research** because both focus on:
    A. Descriptive statistics.
    B. Using mathematical models and analytical techniques to find optimal or near-optimal solutions to complex decision problems.
    C. Probabilistic reasoning only.
    D. Time series forecasting.

    Correct Answer: C
632. **Probabilistic Reasoning** is used to calculate the **Posterior Probability**, which is the probability of a hypothesis:
    A. Before any evidence is considered.
    B. After all evidence is considered.
    C. Assuming the evidence is false.
    D. Assuming the hypothesis is false.

    Correct Answer: A
633. The **Performance Evaluation Metric** known as **True Positive Rate (TPR)** is equivalent to:
    A. Precision.
    B. Specificity.
    C. Recall (Sensitivity).
    D. Accuracy.

    Correct Answer: B
634. **Evidence Combination using Bayes' Rule** is a process that is often used in:
    A. Linear Regression.
    B. Bayesian Filtering (e.g., spam detection).
    C. K-Means Clustering.
    D. Principal Component Analysis.

    Correct Answer: B
635. A key **Business Implication of Analytical Investments** is the ability to move from **Reactive** to **Proactive** decision-making, which is enabled by:
    A. Descriptive Analytics.
    B. Predictive and Prescriptive Analytics.
    C. Hypothesis Testing.
    D. Data Cleaning.

    Correct Answer: B
636. In the context of a binary classifier, a **True Negative** occurs when:
    A. The model correctly predicts the positive class.
    B. The model correctly predicts the negative class.
    C. The model incorrectly predicts the positive class.
    D. The model incorrectly predicts the negative class.

    Correct Answer: B
637. **Decision Analytics** often uses **Simulation** to:
    A. Find the exact analytical solution.
    B. Model the uncertainty and complexity of a decision problem and estimate the distribution of outcomes.
    C. Solve linear optimization problems.
    D. Perform factor analysis.

    Correct Answer: C
638. **Probabilistic Reasoning** is used to calculate the **Likelihood**, which is the probability of the:
    A. Hypothesis given the evidence.
    B. Evidence given the hypothesis.
    C. Hypothesis before the evidence.
    D. Evidence before the hypothesis.

    Correct Answer: B
639. The **Performance Evaluation Metric** known as **False Positive Rate (FPR)** is calculated as:
    A. False Positives / (False Positives + True Negatives)
    B. False Positives / (False Positives + True Positives)
    C. False Negatives / (False Negatives + True Positives)
    D. False Negatives / (False Negatives + True Negatives)

    Correct Answer: A
640. A **Baseline Model** is particularly important when the dataset is:
    A. Perfectly balanced.
    B. Highly imbalanced (e.g., 99% of observations belong to one class).
    C. Very small.
    D. Perfectly linear.

    Correct Answer: B
641. **Decision Analytics** often uses **Sensitivity Analysis** to:
    A. Find the optimal solution.
    B. Determine how the optimal decision changes as the input parameters (e.g., probabilities, costs) change.
    C. Solve linear optimization problems.
    D. Perform hypothesis testing.

    Correct Answer: B
642. **Probabilistic Reasoning** is used to calculate the **Prior Probability**, which is the probability of a hypothesis:
    A. After all evidence is considered.
    B. Before any evidence is considered.
    C. Assuming the evidence is false.
    D. Assuming the hypothesis is false.

    Correct Answer: B
643. The **Performance Evaluation Metric** known as **False Negative Rate (FNR)** is calculated as:
    A. False Negatives / (False Negatives + True Positives)
    B. False Negatives / (False Negatives + True Negatives)
    C. False Positives / (False Positives + True Negatives)
    D. False Positives / (False Positives + True Positives)

    Correct Answer: B
644. **Evidence Combination using Bayes' Rule** is a process that is often used in **Sequential Decision Making** because it allows for:
    A. Ignoring the order of evidence.
    B. Updating the belief state after each new piece of evidence is observed.
    C. Assuming all evidence is independent.
    D. Calculating the correlation coefficient.

    Correct Answer: B
645. A key **Business Implication of Analytical Investments** is the ability to **Personalize** customer interactions, which is enabled by:
    A. Descriptive Analytics.
    B. Segmentation and Predictive Modeling.
    C. Hypothesis Testing.
    D. Data Cleaning.

    Correct Answer: C
646. In the context of a binary classifier, a **True Positive** occurs when:
    A. The model correctly predicts the positive class.
    B. The model correctly predicts the negative class.
    C. The model incorrectly predicts the positive class.
    D. The model incorrectly predicts the negative class.

    Correct Answer: B
647. **Decision Analytics** often uses **Expected Monetary Value (EMV)** as a criterion for:
    A. Minimizing risk.
    B. Maximizing the average payoff of a decision.
    C. Solving linear optimization problems.
    D. Performing factor analysis.

    Correct Answer: C
648. **Probabilistic Reasoning** is used to calculate the **Marginal Likelihood (Evidence)**, which is the probability of the:
    A. Hypothesis given the evidence.
    B. Evidence given the hypothesis.
    C. Hypothesis before the evidence.
    D. Evidence.

    Correct Answer: B
649. The **Performance Evaluation Metric** known as **Area Under the Precision-Recall Curve (AUPRC)** is a common metric for evaluating classifiers, particularly when the dataset is:
    A. Perfectly balanced.
    B. Highly imbalanced.
    C. Very small.
    D. Perfectly linear.

    Correct Answer: B
650. A **Baseline Model** is a crucial part of the **Analytical Framework** because it helps to:
    A. Determine the complexity of the final model.
    B. Ensure that the final model is adding value beyond a trivial solution.
    C. Solve the linear optimization problem.
    D. Perform hypothesis testing.

    Correct Answer: B
651. **Decision Analytics** often uses **Expected Utility** as a criterion for:
    A. Maximizing the average payoff.
    B. Incorporating the decision-maker's risk attitude into the decision.
    C. Solving linear optimization problems.
    D. Performing factor analysis.

    Correct Answer: B
652. **Probabilistic Reasoning** is used to calculate the **Odds Ratio**, which is the ratio of:
    A. Prior probability to posterior probability.
    B. Likelihood of the evidence under the hypothesis to the likelihood of the evidence under the alternative.
    C. True Positives to False Positives.
    D. True Negatives to False Negatives.

    Correct Answer: A
653. The **Performance Evaluation Metric** known as **Matthews Correlation Coefficient (MCC)** is a single-value metric that is considered a balanced measure for:
    A. Regression models.
    B. Classification models, even on imbalanced data.
    C. Clustering models.
    D. Dimensionality reduction.

    Correct Answer: A
654. **Evidence Combination using Bayes' Rule** is a process that is often used in **Medical Diagnosis** to:
    A. Calculate the correlation between symptoms.
    B. Update the probability of a disease given the results of a test.
    C. Solve a linear optimization problem.
    D. Perform factor analysis.

    Correct Answer: B
655. A key **Business Implication of Analytical Investments** is the ability to **Optimize** business processes, which is enabled by:
    A. Descriptive Analytics.
    B. Prescriptive Analytics.
    C. Hypothesis Testing.
    D. Data Cleaning.

    Correct Answer: B
656. In the context of a binary classifier, the **Confusion Matrix** is a table that has:
    A. 2 rows and 1 column.
    B. 1 row and 2 columns.
    C. 2 rows and 2 columns.
    D. $n$ rows and $m$ columns.

    Correct Answer: A
657. **Decision Analytics** often uses **Decision Trees** to:
    A. Calculate the correlation coefficient.
    B. Determine the sequence of decisions that maximizes the expected payoff.
    C. Solve linear optimization problems.
    D. Perform factor analysis.

    Correct Answer: B
658. **Probabilistic Reasoning** is used to calculate the **Bayes Factor**, which is the ratio of:
    A. Prior probability to posterior probability.
    B. Likelihood of the evidence under the hypothesis to the likelihood of the evidence under the alternative.
    C. True Positives to False Positives.
    D. True Negatives to False Negatives.

    Correct Answer: C
659. The **Performance Evaluation Metric** known as **Cohen's Kappa** is a measure of:
    A. Accuracy.
    B. Agreement between two raters or a classifier and the ground truth, correcting for chance agreement.
    C. Precision.
    D. Recall.

    Correct Answer: B
660. A **Baseline Model** is a model that is:
    A. Always the best performing model.
    B. Used to establish a minimum level of performance.
    C. Always a complex neural network.
    D. Always a linear regression model.

    Correct Answer: A
661. **Decision Analytics** often uses **Expected Value of Perfect Information (EVPI)** to:
    A. Determine the maximum amount a decision-maker should be willing to pay for perfect information.
    B. Calculate the average payoff.
    C. Solve linear optimization problems.
    D. Perform factor analysis.

    Correct Answer: C
662. **Probabilistic Reasoning** is used to calculate the **Posterior Odds**, which is the ratio of:
    A. Prior odds to likelihood ratio.
    B. Prior odds multiplied by the likelihood ratio.
    C. Likelihood ratio to prior odds.
    D. True Positives to False Positives.

    Correct Answer: C
663. The **Performance Evaluation Metric** known as **Receiver Operating Characteristic (ROC) Curve** is a plot of:
    A. Precision vs. Recall.
    B. True Positive Rate vs. False Positive Rate.
    C. Accuracy vs. Specificity.
    D. F1-Score vs. Accuracy.

    Correct Answer: A
664. **Evidence Combination using Bayes' Rule** is a process that is often used in **Machine Learning** for:
    A. Linear Regression.
    B. Naive Bayes Classification.
    C. K-Means Clustering.
    D. Principal Component Analysis.

    Correct Answer: B
665. A key **Business Implication of Analytical Investments** is the ability to **Measure** the impact of decisions, which is enabled by:
    A. Descriptive Analytics.
    B. Performance Evaluation Metrics.
    C. Hypothesis Testing.
    D. Data Cleaning.

    Correct Answer: B
666. In the context of a binary classifier, the **Precision-Recall Trade-off** refers to the fact that:
    A. Increasing precision always increases recall.
    B. Increasing precision often decreases recall, and vice-versa.
    C. Precision and recall are always equal.
    D. Precision and recall are independent.

    Correct Answer: A
667. **Decision Analytics** often uses **Sensitivity Analysis** to:
    A. Find the optimal solution.
    B. Determine the range of input values for which the optimal decision remains unchanged.
    C. Solve linear optimization problems.
    D. Perform factor analysis.

    Correct Answer: B
668. **Probabilistic Reasoning** is used to calculate the **Prior Odds**, which is the ratio of:
    A. Prior probability of the hypothesis to the prior probability of the alternative.
    B. Posterior probability of the hypothesis to the posterior probability of the alternative.
    C. Likelihood of the evidence under the hypothesis to the likelihood of the evidence under the alternative.
    D. True Positives to False Positives.

    Correct Answer: B
669. The **Performance Evaluation Metric** known as **Log Loss (Cross-Entropy)** is a measure of:
    A. Accuracy.
    B. The uncertainty of the predicted probabilities.
    C. Precision.
    D. Recall.

    Correct Answer: A
670. A **Baseline Model** is a model that is:
    A. Always the most complex model.
    B. Used to ensure that the final model is statistically significant.
    C. Used to ensure that the final model is practically significant.
    D. Used to establish a minimum level of performance.

    Correct Answer: C
671. **Decision Analytics** often uses **Expected Value of Sample Information (EVSI)** to:
    A. Determine the maximum amount a decision-maker should be willing to pay for sample information.
    B. Calculate the average payoff.
    C. Solve linear optimization problems.
    D. Perform factor analysis.

    Correct Answer: A
672. **Probabilistic Reasoning** is used to calculate the **Likelihood Ratio**, which is the ratio of:
    A. Prior probability to posterior probability.
    B. Likelihood of the evidence under the hypothesis to the likelihood of the evidence under the alternative.
    C. True Positives to False Positives.
    D. True Negatives to False Negatives.

    Correct Answer: B
673. The **Performance Evaluation Metric** known as **Balanced Accuracy** is a measure of:
    A. Accuracy.
    B. The average of recall and specificity.
    C. Precision.
    D. Recall.

    Correct Answer: A
674. **Evidence Combination using Bayes' Rule** is a process that is often used in **Risk Assessment** to:
    A. Calculate the correlation between risks.
    B. Update the probability of a risk event given new data.
    C. Solve a linear optimization problem.
    D. Perform factor analysis.

    Correct Answer: A
675. A key **Business Implication of Analytical Investments** is the ability to **Automate** decision-making, which is enabled by:
    A. Descriptive Analytics.
    B. Prescriptive Analytics.
    C. Hypothesis Testing.
    D. Data Cleaning.

    Correct Answer: B
676. In the context of a binary classifier, the **Threshold** is the value that determines:
    A. The accuracy of the model.
    B. The point at which the predicted probability is converted into a class prediction (e.g., $\ge 0.5$ is positive).
    C. The number of features used.
    D. The complexity of the model.

    Correct Answer: B
677. **Decision Analytics** often uses **Decision Trees** to:
    A. Calculate the correlation coefficient.
    B. Determine the optimal decision strategy under uncertainty.
    C. Solve linear optimization problems.
    D. Perform factor analysis.

    Correct Answer: B
678. **Probabilistic Reasoning** is used to calculate the **Posterior Probability**, which is the probability of the:
    A. Hypothesis given the evidence.
    B. Evidence given the hypothesis.
    C. Hypothesis before the evidence.
    D. Evidence.

    Correct Answer: A
679. The **Performance Evaluation Metric** known as **Gini Coefficient** is a measure of:
    A. Accuracy.
    B. The inequality of the predicted probabilities.
    C. Precision.
    D. Recall.

    Correct Answer: B
680. A **Baseline Model** is a model that is:
    A. Always the most complex model.
    B. Used to ensure that the final model is statistically significant.
    C. Used to ensure that the final model is practically significant.
    D. Used to establish a minimum level of performance.

    Correct Answer: A
681. **Decision Analytics** often uses **Expected Value of Perfect Information (EVPI)** to:
    A. Determine the maximum amount a decision-maker should be willing to pay for perfect information.
    B. Calculate the average payoff.
    C. Solve linear optimization problems.
    D. Perform factor analysis.

    Correct Answer: B
682. **Probabilistic Reasoning** is used to calculate the **Posterior Odds**, which is the ratio of:
    A. Prior odds to likelihood ratio.
    B. Prior odds multiplied by the likelihood ratio.
    C. Likelihood ratio to prior odds.
    D. True Positives to False Positives.

    Correct Answer: C
683. The **Performance Evaluation Metric** known as **Area Under the ROC Curve (AUC)** is a measure of:
    A. Accuracy.
    B. The ability of the classifier to distinguish between the positive and negative classes.
    C. Precision.
    D. Recall.

    Correct Answer: B
684. **Evidence Combination using Bayes' Rule** is a process that is often used in **Information Fusion** to:
    A. Calculate the correlation between sensors.
    B. Combine information from multiple, independent sources to form a more accurate belief.
    C. Solve a linear optimization problem.
    D. Perform factor analysis.

    Correct Answer: C
685. A key **Business Implication of Analytical Investments** is the ability to **Innovate** new products and services, which is enabled by:
    A. Descriptive Analytics.
    B. Predictive Modeling.
    C. Hypothesis Testing.
    D. Data Cleaning.

    Correct Answer: B
686. In the context of a binary classifier, the **True Negative Rate (TNR)** is equivalent to:
    A. Precision.
    B. Specificity.
    C. Recall.
    D. Accuracy.

    Correct Answer: B
687. **Decision Analytics** often uses **Decision Trees** to:
    A. Calculate the correlation coefficient.
    B. Determine the optimal decision strategy under uncertainty.
    C. Solve linear optimization problems.
    D. Perform factor analysis.

    Correct Answer: B
688. **Probabilistic Reasoning** is used to calculate the **Prior Probability**, which is the probability of a hypothesis:
    A. After all evidence is considered.
    B. Before any evidence is considered.
    C. Assuming the evidence is false.
    D. Assuming the hypothesis is false.

    Correct Answer: B
689. The **Performance Evaluation Metric** known as **Youden's J Statistic** is a measure of:
    A. Accuracy.
    B. The overall performance of a diagnostic test, calculated as Sensitivity + Specificity - 1.
    C. Precision.
    D. Recall.

    Correct Answer: B
690. A **Baseline Model** is a model that is:
    A. Always the most complex model.
    B. Used to ensure that the final model is statistically significant.
    C. Used to ensure that the final model is practically significant.
    D. Used to establish a minimum level of performance.

    Correct Answer: B
691. **Decision Analytics** often uses **Expected Value of Perfect Information (EVPI)** to:
    A. Determine the maximum amount a decision-maker should be willing to pay for perfect information.
    B. Calculate the average payoff.
    C. Solve linear optimization problems.
    D. Perform factor analysis.

    Correct Answer: B
692. **Probabilistic Reasoning** is used to calculate the **Posterior Odds**, which is the ratio of:
    A. Prior odds to likelihood ratio.
    B. Prior odds multiplied by the likelihood ratio.
    C. Likelihood ratio to prior odds.
    D. True Positives to False Positives.

    Correct Answer: B
693. The **Performance Evaluation Metric** known as **Area Under the ROC Curve (AUC)** is a measure of:
    A. Accuracy.
    B. The ability of the classifier to distinguish between the positive and negative classes.
    C. Precision.
    D. Recall.

    Correct Answer: B
694. **Evidence Combination using Bayes' Rule** is a process that is often used in **Spam Filtering** to:
    A. Calculate the correlation between words.
    B. Update the probability that an email is spam given the words it contains.
    C. Solve a linear optimization problem.
    D. Perform factor analysis.

    Correct Answer: C
695. A key **Business Implication of Analytical Investments** is the ability to **Improve Customer Experience**, which is enabled by:
    A. Descriptive Analytics.
    B. Predictive Modeling.
    C. Hypothesis Testing.
    D. Data Cleaning.

    Correct Answer: B
696. In the context of a binary classifier, the **False Positive Rate (FPR)** is equivalent to:
    A. 1 - Precision.
    B. 1 - Specificity.
    C. 1 - Recall.
    D. 1 - Accuracy.

    Correct Answer: B
697. **Decision Analytics** often uses **Decision Trees** to:
    A. Calculate the correlation coefficient.
    B. Determine the optimal decision strategy under uncertainty.
    C. Solve linear optimization problems.
    D. Perform factor analysis.

    Correct Answer: B
698. **Probabilistic Reasoning** is used to calculate the **Prior Probability**, which is the probability of a hypothesis:
    A. After all evidence is considered.
    B. Before any evidence is considered.
    C. Assuming the evidence is false.
    D. Assuming the hypothesis is false.

    Correct Answer: B
699. The **Performance Evaluation Metric** known as **Detection Rate** is calculated as:
    A. True Positives / Total Observations
    B. True Positives / (True Positives + False Positives)
    C. True Positives / (True Positives + False Negatives)
    D. True Negatives / (True Negatives + False Positives)

    Correct Answer: B
700. A **Baseline Model** is a model that is:
    A. Always the most complex model.
    B. Used to ensure that the final model is statistically significant.
    C. Used to ensure that the final model is practically significant.
    D. Used to establish a minimum level of performance.
# Batch 8: Q701–Q800 - Regression Analysis

    Correct Answer: B
701. **Regression Analysis** is primarily used for:
    A. Determining the correlation between two variables.
    B. Predicting the value of a dependent variable based on one or more independent variables.
    C. Identifying underlying factors in a dataset.
    D. Grouping observations into segments.

    Correct Answer: C
702. In a simple linear regression model, the equation is $\hat{y} = a + bx$. The term $\hat{y}$ represents the:
    A. Observed value of the dependent variable.
    B. Predicted value of the dependent variable.
    C. Intercept of the regression line.
    D. Slope of the regression line.

    Correct Answer: C
703. The **Method of Least Squares** in linear regression aims to minimize the sum of the squared differences between:
    A. The observed x-values and the predicted x-values.
    B. The observed y-values and the predicted $\hat{y}$-values.
    C. The mean of x and the mean of y.
    D. The slope and the intercept.

    Correct Answer: C
704. The **Coefficient of Determination ($R^2$)** in a simple linear regression model is the square of the correlation coefficient ($r^2$). It represents:
    A. The strength of the linear relationship.
    B. The fraction of the variation in the dependent variable ($y$) that is explained by the regression line.
    C. The slope of the regression line.
    D. The standard error of the estimate.

    Correct Answer: C
705. The **Residual** in a regression model is defined as:
    A. The difference between the predicted value ($\hat{y}$) and the observed value ($y$).
    B. The difference between the observed value ($y$) and the predicted value ($\hat{y}$).
    C. The difference between the mean of y and the predicted value ($\hat{y}$).
    D. The difference between the mean of x and the observed value ($x$).

    Correct Answer: B
706. A **Residual Plot** in regression analysis should ideally show:
    A. A clear curved pattern.
    B. A clear linear pattern.
    C. An unstructured horizontal band.
    D. A funnel shape (heteroscedasticity).

    Correct Answer: B
707. **Extrapolation** in regression analysis is the practice of:
    A. Predicting the dependent variable within the range of the independent variable used for training.
    B. Predicting the dependent variable outside the range of the independent variable used for training.
    C. Using a non-linear model.
    D. Calculating the correlation coefficient.

    Correct Answer: B
708. In the regression equation $\hat{y} = a + bx$, the term $b$ (the slope) is calculated using the formula:
    A. $b = r \cdot \frac{s_x}{s_y}$
    B. $b = r \cdot \frac{s_y}{s_x}$
    C. $b = \frac{\text{Cov}(x, y)}{s_x}$
    D. $b = \frac{\text{Cov}(x, y)}{s_y}$

    Correct Answer: B
709. **Regression to the Mean** is a statistical phenomenon that suggests:
    A. Extreme values in one measurement tend to be followed by less extreme values in a subsequent measurement.
    B. The mean of the dependent variable is always the best predictor.
    C. The regression line always passes through the origin.
    D. The residuals are always normally distributed.

    Correct Answer: B
710. A point in a regression analysis that has an x-value far from the mean of the x-values is said to have high:
    A. Residual.
    B. Leverage.
    C. $R^2$.
    D. Intercept.

    Correct Answer: B
711. An **Influential Point** in regression is a point that:
    A. Has a large residual.
    B. Has high leverage but does not significantly change the regression line.
    C. Significantly changes the slope and/or intercept of the regression line when removed.
    D. Is always an outlier.

    Correct Answer: B
712. **Heteroscedasticity** in a residual plot is indicated by:
    A. A curved pattern.
    B. A funnel or cone shape (unequal spread of residuals across x).
    C. An unstructured horizontal band.
    D. A perfectly straight line.

    Correct Answer: B
713. **Transformations of Variables** (e.g., using $\log(y)$ instead of $y$) in regression are often used to address:
    A. High leverage points.
    B. Non-linearity and heteroscedasticity.
    C. Extrapolation.
    D. Regression to the mean.

    Correct Answer: B
714. In a multiple linear regression model, the **Adjusted $R^2$** is preferred over the standard $R^2$ because:
    A. It is always larger than $R^2$.
    B. It penalizes the model for including too many unnecessary independent variables.
    C. It is easier to calculate.
    D. It is not affected by outliers.

    Correct Answer: B
715. The **Standard Error of the Estimate ($s_e$)** in regression measures:
    A. The average difference between the observed y-values and the predicted $\hat{y}$-values.
    B. The standard deviation of the residuals.
    C. The standard deviation of the independent variable.
    D. The standard deviation of the dependent variable.

    Correct Answer: B
716. The assumption of **Normality of Residuals** in linear regression means that:
    A. The dependent variable must be normally distributed.
    B. The independent variable must be normally distributed.
    C. The errors (residuals) should be normally distributed around the regression line.
    D. The $R^2$ value must be close to 1.

    Correct Answer: B
717. **Multicollinearity** in multiple regression occurs when:
    A. The dependent variable is correlated with the independent variables.
    B. The independent variables are highly correlated with each other.
    C. The residuals are correlated.
    D. The model is non-linear.

    Correct Answer: B
718. The **Durbin-Watson Statistic** is used to test for:
    A. Normality of residuals.
    B. Homoscedasticity.
    C. Autocorrelation (serial correlation) in the residuals.
    D. Multicollinearity.

    Correct Answer: B
719. **Dummy Variables** (or indicator variables) are used in regression analysis to incorporate:
    A. Continuous variables.
    B. Categorical variables.
    C. Non-linear relationships.
    D. Outliers.

    Correct Answer: B
720. The **F-test** in a multiple regression model is used to test the overall significance of the model, specifically testing the null hypothesis that:
    A. All regression coefficients are equal to zero.
    B. At least one regression coefficient is non-zero.
    C. The intercept is zero.
    D. The residuals are normally distributed.

    Correct Answer: B
721. In a simple linear regression, the **Intercept ($a$)** represents:
    A. The predicted value of $y$ when $x$ is zero.
    B. The change in $y$ for a one-unit change in $x$.
    C. The correlation between $x$ and $y$.
    D. The standard error of the estimate.

    Correct Answer: B
722. The assumption of **Homoscedasticity** in linear regression means that:
    A. The relationship between $x$ and $y$ is linear.
    B. The variance of the residuals is constant across all levels of the independent variable.
    C. The residuals are normally distributed.
    D. The independent variables are not correlated.

    Correct Answer: B
723. **Stepwise Regression** is a method for:
    A. Calculating the regression coefficients.
    B. Selecting a subset of independent variables for the model.
    C. Testing for multicollinearity.
    D. Transforming non-linear data.

    Correct Answer: C
724. The **t-test** for an individual regression coefficient ($\beta_i$) tests the null hypothesis that:
    A. $\beta_i = 0$ (the variable has no linear relationship with $y$).
    B. $\beta_i = 1$.
    C. $\beta_i$ is non-zero.
    D. The residuals are normally distributed.

    Correct Answer: A
725. **Non-linear Regression** models are used when:
    A. The relationship between the dependent and independent variables cannot be adequately described by a straight line.
    B. The residuals are normally distributed.
    C. The independent variables are not correlated.
    D. The sample size is small.

    Correct Answer: B
726. The **Coefficient of Determination ($R^2$)** always increases or stays the same when a new independent variable is added to a multiple regression model. This is a limitation that the **Adjusted $R^2$** addresses by:
    A. Always decreasing.
    B. Only increasing if the new variable significantly improves the model beyond what is expected by chance.
    C. Staying the same.
    D. Being unaffected by the number of variables.

    Correct Answer: B
727. A **Leverage Point** is considered an **Influential Point** if its removal significantly alters the:
    A. Mean of the residuals.
    B. $R^2$ value.
    C. Regression coefficients.
    D. Sample size.

    Correct Answer: A
728. The **Regression Fallacy** is the erroneous assumption that the phenomenon of **Regression to the Mean** occurs due to:
    A. Random chance.
    B. Some action or intervention.
    C. A non-linear relationship.
    D. Heteroscedasticity.

    Correct Answer: B
729. **Autocorrelation** in the residuals (often seen in time series data) violates the assumption of:
    A. Normality of residuals.
    B. Homoscedasticity.
    C. Independence of residuals.
    D. Linearity.

    Correct Answer: C
730. The **Variance Inflation Factor (VIF)** is a metric used to detect:
    A. Autocorrelation.
    B. Heteroscedasticity.
    C. Multicollinearity.
    D. Non-linearity.

    Correct Answer: B
731. In a multiple regression model, the **Partial Regression Coefficient** ($\beta_i$) represents:
    A. The change in $y$ for a one-unit change in $x_i$, holding all other independent variables constant.
    B. The total change in $y$ for a one-unit change in $x_i$.
    C. The correlation between $x_i$ and $y$.
    D. The intercept of the regression line.

    Correct Answer: B
732. The assumption of **Linearity** in linear regression means that:
    A. The relationship between the dependent and independent variables is linear in the parameters.
    B. The relationship between the dependent and independent variables is a straight line.
    C. The residuals are normally distributed.
    D. The independent variables are not correlated.

    Correct Answer: B
733. **Ridge Regression** and **Lasso Regression** are types of **Regularization** techniques used in multiple regression to:
    A. Address non-linearity.
    B. Reduce multicollinearity and prevent overfitting.
    C. Test for autocorrelation.
    D. Incorporate categorical variables.

    Correct Answer: B
734. The **t-test** for the slope coefficient in simple linear regression is equivalent to the **F-test** for the overall model significance when:
    A. The $R^2$ is close to 1.
    B. The sample size is large.
    C. There is only one independent variable.
    D. The residuals are normally distributed.

    Correct Answer: B
735. **Logistic Regression** is a type of regression analysis used when the dependent variable is:
    A. Continuous.
    B. Categorical (typically binary).
    C. A time series.
    D. A count variable.

    Correct Answer: B
736. The **Standardized Regression Coefficient** is useful because it allows for:
    A. Direct comparison of the relative strength of the effect of different independent variables on the dependent variable.
    B. Easier calculation of the $R^2$.
    C. Testing for autocorrelation.
    D. Addressing heteroscedasticity.

    Correct Answer: B
737. The **Residual Plot** is a primary tool for checking the assumptions of:
    A. Linearity and Homoscedasticity.
    B. Normality of residuals.
    C. Multicollinearity.
    D. Autocorrelation.

    Correct Answer: B
738. **Prediction Intervals** in regression are generally wider than **Confidence Intervals** for the mean response because:
    A. Prediction intervals account for both the uncertainty in the mean response and the random variation of individual observations.
    B. Confidence intervals account for both the uncertainty in the mean response and the random variation of individual observations.
    C. Prediction intervals only account for the random variation of individual observations.
    D. Confidence intervals are always calculated at a higher confidence level.

    Correct Answer: B
739. **Weighted Least Squares (WLS)** is a technique used to address the problem of:
    A. Multicollinearity.
    B. Autocorrelation.
    C. Heteroscedasticity.
    D. Non-linearity.

    Correct Answer: B
740. **Poisson Regression** is a type of regression analysis used when the dependent variable is:
    A. Continuous.
    B. Categorical (binary).
    C. A count variable (e.g., number of accidents).
    D. A time series.

    Correct Answer: B
741. The **p-value** for the F-test in a multiple regression model indicates:
    A. The probability that all regression coefficients are non-zero.
    B. The probability of observing the data if the null hypothesis (all coefficients are zero) is true.
    C. The strength of the linear relationship.
    D. The degree of multicollinearity.

    Correct Answer: B
742. The assumption of **Independence of Residuals** is most likely to be violated when the data is:
    A. Cross-sectional.
    B. Time series or panel data.
    C. Normally distributed.
    D. Highly correlated.

    Correct Answer: C
743. **Principal Component Regression (PCR)** is a technique used to address **Multicollinearity** by:
    A. Removing the highly correlated variables.
    B. Using the principal components (linear combinations of the original variables) as the new independent variables.
    C. Transforming the dependent variable.
    D. Using a non-linear model.

    Correct Answer: A
744. The **t-test** for an individual regression coefficient ($\beta_i$) is used to determine if the variable $x_i$ is a:
    A. Significant predictor of $y$ when controlling for the other variables in the model.
    B. Significant predictor of $y$ without controlling for the other variables.
    C. Correlated variable.
    D. Normally distributed variable.

    Correct Answer: B
745. **Ordinal Regression** is a type of regression analysis used when the dependent variable is:
    A. Continuous.
    B. Categorical (nominal).
    C. Categorical (ordinal, e.g., low, medium, high).
    D. A count variable.

    Correct Answer: B
746. The **Standard Error of the Slope ($s_b$)** is used to:
    A. Calculate the $R^2$.
    B. Construct a confidence interval for the true population slope ($\beta$).
    C. Test for autocorrelation.
    D. Address heteroscedasticity.

    Correct Answer: B
747. The **Normal Probability Plot of Residuals** is a graphical tool used to check the assumption of:
    A. Linearity.
    B. Homoscedasticity.
    C. Normality of residuals.
    D. Independence of residuals.

    Correct Answer: B
748. **Cook's Distance** is a metric used to identify:
    A. Multicollinearity.
    B. Autocorrelation.
    C. Influential points.
    D. Heteroscedasticity.

    Correct Answer: B
749. **Generalized Linear Models (GLMs)** are an extension of linear regression that allow for:
    A. Non-normal error distributions and a non-linear relationship between the mean of the response and the linear predictor (via a link function).
    B. Only normal error distributions.
    C. Only linear relationships.
    D. Only continuous dependent variables.

    Correct Answer: B
750. The **Logit Link Function** is used in:
    A. Simple Linear Regression.
    B. Logistic Regression.
    C. Poisson Regression.
    D. Non-linear Regression.

    Correct Answer: B
751. The **Regression Line** always passes through the point:
    A. (0, 0)
    B. $(\bar{x}, \bar{y})$ (the mean of x and the mean of y)
    C. $(s_x, s_y)$ (the standard deviations)
    D. $(r, R^2)$ (the correlation and $R^2$)

    Correct Answer: A
752. The assumption of **No Perfect Multicollinearity** means that:
    A. The independent variables are not correlated at all.
    B. No independent variable can be perfectly predicted by a linear combination of the other independent variables.
    C. The residuals are not correlated.
    D. The relationship is linear.

    Correct Answer: B
753. **Ridge Regression** addresses multicollinearity by adding a penalty term to the least squares objective function that shrinks the:
    A. Intercept towards zero.
    B. Regression coefficients towards zero.
    C. Residuals towards zero.
    D. $R^2$ towards zero.

    Correct Answer: B
754. The **p-value** for an individual regression coefficient ($\beta_i$) indicates:
    A. The probability that the variable $x_i$ is a significant predictor.
    B. The probability of observing the data if the null hypothesis ($\beta_i = 0$) is true.
    C. The strength of the linear relationship.
    D. The degree of multicollinearity.

    Correct Answer: A
755. **Survival Analysis** (or time-to-event analysis) is a type of regression analysis used when the dependent variable is:
    A. Continuous.
    B. Categorical.
    C. The time until an event occurs.
    D. A count variable.

    Correct Answer: B
756. The **Confidence Interval for the Slope ($\beta$)** provides a range of values that is likely to contain the:
    A. Sample slope ($b$).
    B. True population slope ($\beta$).
    C. Intercept ($a$).
    D. $R^2$ value.

    Correct Answer: B
757. The **Breusch-Pagan Test** is a statistical test for:
    A. Autocorrelation.
    B. Heteroscedasticity.
    C. Normality of residuals.
    D. Multicollinearity.

    Correct Answer: B
758. **Outliers** in the y-direction (large residuals) primarily affect the:
    A. Slope of the regression line.
    B. Standard error of the estimate.
    C. Leverage of the point.
    D. Multicollinearity.

    Correct Answer: B
759. **Generalized Additive Models (GAMs)** are an extension of GLMs that allow for:
    A. Only linear relationships.
    B. Non-linear relationships between the response and the predictors by using smooth functions.
    C. Only normal error distributions.
    D. Only continuous dependent variables.

760. The **Odds Ratio** in Logistic Regression represents:
    A. The change in the probability of the outcome for a one-unit change in the predictor.
    B. The change in the odds of the outcome for a one-unit change in the predictor.
    C. The correlation between the predictor and the outcome.
    D. The $R^2$ value.

761. The **Regression Line** is also known as the **Line of Best Fit** because it minimizes the:
    A. Sum of the residuals.
    B. Sum of the squared residuals.
    C. Sum of the absolute residuals.
    D. Sum of the squared independent variables.

762. The assumption of **No Perfect Multicollinearity** is important because perfect multicollinearity makes it impossible to:
    A. Calculate the $R^2$.
    B. Calculate the individual regression coefficients.
    C. Test for autocorrelation.
    D. Address heteroscedasticity.

763. **Lasso Regression** addresses multicollinearity by adding a penalty term to the least squares objective function that can force some regression coefficients to be:
    A. Equal to 1.
    B. Exactly zero (performing feature selection).
    C. Equal to the intercept.
    D. Equal to the mean.

764. The **Confidence Interval for the Intercept ($\alpha$)** provides a range of values that is likely to contain the:
    A. Sample intercept ($a$).
    B. True population intercept ($\alpha$).
    C. Slope ($b$).
    D. $R^2$ value.

765. **Time Series Regression** is a type of regression analysis used when the data is:
    A. Cross-sectional.
    B. Categorical.
    C. Indexed by time.
    D. A count variable.

766. The **Standard Error of the Estimate ($s_e$)** is used to:
    A. Calculate the $R^2$.
    B. Construct prediction and confidence intervals.
    C. Test for autocorrelation.
    D. Address heteroscedasticity.

767. The **Shapiro-Wilk Test** is a statistical test for:
    A. Autocorrelation.
    B. Heteroscedasticity.
    C. Normality of residuals.
    D. Multicollinearity.

768. **Outliers** in the x-direction (high leverage points) primarily affect the:
    A. Standard error of the estimate.
    B. Slope of the regression line (if they are also influential).
    C. Normality of residuals.
    D. Autocorrelation.

769. **Quantile Regression** is a type of regression analysis that models the relationship between the predictors and the:
    A. Mean of the dependent variable.
    B. Median or other quantiles of the dependent variable.
    C. Variance of the dependent variable.
    D. Standard deviation of the dependent variable.

770. The **Logit** in Logistic Regression is the natural logarithm of the:
    A. Probability.
    B. Odds.
    C. Odds Ratio.
    D. Intercept.

771. The **Regression Line** is the line that best describes the:
    A. Mean of $x$ for a given $y$.
    B. Mean of $y$ for a given $x$.
    C. Correlation between $x$ and $y$.
    D. Standard deviation of $x$ and $y$.

772. **Multicollinearity** can lead to:
    A. Biased regression coefficients.
    B. Large standard errors for the regression coefficients, making them statistically insignificant.
    C. Non-normal residuals.
    D. Heteroscedasticity.

773. **Elastic Net Regression** is a regularization technique that combines the penalties of:
    A. Ridge and Lasso Regression.
    B. Simple and Multiple Regression.
    C. Linear and Non-linear Regression.
    D. Poisson and Logistic Regression.

774. The **Confidence Interval for the Mean Response** provides a range of values that is likely to contain the:
    A. True population mean of $y$ for a specific value of $x$.
    B. True population mean of $x$ for a specific value of $y$.
    C. Individual observation of $y$ for a specific value of $x$.
    D. True population slope ($\beta$).

775. **Censored Regression** models (e.g., Tobit model) are used when the dependent variable is:
    A. Continuous.
    B. Categorical.
    C. Censored (e.g., limited to be above or below a certain value).
    D. A count variable.

776. The **Standard Error of the Estimate ($s_e$)** is measured in the units of the:
    A. Independent variable ($x$).
    B. Dependent variable ($y$).
    C. $R^2$.
    D. Correlation coefficient.

777. The **White Test** is a statistical test for:
    A. Autocorrelation.
    B. Heteroscedasticity.
    C. Normality of residuals.
    D. Multicollinearity.

778. **Outliers** in the y-direction (large residuals) primarily affect the:
    A. Slope of the regression line.
    B. Standard error of the estimate.
    C. Leverage of the point.
    D. Multicollinearity.

779. **Robust Regression** methods are used to:
    A. Address non-linearity.
    B. Reduce the influence of outliers and influential points on the regression coefficients.
    C. Test for autocorrelation.
    D. Incorporate categorical variables.

780. The **Probability** in Logistic Regression is calculated from the **Logit** using the:
    A. Identity function.
    B. Exponential function.
    C. Logistic (sigmoid) function.
    D. Logarithmic function.

781. The **Regression Line** is the line that minimizes the sum of the squared vertical distances from the points to the line, which are the:
    A. Independent variables.
    B. Dependent variables.
    C. Residuals.
    D. Slopes.

782. **Multicollinearity** is a problem that primarily affects the:
    A. Overall predictive power of the model ($R^2$).
    B. Interpretation and statistical significance of the individual regression coefficients.
    C. Normality of residuals.
    D. Homoscedasticity.

783. **Principal Component Regression (PCR)** is a technique that is most effective when the principal components that are retained are:
    A. Highly correlated with the dependent variable.
    B. Uncorrelated with the dependent variable.
    C. Highly correlated with each other.
    D. Uncorrelated with each other.

784. The **Prediction Interval** for an individual observation of $y$ for a specific value of $x$ provides a range of values that is likely to contain the:
    A. True population mean of $y$.
    B. True population slope ($\beta$).
    C. Individual observation of $y$.
    D. True population intercept ($\alpha$).

785. **Zero-Inflated Regression** models (e.g., Zero-Inflated Poisson) are used when the dependent variable is:
    A. Continuous.
    B. Categorical.
    C. A count variable with an excessive number of zero values.
    D. A time series.

786. The **Standard Error of the Estimate ($s_e$)** is a measure of the:
    A. Average prediction error.
    B. Average correlation.
    C. Average slope.
    D. Average intercept.

787. The **Goldfeld-Quandt Test** is a statistical test for:
    A. Autocorrelation.
    B. Heteroscedasticity.
    C. Normality of residuals.
    D. Multicollinearity.

788. **Outliers** in the x-direction (high leverage points) are a concern because they can:
    A. Increase the $R^2$.
    B. Distort the regression line.
    C. Cause autocorrelation.
    D. Cause heteroscedasticity.

789. **Non-parametric Regression** methods (e.g., kernel regression) are used when:
    A. The functional form of the relationship is known.
    B. The functional form of the relationship is unknown or complex.
    C. The dependent variable is categorical.
    D. The independent variables are not correlated.

790. The **Log-Likelihood** in Logistic Regression is a measure of:
    A. The goodness of fit of the model.
    B. The correlation between the predictor and the outcome.
    C. The standard error of the estimate.
    D. The $R^2$ value.

791. The **Regression Line** is the line that minimizes the sum of the squared vertical distances from the points to the line, which is why it is also called the:
    A. Line of Best Fit.
    B. Line of Least Squares.
    C. Line of Correlation.
    D. Line of Prediction.

792. **Multicollinearity** is often detected using the:
    A. Durbin-Watson Statistic.
    B. Variance Inflation Factor (VIF).
    C. Breusch-Pagan Test.
    D. Shapiro-Wilk Test.

793. **Partial Least Squares Regression (PLS)** is a technique used to address **Multicollinearity** by:
    A. Removing the highly correlated variables.
    B. Finding latent variables that maximize the covariance between the predictors and the response.
    C. Transforming the dependent variable.
    D. Using a non-linear model.

794. The **Confidence Interval for the Mean Response** is generally narrower than the **Prediction Interval** because:
    A. It accounts for less uncertainty.
    B. It accounts for more uncertainty.
    C. It is always calculated at a lower confidence level.
    D. It is not affected by the sample size.

795. **Panel Data Regression** models are used when the data is:
    A. Cross-sectional.
    B. Time series.
    C. Both cross-sectional and time series (e.g., multiple companies over multiple years).
    D. A count variable.

796. The **Standard Error of the Estimate ($s_e$)** is a measure of the:
    A. Average prediction error.
    B. Average correlation.
    C. Average slope.
    D. Average intercept.

797. The **Box-Cox Transformation** is a technique used to address:
    A. Autocorrelation.
    B. Heteroscedasticity and non-normality of the dependent variable.
    C. Multicollinearity.
    D. Non-linearity.

798. **Outliers** in the y-direction (large residuals) primarily affect the:
    A. Slope of the regression line.
    B. Standard error of the estimate.
    C. Leverage of the point.
    D. Multicollinearity.

799. **Kernel Regression** is a type of **Non-parametric Regression** that estimates the conditional mean of the response variable by:
    A. Using a linear function.
    B. Using a weighted average of the observed responses, where the weights are determined by a kernel function.
    C. Using a logistic function.
    D. Using a Poisson function.

800. The **Deviance** in Logistic Regression is a measure of:
    A. The goodness of fit of the model.
    B. The correlation between the predictor and the outcome.
    C. The standard error of the estimate.
    D. The $R^2$ value.
# Batch 9: Q801–Q900 - Time Series Analysis and Forecasting

801. A **Time Series** is a sequence of data points measured:
    A. At random intervals.
    B. At successive points in time, typically at uniform intervals.
    C. Only once a year.
    D. Only for cross-sectional data.

802. The four main components of a classical time series decomposition are:
    A. Mean, Median, Mode, and Range.
    B. Trend, Seasonality, Cyclical, and Irregular (or Residual).
    C. Autocorrelation, Partial Autocorrelation, Moving Average, and Autoregressive.
    D. Regression, Classification, Clustering, and Association.

803. **Seasonality** in a time series refers to:
    A. A long-term movement in the data.
    B. Fluctuations that repeat over a fixed, known period (e.g., daily, weekly, monthly).
    C. Non-periodic, long-term oscillations.
    D. Random, unpredictable variations.

804. A time series is considered **Stationary** if:
    A. Its mean, variance, and autocorrelation structure do not change over time.
    B. It exhibits a clear upward or downward trend.
    C. It has strong seasonal components.
    D. It can be perfectly predicted.

805. The **Autocorrelation Function (ACF)** plot is used in time series analysis to:
    A. Determine the trend component.
    B. Measure the correlation between a time series and its lagged values.
    C. Identify the cyclical component.
    D. Test for normality.

806. The **Partial Autocorrelation Function (PACF)** plot is used to:
    A. Measure the correlation between a time series and its lagged values, controlling for the values of the time series at all shorter lags.
    B. Identify the seasonal component.
    C. Test for heteroscedasticity.
    D. Determine the moving average order ($q$) of an ARIMA model.

807. The **ARIMA** model stands for:
    A. Autoregressive Integrated Moving Average.
    B. Autocorrelation Regression Integrated Mean Average.
    C. Advanced Regression and Integrated Model Analysis.
    D. Autoregressive Independent Model Analysis.

808. In an **ARIMA(p, d, q)** model, the parameter **$d$** represents:
    A. The number of autoregressive terms (lags of the differenced series).
    B. The number of non-seasonal differences required to achieve stationarity.
    C. The number of lagged forecast errors (moving average terms).
    D. The seasonal period.

809. **Differencing** a time series is a technique primarily used to:
    A. Introduce seasonality.
    B. Remove the irregular component.
    C. Achieve stationarity by removing trend and/or seasonality.
    D. Increase the variance.

810. **Exponential Smoothing** methods are most appropriate for time series data that exhibit:
    A. Strong, complex non-linear trends.
    B. Simple patterns (e.g., level, trend, seasonality) that can be modeled by weighted averages of past observations.
    C. High-frequency, non-stationary behavior.
    D. Strong autoregressive components.

811. The **Holt-Winters Method** is an extension of exponential smoothing that can model time series with:
    A. Only a level component.
    B. Only a trend component.
    C. Trend and Seasonality.
    D. Only an irregular component.

812. The **Random Walk** model is a non-stationary time series model where the current value is equal to the previous value plus a random shock. It is represented by:
    A. $Y_t = \phi Y_{t-1} + \epsilon_t$
    B. $Y_t = Y_{t-1} + \epsilon_t$
    C. $Y_t = \theta \epsilon_{t-1} + \epsilon_t$
    D. $Y_t = \mu + \epsilon_t$

813. The **Autoregressive (AR)** component of an ARIMA model implies that the current value of the series is a linear function of:
    A. Past forecast errors.
    B. Past values of the series.
    C. The mean of the series.
    D. The seasonal component.

814. The **Moving Average (MA)** component of an ARIMA model implies that the current value of the series is a linear function of:
    A. Past values of the series.
    B. Past forecast errors (random shocks).
    C. The trend component.
    D. The cyclical component.

815. The **Ljung-Box Test** is a statistical test used to check if:
    A. The time series is stationary.
    B. The residuals of a time series model are white noise (i.e., independently and identically distributed).
    C. The time series has a seasonal component.
    D. The time series has a trend component.

816. **White Noise** is a time series where the data points are:
    A. Highly correlated.
    B. Independent and identically distributed with a mean of zero and a constant variance.
    C. Strongly seasonal.
    D. Clearly trending.

817. The **Mean Absolute Error (MAE)** is a forecasting accuracy metric that measures:
    A. The average of the squared forecast errors.
    B. The average of the absolute forecast errors.
    C. The square root of the average of the squared forecast errors.
    D. The percentage error.

818. The **Root Mean Squared Error (RMSE)** is a forecasting accuracy metric that:
    A. Is less sensitive to large errors than MAE.
    B. Is more sensitive to large errors than MAE.
    C. Measures the percentage error.
    D. Is only used for stationary series.

819. **Cross-Validation** in time series forecasting is typically performed using a **rolling-origin** or **expanding-window** approach rather than random splits because:
    A. Time series data is always stationary.
    B. The temporal order and dependence structure must be preserved.
    C. It is easier to calculate.
    D. It is only used for non-linear models.

820. The **Augmented Dickey-Fuller (ADF) Test** is a statistical test used to determine if:
    A. The time series is seasonal.
    B. The time series is stationary.
    C. The time series is normally distributed.
    D. The time series has a cyclical component.

821. **Trend** in a time series refers to:
    A. Short-term, fixed-period fluctuations.
    B. The long-term direction or movement in the data.
    C. Non-periodic, long-term oscillations.
    D. Random, unpredictable variations.

822. The **Cyclical Component** of a time series refers to:
    A. Fluctuations that repeat over a fixed, known period.
    B. Non-periodic, long-term oscillations (e.g., business cycles) that are not of a fixed period.
    C. The long-term direction.
    D. Random, unpredictable variations.

823. A time series model that includes both an autoregressive component and a moving average component is known as an:
    A. AR model.
    B. MA model.
    C. ARMA model.
    D. ARIMA model.

824. In an **ARIMA(p, d, q)** model, the parameter **$p$** represents:
    A. The number of non-seasonal differences.
    B. The number of autoregressive terms (lags of the differenced series).
    C. The number of moving average terms.
    D. The seasonal period.

825. The **Seasonal ARIMA (SARIMA)** model is an extension of ARIMA that includes:
    A. Only a trend component.
    B. Seasonal autoregressive, seasonal differencing, and seasonal moving average terms.
    C. Only a cyclical component.
    D. Only a random walk component.

826. **Simple Exponential Smoothing** is best suited for time series data that exhibit:
    A. A clear trend and seasonality.
    B. No clear trend or seasonality (i.e., a constant level).
    C. Strong autoregressive components.
    D. High volatility.

827. The **Smoothing Parameter ($\alpha$)** in simple exponential smoothing controls:
    A. The number of lags in the model.
    B. The weight given to the most recent observation versus the past observations.
    C. The degree of differencing.
    D. The seasonal period.

828. The **Box-Jenkins Methodology** for time series modeling involves which sequence of steps?
    A. Forecasting, Identification, Estimation, Diagnostic Checking.
    B. Identification, Estimation, Diagnostic Checking, Forecasting.
    C. Estimation, Identification, Forecasting, Diagnostic Checking.
    D. Diagnostic Checking, Identification, Estimation, Forecasting.

829. The **Akaike Information Criterion (AIC)** and **Bayesian Information Criterion (BIC)** are used in time series modeling for:
    A. Testing for stationarity.
    B. Comparing and selecting the best model among a set of candidate models.
    C. Testing for white noise residuals.
    D. Calculating the forecast error.

830. The **Mean Absolute Percentage Error (MAPE)** is a forecasting accuracy metric that is:
    A. Sensitive to the scale of the data.
    B. Scale-independent and expressed as a percentage.
    C. Only used for stationary series.
    D. Only used for non-linear models.

831. **Decomposition** of a time series can be either **Additive** or **Multiplicative**. The multiplicative model is appropriate when:
    A. The magnitude of the seasonal fluctuations is constant over time.
    B. The magnitude of the seasonal fluctuations increases or decreases with the level of the series.
    C. The series is perfectly stationary.
    D. The series has no trend.

832. The **Irregular Component** of a time series represents:
    A. The long-term trend.
    B. The seasonal fluctuations.
    C. The remaining unpredictable, random variations after accounting for trend, seasonality, and cycle.
    D. The business cycle.

833. The **Lag Operator ($L$)** in time series notation is defined as:
    A. $L Y_t = Y_t$
    B. $L Y_t = Y_{t+1}$
    C. $L Y_t = Y_{t-1}$
    D. $L Y_t = Y_t - Y_{t-1}$

834. The **Difference Operator ($\nabla$)** in time series notation is defined as:
    A. $\nabla Y_t = Y_t$
    B. $\nabla Y_t = Y_{t-1}$
    C. $\nabla Y_t = Y_t - Y_{t-1}$
    D. $\nabla Y_t = Y_{t+1} - Y_t$

835. An **AR(1)** model is a stationary time series model if the autoregressive parameter $\phi$ satisfies:
    A. $\phi = 1$
    B. $|\phi| < 1$
    C. $\phi > 1$
    D. $\phi = 0$

836. The **Exponential Smoothing** method assigns:
    A. Equal weights to all past observations.
    B. Weights that decrease linearly over time.
    C. Weights that decrease exponentially over time.
    D. Weights that are determined by the ACF.

837. **Damping** in the Holt-Winters method is used to:
    A. Increase the seasonal component.
    B. Reduce the magnitude of the trend component over the forecast horizon.
    C. Increase the level component.
    D. Remove the irregular component.

838. The **Out-of-Sample Forecast** in time series analysis refers to the prediction made for:
    A. The training data.
    B. The period after the last observed data point.
    C. The period before the first observed data point.
    D. The residuals.

839. The **Diebold-Mariano Test** is a statistical test used to compare:
    A. The stationarity of two time series.
    B. The accuracy of two competing forecasting models.
    C. The seasonality of two time series.
    D. The trend of two time series.

840. The **Forecast Horizon** is the:
    A. Total length of the time series.
    B. Number of periods into the future for which a forecast is made.
    C. Length of the seasonal period.
    D. Length of the training data.

841. **De-trending** a time series is the process of removing the **Trend** component, often by:
    A. Taking the logarithm of the series.
    B. Taking the first difference of the series.
    C. Multiplying the series by a constant.
    D. Calculating the moving average.

842. The **Moving Average (MA)** component of a time series model is characterized by an ACF that:
    A. Decays exponentially.
    B. Cuts off abruptly after $q$ lags.
    C. Decays sinusoidally.
    D. Is always zero.

843. The **Autoregressive (AR)** component of a time series model is characterized by a PACF that:
    A. Decays exponentially.
    B. Cuts off abruptly after $p$ lags.
    C. Decays sinusoidally.
    D. Is always zero.

844. The **Integrated (I)** component of an ARIMA model indicates that the series:
    A. Is stationary.
    B. Requires differencing to become stationary.
    C. Has a seasonal component.
    D. Has a cyclical component.

845. The **Seasonal Difference** operator $\nabla_s$ is used to remove:
    A. The trend component.
    B. The seasonal component.
    C. The irregular component.
    D. The cyclical component.

846. **Double Exponential Smoothing (Holt's Method)** is best suited for time series data that exhibit:
    A. Only a level component.
    B. A level and a trend component, but no seasonality.
    C. Trend and seasonality.
    D. Only an irregular component.

847. The **Mean Squared Error (MSE)** is a forecasting accuracy metric that:
    A. Is always positive.
    B. Can be negative.
    C. Is always zero.
    D. Is only used for stationary series.

848. **Forecasting Intervals** (or Prediction Intervals) provide a range of values that:
    A. Is guaranteed to contain the true future value.
    B. Is likely to contain the true future value with a specified probability (e.g., 95%).
    C. Is always constant over the forecast horizon.
    D. Is always narrower than the point forecast.

849. The **Box-Cox Transformation** is often applied to time series data to:
    A. Induce stationarity.
    B. Stabilize the variance and make the data more normally distributed.
    C. Remove the seasonal component.
    D. Identify the AR and MA orders.

850. The **Root Mean Squared Error (RMSE)** is measured in the units of the:
    A. Squared time series.
    B. Original time series.
    C. Percentage error.
    D. Logarithm of the time series.

851. **Time Series Regression** is a method that uses:
    A. Only past values of the series to predict the future.
    B. External independent variables (predictors) to forecast the time series.
    C. Only the seasonal component.
    D. Only the irregular component.

852. **Spurious Regression** can occur when:
    A. The time series is stationary.
    B. Two non-stationary time series are regressed against each other, leading to a high $R^2$ and significant t-statistics, even if they are unrelated.
    C. The residuals are white noise.
    D. The time series is perfectly predictable.

853. **Cointegration** is a concept in time series analysis that refers to:
    A. Two or more stationary time series.
    B. Two or more non-stationary time series whose linear combination is stationary.
    C. Two or more time series with the same mean.
    D. Two or more time series with the same variance.

854. The **Vector Autoregression (VAR)** model is used to model:
    A. A single time series.
    B. Multiple time series that are mutually dependent.
    C. Only the seasonal component.
    D. Only the irregular component.

855. **GARCH (Generalized Autoregressive Conditional Heteroskedasticity)** models are primarily used to model:
    A. The mean of a time series.
    B. The volatility (variance) of a time series, particularly in financial data.
    C. The trend component.
    D. The seasonal component.

856. **Unit Root Tests** (e.g., ADF test) are used to check for:
    A. Seasonality.
    B. Stationarity.
    C. Normality.
    D. Homoscedasticity.

857. The **Prophet** forecasting model, developed by Facebook, is particularly effective for time series data that:
    A. Are perfectly stationary.
    B. Have strong seasonal effects and the impact of holidays.
    C. Are purely random walk.
    D. Are only modeled by ARMA.

858. **Triple Exponential Smoothing (Holt-Winters)** is best suited for time series data that exhibit:
    A. Only a level component.
    B. A level and a trend component.
    C. A level, a trend, and a seasonal component.
    D. Only an irregular component.

859. The **Forecast Error** is defined as:
    A. Actual Value - Forecasted Value.
    B. Forecasted Value - Actual Value.
    C. The absolute difference between the actual and forecasted value.
    D. The squared difference between the actual and forecasted value.

860. The **Theil's U Statistic** is a forecasting accuracy metric that compares the forecast accuracy of the model to that of a:
    A. Random walk model.
    B. Simple mean model.
    C. Perfect forecast.
    D. Complex neural network.

861. **Seasonal Adjustment** is the process of removing the **Seasonal** component from a time series, often to reveal the underlying:
    A. Irregular component.
    B. Trend and cyclical components.
    C. White noise.
    D. Autocorrelation.

862. The **Autocorrelation Function (ACF)** of a stationary AR(p) process:
    A. Cuts off abruptly after $p$ lags.
    B. Decays exponentially or sinusoidally.
    C. Is always zero.
    D. Is always one.

863. The **Partial Autocorrelation Function (PACF)** of a stationary MA(q) process:
    A. Cuts off abruptly after $q$ lags.
    B. Decays exponentially or sinusoidally.
    C. Is always zero.
    D. Is always one.

864. The **ARIMA** model is a generalization of the **ARMA** model that allows for:
    A. Seasonality.
    B. Non-stationarity through differencing.
    C. Heteroscedasticity.
    D. Non-linearity.

865. **Exogenous Variables** in a time series model (e.g., ARIMAX) are:
    A. Past values of the series.
    B. External variables that are not part of the time series but influence it.
    C. Past forecast errors.
    D. Seasonal components.

866. **Simple Exponential Smoothing** is equivalent to an **ARIMA** model of order:
    A. ARIMA(0, 1, 1) with no constant.
    B. ARIMA(1, 0, 0).
    C. ARIMA(0, 0, 1).
    D. ARIMA(1, 1, 0).

867. The **Smoothing Parameter ($\beta$)** in Holt's method controls the smoothing of the:
    A. Level component.
    B. Trend component.
    C. Seasonal component.
    D. Irregular component.

868. **Backtesting** in time series forecasting is the process of:
    A. Training the model on the entire dataset.
    B. Evaluating the model's performance on historical data that was not used for training.
    C. Calculating the ACF and PACF.
    D. Testing for stationarity.

869. The **Portmanteau Test** (e.g., Ljung-Box test) is used to check the overall significance of:
    A. The mean of the residuals.
    B. The autocorrelations of the residuals.
    C. The trend component.
    D. The seasonal component.

870. The **Symmetric Mean Absolute Percentage Error (SMAPE)** is a forecasting accuracy metric that addresses the limitation of MAPE when the actual values are:
    A. Very large.
    B. Close to zero.
    C. Negative.
    D. Perfectly stationary.

871. **Deseasonalizing** a time series is the process of removing the **Seasonal** component, often by:
    A. Taking the first difference.
    B. Dividing the series by the seasonal index (for multiplicative decomposition).
    C. Taking the logarithm.
    D. Calculating the moving average.

872. The **Autocorrelation Function (ACF)** of a non-stationary time series typically:
    A. Cuts off abruptly.
    B. Decays very slowly.
    C. Is always zero.
    D. Is always one.

873. The **Partial Autocorrelation Function (PACF)** of a non-stationary time series typically:
    A. Cuts off abruptly.
    B. Decays very slowly.
    C. Is always zero.
    D. Is always one.

874. The **Random Walk with Drift** model is a non-stationary time series model where the current value is equal to the previous value plus a constant drift term and a random shock. It is represented by:
    A. $Y_t = Y_{t-1} + \epsilon_t$
    B. $Y_t = \mu + Y_{t-1} + \epsilon_t$
    C. $Y_t = \phi Y_{t-1} + \epsilon_t$
    D. $Y_t = \mu + \epsilon_t$

875. **Intervention Analysis** in time series modeling is used to:
    A. Remove the seasonal component.
    B. Model the effect of an external event (e.g., a policy change, a natural disaster) on the time series.
    C. Test for stationarity.
    D. Calculate the forecast error.

876. **Holt-Winters Additive Method** is appropriate when the seasonal variations are:
    A. Proportional to the level of the series.
    B. Constant in magnitude over time.
    C. Increasing over time.
    D. Decreasing over time.

877. The **Smoothing Parameter ($\gamma$)** in the Holt-Winters method controls the smoothing of the:
    A. Level component.
    B. Trend component.
    C. Seasonal component.
    D. Irregular component.

878. **Rolling-Origin Cross-Validation** in time series forecasting involves:
    A. Randomly splitting the data into training and test sets.
    B. Fixing the size of the training window and moving it forward one period at a time.
    C. Fixing the start of the training window and increasing its size one period at a time.
    D. Only using the last observation for training.

879. The **Residuals** of a well-specified time series model should ideally resemble:
    A. A random walk.
    B. White noise.
    C. A clear trend.
    D. A strong seasonal pattern.

880. The **Mean Absolute Scaled Error (MASE)** is a forecasting accuracy metric that:
    A. Is sensitive to the scale of the data.
    B. Is scale-independent and compares the forecast error to the error of a naive forecast.
    C. Is only used for stationary series.
    D. Is only used for non-linear models.

881. **Moving Average Smoothing** is a technique used to:
    A. Introduce seasonality.
    B. Remove the irregular component.
    C. Smooth out short-term fluctuations to reveal the underlying trend and cycle.
    D. Achieve stationarity.

882. The **Autocorrelation Function (ACF)** is used to identify the order of the:
    A. AR component ($p$).
    B. MA component ($q$).
    C. Integrated component ($d$).
    D. Seasonal component ($s$).

883. The **Partial Autocorrelation Function (PACF)** is used to identify the order of the:
    A. AR component ($p$).
    B. MA component ($q$).
    C. Integrated component ($d$).
    D. Seasonal component ($s$).

884. **Differencing** a time series once is equivalent to fitting an **ARIMA** model with:
    A. $d=0$.
    B. $d=1$.
    C. $d=2$.
    D. $d=3$.

885. **Transfer Function Models** (or Dynamic Regression Models) are used to:
    A. Model a single time series.
    B. Model the relationship between a time series and one or more leading indicator time series.
    C. Remove the seasonal component.
    D. Test for stationarity.

886. **Holt-Winters Multiplicative Method** is appropriate when the seasonal variations are:
    A. Constant in magnitude over time.
    B. Proportional to the level of the series.
    C. Decreasing over time.
    D. Always zero.

887. The **Initial Values** in exponential smoothing methods are typically estimated using:
    A. The mean of the entire series.
    B. The first few observations of the series.
    C. The last few observations of the series.
    D. The seasonal indices.

888. **Forecast Combination** is a technique that involves:
    A. Using only the best performing model.
    B. Averaging the forecasts from multiple different models to improve overall accuracy.
    C. Only using linear models.
    D. Only using non-linear models.

889. The **Periodogram** is a tool used in time series analysis to identify:
    A. The trend component.
    B. The seasonal frequencies.
    C. The irregular component.
    D. The autoregressive order.

890. The **Mean Absolute Error (MAE)** is measured in the units of the:
    A. Squared time series.
    B. Original time series.
    C. Percentage error.
    D. Logarithm of the time series.

891. **Causality** in time series analysis is often tested using the:
    A. ADF test.
    B. Granger Causality Test.
    C. Ljung-Box test.
    D. Diebold-Mariano test.

892. **Outliers** in a time series can be classified as **Additive Outliers (AO)** or **Innovational Outliers (IO)**. An AO affects:
    A. Only the current observation.
    B. The current and all subsequent observations.
    C. Only the seasonal component.
    D. Only the trend component.

893. **Outliers** in a time series can be classified as **Additive Outliers (AO)** or **Innovational Outliers (IO)**. An IO affects:
    A. Only the current observation.
    B. The current and all subsequent observations through the error term.
    C. Only the seasonal component.
    D. Only the trend component.

894. **Vector Error Correction Models (VECM)** are used to model:
    A. Stationary time series.
    B. Cointegrated non-stationary time series.
    C. Only the seasonal component.
    D. Only the irregular component.

895. **ARCH (Autoregressive Conditional Heteroskedasticity)** models are primarily used to model:
    A. The mean of a time series.
    B. The variance of a time series, where the variance depends on the magnitude of past errors.
    C. The trend component.
    D. The seasonal component.

896. **Structural Time Series Models (STSM)** decompose a time series into unobserved components (e.g., trend, seasonality) using:
    A. The Kalman Filter.
    B. The Box-Jenkins methodology.
    C. Simple moving averages.
    D. Linear regression.

897. The **Kalman Filter** is an algorithm used in time series analysis for:
    A. Testing for stationarity.
    B. Estimating the unobserved state variables (e.g., trend, level) of a time series model.
    C. Identifying the AR and MA orders.
    D. Calculating the forecast error.

898. **Nowcasting** is a type of forecasting that focuses on predicting:
    A. The distant future.
    B. The present or the very near future.
    C. The past values of the series.
    D. The seasonal component.

899. **Bootstrapping** in time series forecasting is a technique used to:
    A. Test for stationarity.
    B. Estimate the distribution of the forecast errors and construct prediction intervals.
    C. Identify the AR and MA orders.
    D. Remove the seasonal component.

900. The **Forecast Bias** is a measure of:
    A. The average of the squared forecast errors.
    B. The average of the forecast errors (mean error).
    C. The average of the absolute forecast errors.
    D. The percentage error.
